'use strict';(function(){const indexCfg={cache:true};indexCfg.doc={id:'id',field:['title','content'],store:['title','href','section'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/posts/linux-library/','title':"linux library",'section':"Posts",'content':"定位动态库文件 locate libGL.so 打印载入动态库的过程 export LD_DEBUG=libs\nPrint the lists of directories and candidate libraries stored in the current cache. ldconfig -p\n"});index.add({'id':1,'href':'/posts/Rust-%E5%85%A5%E9%97%A8%E4%B9%8B%E5%AE%89%E8%A3%85/','title':"Rust 入门之安装",'section':"Posts",'content':"准备工具 #  官方网站 https://www.rust-lang.org/。 镜像站点 https://lug.ustc.edu.cn/wiki/mirrors/help/rust-crates\nexport RUSTUP_DIST_SERVER=https://mirrors.ustc.edu.cn/rust-static export RUSTUP_UPDATE_ROOT=https://mirrors.ustc.edu.cn/rust-static/rustup\nset RUSTUP_DIST_SERVER=https://mirrors.ustc.edu.cn/rust-static set RUSTUP_UPDATE_ROOT=https://mirrors.ustc.edu.cn/rust-static/rustup\n安装 #  启动安装程序rustup-init.exe, 或安装脚本。 https://static.rust-lang.org/rustup/dist/x86_64-pc-windows-msvc/rustup-init.exe curl \u0026ndash;proto \u0026lsquo;=https\u0026rsquo; \u0026ndash;tlsv1.2 -sSf https://sh.rustup.rs | sh\n镜像 #  在 $HOME/.cargo/config 配置镜像，\n[source.crates-io] registry = \u0026#34;https://github.com/rust-lang/crates.io-index\u0026#34; replace-with = \u0026#39;ustc\u0026#39; [source.ustc] registry = \u0026#34;git://mirrors.ustc.edu.cn/crates.io-index\u0026#34; "});index.add({'id':2,'href':'/posts/%E8%AE%B0%E4%B8%80%E6%AC%A1grub%E5%BC%95%E5%AF%BC%E9%85%8D%E7%BD%AE/','title':"记一次grub引导配置",'section':"Posts",'content':"Centos7 启动过程中进入grub2的启动菜单。菜单中默认的第一个启动项的内核已经不存在，启动失败。 尝试更改/boot/efi/centos/grub.conf， 发现与启动菜单中的内核版本号对不上。 使用fdisk -l 查看，发现有单独的efi分区/sda1 。 当前系统的/boot/分区挂载的是/sda2。 所以前面修改的/boot/efi/centos/grub.conf其实是/sda2中的文件。 尝试挂载/sda1，系统提示unknown filesystem type vfat 搜索答案无果，偶然发现 fdisk 提示 分区为 msdos 格式。 使用 mount -t msdos /dev/sda1 /mnt/ 挂载成功。 修改grub.conf配置文件，注释无效的第一个启动项，系统重启成功。\n"});index.add({'id':3,'href':'/posts/lsyncd%E5%90%8C%E6%AD%A5/','title':"lsyncd同步",'section':"Posts",'content':"参考\n几大实时同步工具比较 https://www.cnblogs.com/zxci/p/6243574.html\nLsyncd搭建同步镜像-用Lsyncd实现本地和远程服务器之间实时同步 https://www.cnblogs.com/jiangzhaowei/p/8298416.html\n"});index.add({'id':4,'href':'/posts/gb28181_rest-docker-/','title':"gb28181_rest docker ",'section':"Posts",'content':"启动mysql服务 sudo docker run -p 3306:3306 \u0026ndash;name gb28181_mysql -v /home/z/docker/etc/mysql/my.cnf:/etc/mysql/my.cnf -d mariadb\nsudo docker run -d -p 3306:3306 -v /home/z/docker/mysql/data:/var/lib/mysql -v /home/z/docker/etc/mysql/my.cnf:/etc/mysql/my.cnf -e MYSQL_PASS=\u0026ldquo;root\u0026rdquo; tutum/mysql\ndocker run\n\u0026ndash;detach\n\u0026ndash;publish=33006:3306\n\u0026ndash;restart=always\n\u0026ndash;privileged=true\n\u0026ndash;env=MYSQL_ROOT_PASSWORD=root\n\u0026ndash;name=mysql\ntutum/mysql\n\u0026ndash;character-set-server=utf8\n\u0026ndash;collation-server=utf8_general_ci\n\u0026ndash;default-authentication-plugin=mysql_native_password \u0026ndash;lower_case_table_names=1 ———————————————— 版权声明：本文为CSDN博主「fengzi-fengzi」的原创文章，遵循CC 4.0 by-sa版权协议，转载请附上原文出处链接及本声明。 原文链接：https://blog.csdn.net/qq_31864653/article/details/90769142\n/usr/sbin/mysqld \u0026ndash;basedir=/usr \u0026ndash;datadir=/var/lib/mysql \u0026ndash;plugin-dir=/usr/lib/mysql/plugin \u0026ndash;user=mysql \u0026ndash;log-error=/var/log/mysql/error.log \u0026ndash;pid-file=/var/run/mysqld/mysqld.pid \u0026ndash;socket=/var/run/mysqld/mysqld.sock \u0026ndash;port=3306 ######################################################################################### mkdir -p /root/docker/etc/mysql sudo docker run \u0026ndash;name gb28181_mysql -d -p 33006:3306 \u0026ndash;privileged=true -v /home/docker/root/etc/mysql:/etc/mysql -v /home/docker/root/var/lib/mysql:/var/lib/mysql -e MYSQL_PASS=\u0026ldquo;root\u0026rdquo; tutum/mysql docker exec -ti 7b3b /bin/bash\n/etc/mysql/my.cnf #lower_case_table_names=1 #  mysql grant all privileges on . to root@\u0026quot;%\u0026quot; identified by \u0026ldquo;root\u0026rdquo; with grant option; flush privileges; mysql -h 127.0.0.1 -uroot -proot -P 33006\n"});index.add({'id':5,'href':'/posts/yum-manual/','title':"yum manual",'section':"Posts",'content':"下载包以及依赖包离线安装 yum install yum-utils yumdownloader \u0026ndash;resolve \u0026ndash;destdir /home/z/myrpm/ mariadb-server\n"});index.add({'id':6,'href':'/posts/systemd-manual/','title':"systemd manual",'section':"Posts",'content':"使用脚本启动主程序，在使用systemd时，需要删除nohup启动，切保证启动脚本中不会报错。\n参考 http://www.jinbuguo.com/systemd/systemd.index.html http://www.ruanyifeng.com/blog/2016/03/systemd-tutorial-part-two.html\ncp test.service /usr/lib/systemd/system\nsystemctl daemon-reload systemctl enable test systemctl start test systemctl disable test systemctl stop test systemctl restart test systemctl reload test\ntest.service [Unit] Description= Documentation= After=network.target Wants=\n[Service] #EnvironmentFile= WorkingDirectory=/home/z/Workspace/systemd/ ExecStart=/bin/bash /home/z/Workspace/systemd/start.sh\nsimple fork oneshot #  Type=simple\ncontrol-group process mixed none #  KillMode= control-group #  RemainAfterExit=yes 进程退出后服务仍然执行 #  on-success on-failure always on #  Restart=always RestartSec=10s\n[Install] WantedBy=multi-user.target\n"});index.add({'id':7,'href':'/posts/crontab-manual/','title':"crontab manual",'section':"Posts",'content':"参考: https://www.cnblogs.com/longjshz/p/5779215.html\ncrontab -u root -e 59 18 * * * root /sbin/poweroff\n注意：命令和脚本名要使用完整路径\n"});index.add({'id':8,'href':'/posts/openssl-ca-make/','title':"openssl ca make",'section':"Posts",'content':"简单版 #  自签名证书 原文链接：https://blog.csdn.net/zheyiw/article/details/88909697\n1，自制CA私钥 openssl genrsa -des3 -out ca.key 4096 2，自制CA证书 openssl req -new -x509 -days 3650 -key ca.key -out ca.crt\n3，自制Server私钥，生成免密码版本 openssl genrsa -des3 -out server.key 4096 openssl rsa -in server.key -out server.nosecret.key 4，制作csr文件 openssl req -new -key server.key -out server.csr 5，用CA证书私钥对csr签名（CA不能用X509，这点需要注意）生成Server证书 openssl ca -days 3650 -in server.csr -cert ca.crt -keyfile ca.key -out server.crt\n提示文件打开失败可以参考以下指令 sudo mkdir /etc/ssl/newcerts touch /etc/ssl/index.txt touch /etc/ssl/serial echo \u0026ldquo;01\u0026rdquo; \u0026gt; /etc/ssl/serial echo \u0026ldquo;01\u0026rdquo; \u0026gt; /etc/ssl/index.txt\n"});index.add({'id':9,'href':'/posts/firewalld-manual/','title':"firewalld manual",'section':"Posts",'content':"from https://www.cnblogs.com/xxoome/p/7115614.html\n1、查看firewall服务状态\nsystemctl status firewalld\n2、查看firewall的状态\nfirewall-cmd \u0026ndash;state\n3、开启、重启、关闭、firewalld.service服务\n开启 #  service firewalld start\n重启 #  service firewalld restart\n关闭 #  service firewalld stop 4、查看防火墙规则\nfirewall-cmd \u0026ndash;list-all\n查询端口是否开放 #  firewall-cmd \u0026ndash;query-port=8080/tcp\n开放80端口 #  firewall-cmd \u0026ndash;permanent \u0026ndash;add-port=80/tcp\n移除端口 #  firewall-cmd \u0026ndash;permanent \u0026ndash;remove-port=8080/tcp\n#重启防火墙(修改配置后要重启防火墙) firewall-cmd \u0026ndash;reload\n参数解释 #  1、firwall-cmd：是Linux提供的操作firewall的一个工具； 2、\u0026ndash;permanent：表示设置为持久； 3、\u0026ndash;add-port：标识添加的端口；\n"});index.add({'id':10,'href':'/posts/bash-shell-manual/','title':"bash shell manual",'section':"Posts",'content':" 删除  清空屏幕, \u0026lt;ctrl+e\u0026gt; 光标跳至命令结尾 \u0026lt;ctrl+a\u0026gt; 光标跳至命令开始 \u0026lt;ctrl+b\u0026gt; 光标左移一个字母 \u0026lt;ctrl+f\u0026gt; 光标右移一个字母 \u0026lt;ctrl+t\u0026gt; 交换光标位置前的两个字符 \u0026lt;ctrl+h\u0026gt; 删除光标前一个字符 \u0026lt;ctrl+w\u0026gt; 移除光标前的一个单词 \u0026lt;ctrl+u\u0026gt; 清除光标前至行首间的所有内容 \u0026lt;ctrl+k\u0026gt; 清除光标后至行尾的内容 \u0026lt;ctrl+y\u0026gt; 粘贴或者恢复上次的删除 \u0026lt;ctrl+p\u0026gt; 前一个命令 \u0026lt;ctrl+n\u0026gt; 后一个命令 \u0026lt;ctrl+r\u0026gt; 历史命令搜索  中断当前的命令并返回Shell  中断当前的通信或从文件中退出 \u0026lt;ctrl+z\u0026gt; 暂停当前进程bg后台运行,fg转到前台\nwhile [ 1 ]; do sleep 1; ll; done # 无限循环 while [ $i -lt 10 ]; do echo $i;let \u0026ldquo;i=$i+1\u0026rdquo;; done # 有限循环 cat raw.txt | while read line; do echo $line; done # readline until [ 1 = 0 ]; do sleep 1; ll; done # 无限循环 for i in /media/m* ; do ls -l $i; done # 与目录资源结合 if [ 1 -eq 1 ]; then ll ;fi # test常用判断 if [[ 0 -eq 0 \u0026amp;\u0026amp; 1 -eq 0 ]]; then ll ;fi if [ 0 -eq 0 -a 1 -eq 0 ]; then ll ;fi if [ ! -e /tmp/111 -a -z \u0026ldquo;$a\u0026rdquo; ]; then ll ;fi # 不存在111文件 且a变量长度为0 则执行ll\nps -ef | grep java | grep -v eclipse # 查看进程，筛选出java的，排除eclipse的 echo \u0026lsquo;a:b:c\u0026rsquo; | tr -s \u0026lsquo;:\u0026rsquo; \u0026lsquo;\u0026rsquo; # 替换字符:为，输出 abc echo \u0026lsquo;a:b:c\u0026rsquo; | awk -F \u0026lsquo;:\u0026rsquo; \u0026lsquo;{print $1 \u0026ldquo;+\u0026rdquo; $3 \u0026ldquo;+\u0026rdquo; $2}\u0026rsquo; # 按:切分后，按下标调整顺序，空格分割输出。a+c+b awk -F':' \u0026lsquo;{print $1}\u0026rsquo; temp2.log | awk \u0026lsquo;{ arr[$1]++ } END { for( no in arr) { print no , arr[no] } }\u0026rsquo; | sort -n -t\u0026quot; \u0026quot; -k 2 -r # 一句话实现group by grep -rn \u0026lsquo;ReturnMessageListCount\u0026rsquo; info.log | awk -F\u0026quot;|\u0026quot; \u0026lsquo;$3 ==11 {print $0 }\u0026rsquo; echo \u0026lsquo;a:b:c\u0026rsquo; | sed -e \u0026rsquo;s#:##g' # 替换字符:为，输出 abc zgrep \u0026quot; body size \u0026quot; push-receipt-service-info.1.log.gz | awk \u0026lsquo;{sum+=$NF}END{print sum}\u0026rsquo; 不解压过滤文本 sed -i \u0026rsquo;s/^[^{]*//g' 文件 #去除从行首到第一个{之前的字符。\nsudo su admin # 切换为admin身份 sudo -u admin kill -9 xxx # 以admin身份执行kill命令 zip -9 -p haha -r bak.zip src # 以9级压缩比、haha为密码，压缩src目录，压缩后的文件是bak.zip gunzip FileName.gz #解压缩\n"});index.add({'id':11,'href':'/posts/archlinux-manual/','title':"archlinux manual",'section':"Posts",'content':"GPT分区 + GRUB + BIOS启动 https://www.jianshu.com/p/be0f47f376b1\n"});index.add({'id':12,'href':'/posts/PyQt5-%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/','title':"PyQt5 使用笔记",'section':"Posts",'content':"文件对话\ndirectory1 = QFileDialog.getExistingDirectory(self, \u0026#34;选取文件夹\u0026#34;, \u0026#34;C:/\u0026#34;) #起始路径 fileName1, filetype = QFileDialog.getOpenFileName(self, \u0026#34;选取文件\u0026#34;, \u0026#34;C:/\u0026#34;, \u0026#34;All Files (*);;Text Files (*.txt)\u0026#34;) #设置文件扩展名过滤,注意用双分号间隔 files, ok1 = QFileDialog.getOpenFileNames(self, \u0026#34;多文件选择\u0026#34;, \u0026#34;C:/\u0026#34;, \u0026#34;All Files (*);;Text Files (*.txt)\u0026#34;) fileName2, ok2 = QFileDialog.getSaveFileName(self, \u0026#34;文件保存\u0026#34;, \u0026#34;C:/\u0026#34;, \u0026#34;All Files (*);;Text Files (*.txt)\u0026#34;) "});index.add({'id':13,'href':'/posts/Django%E7%AC%94%E8%AE%B0/','title':"Django笔记",'section':"Posts",'content':"python manage.py migrate python manage.py createsuperuser\n"});index.add({'id':14,'href':'/posts/Python%E7%AC%94%E8%AE%B0/','title':"Python笔记",'section':"Posts",'content':"##多线程\nCPython的实现中因为GIL的存在，Python的多线程实际上是单线程。multiprocessing包用于多进程处理，但此进程是系统级的进程。\nfrom multiprocessing import Pool import random,time def work(i): print(i) time.sleep((random.random()*0.5)) print(i[0],i[1]) if __name__ == \u0026#34;__main__\u0026#34;: print(\u0026#39;start\u0026#39;) data = [(\u0026#39;a\u0026#39;,2),(\u0026#39;b\u0026#39;,3),(\u0026#39;c\u0026#39;,4)] # 第一种用法 p = Pool(2) for x in p.imap(work, data): pass print(\u0026#39;done\u0026#39;) # 第二种用法 p0 = Pool(2) p0.map_async(work,data) p0.close() # pool无法再放入进程，pool内进程执行完成后销毁 # p0.terminate() 直接销毁进程池  p0.join() # 第三种用法 print(\u0026#39;map_async_done\u0026#39;) p1 = Pool(2) p1.apply_async(func=work,args=((1,2),)) p1.close() # p1.terminate() p1.join() print(\u0026#39;done\u0026#39;) jupyter-notobook #  展示二进制图片\nfrom IPython.display import Image,display display(Image(data=)) "});index.add({'id':15,'href':'/posts/manjaro-manual/','title':"manjaro- manual",'section':"Posts",'content':"修改软件源 sudo pacman-mirrors -i -c China -m rank sudo pacman -Syyu 打开pamac-manager，开启aur\n安装中文字体，否则有些程序会乱码（比如wps，vlc） pacman -S wqy-zenhei ttf-fireflysung\n安装输入法 sudo pacman -S fcitx-im #默认全部安装 sudo pacman -S fcitx-configtool sudo pacman -S fcitx-sogoupinyin sudo nano ~/.xprofile\nexport GTK_IM_MODULE=fcitx\rexport QT_IM_MODULE=fcitx\rexport XMODIFIERS=\u0026quot;@im=fcitx\u0026quot;\r 用户目录改英文 export LANG=en_US xdg-user-dirs-gtk-update export LANG=zh_CN\noh-my-zsh chsh -s /bin/zsh sh -c \u0026ldquo;$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\u0026quot;\ncp ~/.oh-my-zsh/templates/zshrc.zsh-template ~/.zshrc git clone https://github.com/zsh-users/zsh-autosuggestions ~/.oh-my-zsh/plugins/zsh-autosuggestions git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ~/.oh-my-zsh/plugins/zsh-syntax-highlighting\nvim ~/.zshrc plugins=( git zsh-syntax-highlighting zsh-autosuggestions )\nsource ~/.zshrc\n修改字体优先级 /etc/fonts/conf.d/65-nonlatin.conf\n清除Gnome占用IDEA的快捷键 Ctrl + Alt + Left gsettings get org.gnome.desktop.wm.keybindings switch-to-workspace-left ['Left']\n"});index.add({'id':16,'href':'/posts/MicroPython-With-ESP32/','title':"MicroPython With ESP32",'section':"Posts",'content':"install esptool #  pip install esptool sudo esptool.py \u0026ndash;chip esp32 \u0026ndash;port /dev/ttyUSB0 erase_flash #download fireware http://www.micropython.org/download#esp32 sudo esptool.py \u0026ndash;chip esp32 \u0026ndash;port /dev/ttyUSB0 write_flash -z 0x1000 ~/install/esp32-20190707-v1.11-126-g7c2e83324.bin picocom -b 115200 /dev/ttyUSB0\ninstall emp-ide #  http://www.1zlab.com/wiki/micropython-esp32/emp-ide-userguide/\ncode example #  import network wifi = network.WLAN(network.STA_IF) wifi.active(True) wifi.connect(\u0026#39;zzz\u0026#39;, \u0026#39;zhangxin\u0026#39;) import upip upip.install(\u0026#39;emp-1zlab\u0026#39;) from emp_boot import set_boot_mode set_boot_mode() #led from machine import Pin import time led = Pin(16, Pin.OUT) c = 10 while (c \u0026gt; 0): print(c) c -= 1 print(\u0026#34;on\u0026#34;) led.value(0) time.sleep(0.5) print(\u0026#34;off\u0026#34;) led.value(1) time.sleep(0.5) #lcd from machine import Pin, I2C i2c = I2C(scl=Pin(4), sda=Pin(5)) from ssd1306 import SSD1306_I2C oled = SSD1306_I2C(128, 64, i2c) oled.fill(1) oled.show() oled.fill(0) oled.show() oled.pixel(50, 50, 1) oled.show() oled.pixel(127, 63, 1) oled.show() oled.text(\u0026#39;Hello\u0026#39;, 0, 0) oled.text(\u0026#39;World\u0026#39;, 0, 10) oled.show() import math i = 0 c = 120 while (i \u0026lt; c): print(i) i += 1 oled.pixel(i+10, int(math.sin(i/3.1415926)*8+50) ,1) oled.show() oled.invert(True) oled.invert(False) #ssd1306 # MicroPython SSD1306 OLED driver, I2C and SPI interfaces import time import framebuf # register definitions SET_CONTRAST = const(0x81) SET_ENTIRE_ON = const(0xa4) SET_NORM_INV = const(0xa6) SET_DISP = const(0xae) SET_MEM_ADDR = const(0x20) SET_COL_ADDR = const(0x21) SET_PAGE_ADDR = const(0x22) SET_DISP_START_LINE = const(0x40) SET_SEG_REMAP = const(0xa0) SET_MUX_RATIO = const(0xa8) SET_COM_OUT_DIR = const(0xc0) SET_DISP_OFFSET = const(0xd3) SET_COM_PIN_CFG = const(0xda) SET_DISP_CLK_DIV = const(0xd5) SET_PRECHARGE = const(0xd9) SET_VCOM_DESEL = const(0xdb) SET_CHARGE_PUMP = const(0x8d) class SSD1306: def __init__(self, width, height, external_vcc): self.width = width self.height = height self.external_vcc = external_vcc self.pages = self.height // 8 # Note the subclass must initialize self.framebuf to a framebuffer. # This is necessary because the underlying data buffer is different # between I2C and SPI implementations (I2C needs an extra byte). self.poweron() self.init_display() def init_display(self): for cmd in ( SET_DISP | 0x00, # off # address setting SET_MEM_ADDR, 0x00, # horizontal # resolution and layout SET_DISP_START_LINE | 0x00, SET_SEG_REMAP | 0x01, # column addr 127 mapped to SEG0 SET_MUX_RATIO, self.height - 1, SET_COM_OUT_DIR | 0x08, # scan from COM[N] to COM0 SET_DISP_OFFSET, 0x00, SET_COM_PIN_CFG, 0x02 if self.height == 32 else 0x12, # timing and driving scheme SET_DISP_CLK_DIV, 0x80, SET_PRECHARGE, 0x22 if self.external_vcc else 0xf1, SET_VCOM_DESEL, 0x30, # 0.83*Vcc # display SET_CONTRAST, 0xff, # maximum SET_ENTIRE_ON, # output follows RAM contents SET_NORM_INV, # not inverted # charge pump SET_CHARGE_PUMP, 0x10 if self.external_vcc else 0x14, SET_DISP | 0x01): # on self.write_cmd(cmd) self.fill(0) self.show() def poweroff(self): self.write_cmd(SET_DISP | 0x00) def contrast(self, contrast): self.write_cmd(SET_CONTRAST) self.write_cmd(contrast) def invert(self, invert): self.write_cmd(SET_NORM_INV | (invert \u0026amp; 1)) def show(self): x0 = 0 x1 = self.width - 1 if self.width == 64: # displays with width of 64 pixels are shifted by 32 x0 += 32 x1 += 32 self.write_cmd(SET_COL_ADDR) self.write_cmd(x0) self.write_cmd(x1) self.write_cmd(SET_PAGE_ADDR) self.write_cmd(0) self.write_cmd(self.pages - 1) self.write_framebuf() def fill(self, col): self.framebuf.fill(col) def pixel(self, x, y, col): self.framebuf.pixel(x, y, col) def scroll(self, dx, dy): self.framebuf.scroll(dx, dy) def text(self, string, x, y, col=1): self.framebuf.text(string, x, y, col) class SSD1306_I2C(SSD1306): def __init__(self, width, height, i2c, addr=0x3c, external_vcc=False): self.i2c = i2c self.addr = addr self.temp = bytearray(2) # Add an extra byte to the data buffer to hold an I2C data/command byte # to use hardware-compatible I2C transactions. A memoryview of the # buffer is used to mask this byte from the framebuffer operations # (without a major memory hit as memoryview doesn\u0026#39;t copy to a separate # buffer). self.buffer = bytearray(((height // 8) * width) + 1) self.buffer[0] = 0x40 # Set first byte of data buffer to Co=0, D/C=1 self.framebuf = framebuf.FrameBuffer1(memoryview(self.buffer)[1:], width, height) super().__init__(width, height, external_vcc) def write_cmd(self, cmd): self.temp[0] = 0x80 # Co=1, D/C#=0 self.temp[1] = cmd self.i2c.writeto(self.addr, self.temp) def write_framebuf(self): # Blast out the frame buffer using a single I2C transaction to support # hardware I2C interfaces. self.i2c.writeto(self.addr, self.buffer) def poweron(self): pass class SSD1306_SPI(SSD1306): def __init__(self, width, height, spi, dc, res, cs, external_vcc=False): self.rate = 10 * 1024 * 1024 dc.init(dc.OUT, value=0) res.init(res.OUT, value=0) cs.init(cs.OUT, value=1) self.spi = spi self.dc = dc self.res = res self.cs = cs self.buffer = bytearray((height // 8) * width) self.framebuf = framebuf.FrameBuffer1(self.buffer, width, height) super().__init__(width, height, external_vcc) def write_cmd(self, cmd): self.spi.init(baudrate=self.rate, polarity=0, phase=0) self.cs.high() self.dc.low() self.cs.low() self.spi.write(bytearray([cmd])) self.cs.high() def write_framebuf(self): self.spi.init(baudrate=self.rate, polarity=0, phase=0) self.cs.high() self.dc.high() self.cs.low() self.spi.write(self.buffer) self.cs.high() def poweron(self): self.res.high() time.sleep_ms(1) self.res.low() time.sleep_ms(10) self.res.high() "});index.add({'id':17,'href':'/posts/CGO-%E8%B5%84%E6%96%99%E6%94%B6%E9%9B%86/','title':"CGO 资料收集",'section':"Posts",'content':"go通过swig封装、调用c++共享库的技术总结 https://www.cnblogs.com/terencezhou/p/10059156.html\n"});index.add({'id':18,'href':'/posts/%E9%98%B2%E6%AD%A2SSH%E6%9A%B4%E5%8A%9B%E6%94%BB%E5%87%BB/','title':"防止SSH暴力攻击",'section':"Posts",'content':"解除登录限制 #  #!/bin/bash  IP=$1 if [ -n \u0026#34;$IP\u0026#34; ];then if [[ $IP =~ ^[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}$ ]];then service denyhosts stop sed -i \u0026#34;/$IP/d\u0026#34; /etc/hosts.deny sed -i \u0026#34;/$IP/d\u0026#34; /var/lib/denyhosts/hosts-valid sed -i \u0026#34;/$IP/d\u0026#34; /var/lib/denyhosts/users-hosts sed -i \u0026#34;/$IP/d\u0026#34; /var/lib/denyhosts/hosts sed -i \u0026#34;/$IP/d\u0026#34; /var/lib/denyhosts/hosts-root sed -i \u0026#34;/$IP/d\u0026#34; /var/lib/denyhosts/hosts-restricted iptables -D INPUT -s $IP -j DROP echo $IP remove from Denyhosts service denyhosts start else echo \u0026#34;This is not IP\u0026#34; fi else echo \u0026#34;IP is empty\u0026#34; fi 记录登录日志 #  vim /etc/ssh/sshd_config SyslogFacility AUTHPRIV LogLevel INFO\n[DenyHosts 阻止SSH暴力攻击][1]http://blog.csdn.net/wanglei_storage/article/details/50849070\n"});index.add({'id':19,'href':'/posts/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%AD%E7%9A%84%E6%A0%91/','title':"数据结构中的树",'section':"Posts",'content':"###二叉树\n 每个父节点只能有两个子节点 ###二叉搜索树   二叉搜索树，既能像顺序数组一样进行二叉搜索，又能像链表一样在数据中间自由插入新数据\n  每个父节点只能有两个子节点 左节点\u0026lt;父节点\u0026lt;右节点 ###AVL树   AVL树保持自平衡，防止因数据偏斜到使树退化成链表的情况。\n  每个父节点只能有两个子节点 左节点\u0026lt;父节点\u0026lt;右节点 任意叶子节点到根节点的高度不能相差超过1  ###红黑树\n 红黑树在保持自平衡的基础上减少了旋转操作，红黑树需要把树加载到内存。\n  节点可以是黑色或红色 根节点和叶子节点是黑色 红色节点的子节点是黑色 任意叶子节点到根节点的最短路径上的黑色节点数量一致  ###B—树\n 用于MongoDB这样的KV数据库\n  每个节点都存数据地址，一个节点可有不止一个key 可能在根节点就查到了数据，也可能遍历到叶子才查到数据，查询效率不稳定，但整体查询效率比B+树更高。   ###B+树\n 常用于文件系统和关系型数据库系统\n  只有最下方的叶子节点可以存数据的地址 B+树呈矮胖形态，查询到叶子节点通常需要3~4次IO 每次查找都要查询到叶子节点，查找效率稳定 叶子节点之间按链表形式连接，方便遍历和区间查找 磁盘每个区块512Byte，文件系统一个族为4K、8K、16K，文件系统一次IO取一个族。一个节点的容量安排为4K，有助于减少IO次数。  疑问❓ 为什么mongodb和mysql分别用B树和B+树？\n"});index.add({'id':20,'href':'/posts/SSH%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C%E7%AC%94%E8%AE%B0/','title':"SSH相关操作笔记",'section':"Posts",'content':" ssh登录 ssh root@localhost ssh -l root -p 22 localhost ssh免密码登录 ssh-keygen ssh-copy-id -i ~/.ssh/id_rsa.pub root@localhost 复制文件 scp root@localhsot:/root/hello.zip ~/hello.zip  "});index.add({'id':21,'href':'/posts/Python%E5%AE%9E%E4%BE%8B%E6%89%8B%E5%86%8C/','title':"Python实例手册",'section':"Posts",'content':"Python实例手册\r #encoding:utf8\n设定编码-支持中文 #  0说明\n手册制作: 雪松 littlepy reboot\r更新日期: 2014-10-29\r欢迎系统运维加入Q群: 198173206 # 加群请回答问题\r欢迎运维开发加入Q群: 365534424 # 不定期技术分享\r请使用\u0026quot;notepad++\u0026quot;打开此文档,\u0026quot;alt+0\u0026quot;将函数折叠后方便查阅\r请勿删除信息，转载请说明出处，抵制不道德行为。\r错误在所难免，还望指正！\r# python实例手册下载地址:\rhttp://hi.baidu.com/quanzhou722/item/cf4471f8e23d3149932af2a7\r# shell实例手册最新下载地址:\rhttp://hi.baidu.com/quanzhou722/item/f4a4f3c9eb37f02d46d5c0d9\r# LazyManage运维批量管理软件下载[shell]:\rhttp://hi.baidu.com/quanzhou722/item/4ccf7e88a877eaccef083d1a\r# LazyManage运维批量管理软件下载[python]:\rhttp://hi.baidu.com/quanzhou722/item/4213db3626a949fe96f88d3c\r 1 基础\n查看帮助\rimport os\rfor i in dir(os):\rprint i # 模块的方法\rhelp(os.path) # 方法的帮助\r调试\rpython -m trace -t aaaaaa.py\rpip模块安装\ryum install python-pip # centos安装pip\rsudo apt-get install python-pip # ubuntu安装pip\rpip官方安装脚本\rwget https://raw.github.com/pypa/pip/master/contrib/get-pip.py\rpython get-pip.py\r加载环境变量\rvim /etc/profile\rexport PATH=/usr/local/python27/bin:$PATH\r. /etc/profile\rpip install Package # 安装包 pip install requests\rpip show --files Package # 查看安装包时安装了哪些文件\rpip show --files Package # 查看哪些包有更新\rpip install --upgrade Package # 更新一个软件包\rpip uninstall Package # 卸载软件包\r变量\rr=r'\\n' # 输出时原型打印\ru=u'中文' # 定义为unicode编码\rglobal x # 全局变量\ra = 0 or 2 or 1 # 布尔运算赋值,a值为True既不处理后面,a值为2. None、字符串''、空元组()、空列表[],空字典{}、0、空字符串都是false\rname = raw_input(\u0026quot;input:\u0026quot;).strip() # 输入字符串变量\rnum = int(raw_input(\u0026quot;input:\u0026quot;).strip()) # 输入字符串str转为int型\rlocals() # 所有局部变量组成的字典\rlocals().values() # 所有局部变量值的列表\ros.popen(\u0026quot;date -d @{0} +'%Y-%m-%d %H:%M:%S'\u0026quot;.format(12)).read() # 特殊情况引用变量 {0} 代表第一个参数\r打印\r# 字符串 %s 整数 %d 浮点 %f 原样打印 %r\rprint '字符串: %s 整数: %d 浮点: %f 原样打印: %r' % ('aa',2,1.0,'r')\rprint 'abc', # 有逗号,代表不换行打印,在次打印会接着本行打印\r列表\r# 列表元素的个数最多 536870912\rshoplist = ['apple', 'mango', 'carrot', 'banana']\rshoplist[2] = 'aa'\rdel shoplist[0]\rshoplist.insert('4','www')\rshoplist.append('aaa')\rshoplist[::-1] # 倒着打印 对字符翻转串有效\rshoplist[2::3] # 从第二个开始每隔三个打印\rshoplist[:-1] # 排除最后一个\r'\\t'.join(li) # 将列表转换成字符串\rsys.path[1:1]=[5] # 在位置1前面插入列表中一个值\rlist(set(['qwe', 'as', '123', '123'])) # 将列表通过集合去重复\reval(\u0026quot;['1','a']\u0026quot;) # 将字符串当表达式求值,得到列表\r元组\r# 不可变\rzoo = ('wolf', 'elephant', 'penguin')\r字典\rab = { 'Swaroop' : 'swaroopch@byteofpython.info',\r'Larry' : 'larry@wall.org',\r}\rab['c'] = 80 # 添加字典元素\rdel ab['Larry'] # 删除字典元素\rab.keys() # 查看所有键值\rab.values() # 打印所有值\rab.has_key('a') # 查看键值是否存在\rab.items() # 返回整个字典列表\r复制字典\ra = {1: {1: 2, 3: 4}}\rb = a b[1][1] = 8888 # a和b都为 {1: {1: 8888, 3: 4}}\rimport copy\rc = copy.deepcopy(a) # 再次赋值 b[1][1] = 9999 拷贝字典为新的字典,互不干扰\ra[2] = copy.deepcopy(a[1]) # 复制出第二个key，互不影响 {1: {1: 2, 3: 4},2: {1: 2, 3: 4}}\r流程结构\rif判断\r# 布尔值操作符 and or not 实现多重判断\rif a == b:\rprint '=='\relif a \u0026lt; b:\rprint b\relse:\rprint a\rfi\rwhile循环\rwhile True:\rif a == b:\rprint \u0026quot;==\u0026quot;\rbreak\rprint \u0026quot;!=\u0026quot;\relse:\rprint 'over'\rcount=0\rwhile(count\u0026lt;9):\rprint count\rcount += 1\rfor循环\rsorted() # 返回一个序列(列表)\rzip() # 返回一个序列(列表)\renumerate() # 返回循环列表序列 for i,v in enumerate(['a','b']):\rreversed() # 反序迭代器对象\rdict.iterkeys() # 通过键迭代\rdict.itervalues() # 通过值迭代\rdict.iteritems() # 通过键-值对迭代\rrandline() # 文件迭代\riter(obj) # 得到obj迭代器 检查obj是不是一个序列\riter(a,b) # 重复调用a,直到迭代器的下一个值等于b\rfor i in range(1, 5):\rprint i\relse:\rprint 'over'\rlist = ['a','b','c','b']\rfor i in range(len(list)):\rprint list[i]\rfor x, Lee in enumerate(list):\rprint \u0026quot;%d %s Lee\u0026quot; % (x+1,Lee)\r# enumerate 使用函数得到索引值和对应值\rfor i, v in enumerate(['tic', 'tac', 'toe']):\rprint(i, v)\r流程结构简写\r[ i * 2 for i in [8,-2,5]]\r[16,-4,10]\r[ i for i in range(8) if i %2 == 0 ]\r[0,2,4,6]\rtab补全\r# vim /usr/lib/python2.7/dist-packages/tab.py\r# python startup file\rimport sys\rimport readline\rimport rlcompleter\rimport atexit\rimport os\r# tab completion\rreadline.parse_and_bind('tab: complete')\r# history file\rhistfile = os.path.join(os.environ['HOME'], '.pythonhistory')\r函数\rdef printMax(a, b = 1):\rif a \u0026gt; b:\rprint a\rreturn a\relse:\rprint b\rreturn b\rx = 5\ry = 7\rprintMax(x, y)\rdef update(*args,**kwargs):\rp=''\rfor i,t in kwargs.items():\rp = p+ '%s=%s,' %(i,str(t))\rsql = \u0026quot;update 'user' set (%s) where (%s)\u0026quot; %(args[0],p)\rprint sql\rupdate('aaa',uu='uu',id=3)\r模块\r# Filename: mymodule.py\rdef sayhi():\rprint 'mymodule'\rversion = '0.1'\r# 使用模块中方法\rimport mymodule\rfrom mymodule import sayhi, version\rmymodule.sayhi() # 使用模块中函数方法\r类对象的方法\rclass Person:\r# 实例化初始化的方法\rdef __init__(self, name ,age):\rself.name = name\rself.age = age\rprint self.name\r# 有self此函数为方法\rdef sayHi(self):\rprint 'Hello, my name is', self.name\r# 对象消逝的时候被调用\rdef __del__(self):\rprint 'over'\r# 实例化对象\rp = Person('Swaroop')\r# 使用对象方法\rp.sayHi()\r# 继承\rclass Teacher(Person):\rdef __init__(self, name, age, salary):\rPerson.__init__(self, name, age)\rself.salary = salary\rprint '(Initialized Teacher: %s)' % self.name\rdef tell(self):\rPerson.tell(self)\rprint 'Salary: \u0026quot;%d\u0026quot;' % self.salary\rt = Teacher('Mrs. Shrividya', 40, 30000)\r执行模块类中的所有方法\r# moniItems.py\rimport sys, time\rimport inspect\rclass mon:\rdef __init__(self, n):\rself.name = n\rself.data = dict()\rdef run(self):\rprint 'hello', self.name\rreturn self.runAllGet()\rdef getDisk(self):\rreturn 222\rdef getCpu(self):\rreturn 111\rdef runAllGet(self):\rfor fun in inspect.getmembers(self, predicate=inspect.ismethod):\rprint fun[0], fun[1]\rif fun[0][:3] == 'get':\rself.data[fun[0][3:]] = fun[1]()\rprint self.data\rreturn self.data\r# 模块导入使用\rfrom moniItems import mon\rm = mon()\rm.runAllGet()\r文件处理\r# 模式: 读'r' 写[清空整个文件]'w' 追加[文件需要存在]'a' 读写'r+' 二进制文件'b' 'rb','wb','rb+'\r写文件\ri={'ddd':'ccc'}\rf = file('poem.txt', 'a') f.write(\u0026quot;string\u0026quot;)\rf.write(str(i))\rf.flush()\rf.close()\r读文件\rf = file('/etc/passwd','r')\rc = f.read().strip() # 读取为一个大字符串，并去掉最后一个换行符\rfor i in c.spilt('\\n'): # 用换行符切割字符串得到列表循环每行\rprint i\rf.close()\r读文件1\rf = file('/etc/passwd','r')\rwhile True:\rline = f.readline() # 返回一行\rif len(line) == 0:\rbreak\rx = line.split(\u0026quot;:\u0026quot;) # 冒号分割定义序列\r#x = [ x for x in line.split(\u0026quot;:\u0026quot;) ] # 冒号分割定义序列\r#x = [ x.split(\u0026quot;/\u0026quot;) for x in line.split(\u0026quot;:\u0026quot;) ] # 先冒号分割,在/分割 打印x[6][1]\rprint x[6],\u0026quot;\\n\u0026quot;,\rf.close() 读文件2\rf = file('/etc/passwd')\rc = f.readlines() # 读入所有文件内容,可反复读取,大文件时占用内存较大\rfor line in c:\rprint line.rstrip(),\rf.close()\r读文件3\rfor i in open('b.txt'): # 直接读取也可迭代,并有利于大文件读取,但不可反复读取\rprint i,\r追加日志\rlog = open('/home/peterli/xuesong','a')\rprint \u0026gt;\u0026gt; log,'faaa'\rlog.close()\rwith读文件\rwith open('a.txt') as f:\rfor i in f:\rprint i\rprint f.read() # 打印所有内容为字符串\rprint f.readlines() # 打印所有内容按行分割的列表\rcsv读配置文件 192.168.1.5,web # 配置文件按逗号分割\rlist = csv.reader(file('a.txt'))\rfor line in list:\rprint line # ['192.168.1.5', 'web']\r内建函数\rdir(sys) # 显示对象的属性\rhelp(sys) # 交互式帮助\rint(obj) # 转型为整形\rstr(obj) # 转为字符串\rlen(obj) # 返回对象或序列长度\ropen(file,mode) # 打开文件 #mode (r 读,w 写, a追加)\rrange(0,3) # 返回一个整形列表\rraw_input(\u0026quot;str:\u0026quot;) # 等待用户输入\rtype(obj) # 返回对象类型\rabs(-22) # 绝对值\rrandom # 随机数\rchoice() # 随机返回给定序列的一个元素\rdivmod(x,y) # 函数完成除法运算，返回商和余数。\rround(x[,n]) # 函数返回浮点数x的四舍五入值，如给出n值，则代表舍入到小数点后的位数\rstrip() # 是去掉字符串两端多于空格,该句是去除序列中的所有字串两端多余的空格\rdel # 删除列表里面的数据\rcmp(x,y) # 比较两个对象 #根据比较结果返回一个整数，如果x\u0026lt;y，则返回-1；如果x\u0026gt;y，则返回1,如果x==y则返回0\rmax() # 字符串中最大的字符\rmin() # 字符串中最小的字符\rsorted() # 对序列排序\rreversed() # 对序列倒序\renumerate() # 返回索引位置和对应的值\rsum() # 总和\rlist() # 变成列表可用于迭代\reval('3+4') # 将字符串当表达式求值 得到7\rexec 'a=100' # 将字符串按python语句执行\rexec(a+'=new') # 将变量a的值作为新的变量\rtuple() # 变成元组可用于迭代 #一旦初始化便不能更改的数据结构,速度比list快\rzip(s,t) # 返回一个合并后的列表 s = ['11','22'] t = ['aa','bb'] [('11', 'aa'), ('22', 'bb')]\risinstance(object,int) # 测试对象类型 int xrange([lower,]stop[,step]) # 函数与range()类似，但xrnage()并不创建列表，而是返回一个xrange对象\r字符串相关模块\rstring # 字符串操作相关函数和工具\rre # 正则表达式\rstruct # 字符串和二进制之间的转换\rc/StringIO # 字符串缓冲对象,操作方法类似于file对象\rbase64 # Base16\\32\\64数据编解码\rcodecs # 解码器注册和基类\rcrypt # 进行单方面加密\rdifflib # 找出序列间的不同\rhashlib # 多种不同安全哈希算法和信息摘要算法的API\rhma # HMAC信息鉴权算法的python实现\rmd5 # RSA的MD5信息摘要鉴权\rrotor # 提供多平台的加解密服务\rsha # NIAT的安全哈希算法SHA\rstringprep # 提供用于IP协议的Unicode字符串\rtextwrap # 文本包装和填充\runicodedate # unicode数据库\r列表类型内建函数\rlist.append(obj) # 向列表中添加一个对象obj\rlist.count(obj) # 返回一个对象obj在列表中出现的次数\rlist.extend(seq) # 把序列seq的内容添加到列表中\rlist.index(obj,i=0,j=len(list)) # 返回list[k] == obj 的k值,并且k的范围在i\u0026lt;=k\u0026lt;j;否则异常\rlist.insert(index.obj) # 在索引量为index的位置插入对象obj\rlist.pop(index=-1) # 删除并返回指定位置的对象,默认是最后一个对象\rlist.remove(obj) # 从列表中删除对象obj\rlist.reverse() # 原地翻转列表\rlist.sort(func=None,key=None,reverse=False) # 以指定的方式排序列表中成员,如果func和key参数指定,则按照指定的方式比较各个元素,如果reverse标志被置为True,则列表以反序排列\r序列类型操作符\rseq[ind] # 获取下标为ind的元素\rseq[ind1:ind2] # 获得下标从ind1到ind2的元素集合\rseq * expr # 序列重复expr次\rseq1 + seq2 # 连接seq1和seq2\robj in seq # 判断obj元素是否包含在seq中\robj not in seq # 判断obj元素是否不包含在seq中\r字符串类型内建方法\rstring.expandtabs(tabsize=8) # tab符号转为空格 #默认8个空格\rstring.endswith(obj,beg=0,end=len(staring)) # 检测字符串是否已obj结束,如果是返回True #如果beg或end指定检测范围是否已obj结束\rstring.count(str,beg=0,end=len(string)) # 检测str在string里出现次数 f.count('\\n',0,len(f)) 判断文件行数\rstring.find(str,beg=0,end=len(string)) # 检测str是否包含在string中\rstring.index(str,beg=0,end=len(string)) # 检测str不在string中,会报异常\rstring.isalnum() # 如果string至少有一个字符并且所有字符都是字母或数字则返回True\rstring.isalpha() # 如果string至少有一个字符并且所有字符都是字母则返回True\rstring.isnumeric() # 如果string只包含数字字符,则返回True\rstring.isspace() # 如果string包含空格则返回True\rstring.isupper() # 字符串都是大写返回True\rstring.islower() # 字符串都是小写返回True\rstring.lower() # 转换字符串中所有大写为小写\rstring.upper() # 转换字符串中所有小写为大写\rstring.lstrip() # 去掉string左边的空格\rstring.rstrip() # 去掉string字符末尾的空格\rstring.replace(str1,str2,num=string.count(str1)) # 把string中的str1替换成str2,如果num指定,则替换不超过num次\rstring.startswith(obj,beg=0,end=len(string)) # 检测字符串是否以obj开头\rstring.zfill(width) # 返回字符长度为width的字符,原字符串右对齐,前面填充0\rstring.isdigit() # 只包含数字返回True\rstring.split(\u0026quot;分隔符\u0026quot;) # 把string切片成一个列表\r\u0026quot;:\u0026quot;.join(string.split()) # 以:作为分隔符,将所有元素合并为一个新的字符串\r序列类型相关的模块\rarray # 一种受限制的可变序列类型,元素必须相同类型\rcopy # 提供浅拷贝和深拷贝的能力\roperator # 包含函数调用形式的序列操作符 operator.concat(m,n)\rre # perl风格的正则表达式查找\rStringIO # 把长字符串作为文件来操作 如: read() \\ seek()\rcStringIO # 把长字符串作为文件来操,作速度更快,但不能被继承\rtextwrap # 用作包装/填充文本的函数,也有一个类\rtypes # 包含python支持的所有类型\rcollections # 高性能容器数据类型\r字典内建方法\rdict.clear() # 删除字典中所有元素\rdict copy() # 返回字典(浅复制)的一个副本\rdict.fromkeys(seq,val=None) # 创建并返回一个新字典,以seq中的元素做该字典的键,val做该字典中所有键对的初始值\rdict.get(key,default=None) # 对字典dict中的键key,返回它对应的值value,如果字典中不存在此键,则返回default值\rdict.has_key(key) # 如果键在字典中存在,则返回True 用in和not in代替\rdicr.items() # 返回一个包含字典中键、值对元组的列表\rdict.keys() # 返回一个包含字典中键的列表\rdict.iter() # 方法iteritems()、iterkeys()、itervalues()与它们对应的非迭代方法一样,不同的是它们返回一个迭代子,而不是一个列表\rdict.pop(key[,default]) # 和方法get()相似.如果字典中key键存在,删除并返回dict[key]\rdict.setdefault(key,default=None) # 和set()相似,但如果字典中不存在key键,由dict[key]=default为它赋值\rdict.update(dict2) # 将字典dict2的键值对添加到字典dict\rdict.values() # 返回一个包含字典中所有值得列表\rdict([container]) # 创建字典的工厂函数。提供容器类(container),就用其中的条目填充字典\rlen(mapping) # 返回映射的长度(键-值对的个数)\rhash(obj) # 返回obj哈希值,判断某个对象是否可做一个字典的键值\t集合方法\rs.update(t) # 用t中的元素修改s,s现在包含s或t的成员 s |= t\rs.intersection_update(t) # s中的成员是共用属于s和t的元素 s \u0026amp;= t\rs.difference_update(t) # s中的成员是属于s但不包含在t中的元素 s -= t\rs.symmetric_difference_update(t) # s中的成员更新为那些包含在s或t中,但不是s和t共有的元素 s ^= t\rs.add(obj) # 在集合s中添加对象obj\rs.remove(obj) # 从集合s中删除对象obj;如果obj不是集合s中的元素(obj not in s),将引发KeyError错误\rs.discard(obj) # 如果obj是集合s中的元素,从集合s中删除对象obj\rs.pop() # 删除集合s中的任意一个对象,并返回它\rs.clear() # 删除集合s中的所有元素\rs.issubset(t) # 如果s是t的子集,则返回True s \u0026lt;= t\rs.issuperset(t) # 如果t是s的超集,则返回True s \u0026gt;= t\rs.union(t) # 合并操作;返回一个新集合,该集合是s和t的并集 s | t\rs.intersection(t) # 交集操作;返回一个新集合,该集合是s和t的交集 s \u0026amp; t\rs.difference(t) # 返回一个新集合,改集合是s的成员,但不是t的成员 s - t\rs.symmetric_difference(t) # 返回一个新集合,该集合是s或t的成员,但不是s和t共有的成员 s ^ t\rs.copy() # 返回一个新集合,它是集合s的浅复制\robj in s # 成员测试;obj是s中的元素 返回True\robj not in s # 非成员测试:obj不是s中元素 返回True\rs == t # 等价测试 是否具有相同元素\rs != t # 不等价测试 s \u0026lt; t # 子集测试;s!=t且s中所有元素都是t的成员\rs \u0026gt; t # 超集测试;s!=t且t中所有元素都是s的成员\r序列化\r#!/usr/bin/python\rimport cPickle\robj = {'1':['4124','1241','124'],'2':['12412','142','1241']}\rpkl_file = open('account.pkl','wb')\rcPickle.down(obj,pkl_file)\rpkl_file.close()\rpkl_file = open('account.pkl','rb')\raccount_list = cPickle.load(pkl_file)\rpkl_file.close()\r文件对象方法\rfile.close() # 关闭文件\rfile.fileno() # 返回文件的描述符\rfile.flush() # 刷新文件的内部缓冲区\rfile.isatty() # 判断file是否是一个类tty设备\rfile.next() # 返回文件的下一行,或在没有其他行时引发StopIteration异常\rfile.read(size=-1) # 从文件读取size个字节,当未给定size或给定负值的时候,读取剩余的所有字节,然后作为字符串返回\rfile.readline(size=-1) # 从文件中读取并返回一行(包括行结束符),或返回最大size个字符\rfile.readlines(sizhint=0) # 读取文件的所有行作为一个列表返回\rfile.xreadlines() # 用于迭代,可替换readlines()的一个更高效的方法\rfile.seek(off, whence=0) # 在文件中移动文件指针,从whence(0代表文件起始,1代表当前位置,2代表文件末尾)偏移off字节\rfile.tell() # 返回当前在文件中的位置\rfile.truncate(size=file.tell()) # 截取文件到最大size字节,默认为当前文件位置\rfile.write(str) # 向文件写入字符串\rfile.writelines(seq) # 向文件写入字符串序列seq;seq应该是一个返回字符串的可迭代对象\r文件对象的属性\rfile.closed # 表示文件已被关闭,否则为False\rfile.encoding # 文件所使用的编码 当unicode字符串被写入数据时,它将自动使用file.encoding转换为字节字符串;若file.encoding为None时使用系统默认编码\rfile.mode # Access文件打开时使用的访问模式\rfile.name # 文件名\rfile.newlines # 未读取到行分隔符时为None,只有一种行分隔符时为一个字符串,当文件有多种类型的行结束符时,则为一个包含所有当前所遇到的行结束符的列表\rfile.softspace # 为0表示在输出一数据后,要加上一个空格符,1表示不加\r异常处理\r# try 中使用 sys.exit(2) 会被捕获,无法退出脚本,可使用 os._exit(2) 退出脚本\rclass ShortInputException(Exception): # 继承Exception异常的类,定义自己的异常\rdef __init__(self, length, atleast):\rException.__init__(self)\rself.length = length\rself.atleast = atleast\rtry:\rs = raw_input('Enter something --\u0026gt; ')\rif len(s) \u0026lt; 3:\rraise ShortInputException(len(s), 3) # 触发异常\rexcept EOFError:\rprint '\\nWhy did you do an EOF on me?'\rexcept ShortInputException, x: # 捕捉指定错误信息\rprint 'ShortInputException: %d | %d' % (x.length, x.atleast)\rexcept Exception as err: # 捕捉所有其它错误信息内容\rprint str(err)\r#except urllib2.HTTPError as err: # 捕捉外部导入模块的错误\r#except: # 捕捉所有其它错误 不会看到错误内容\r#\tprint 'except'\rfinally: # 无论什么情况都会执行 关闭文件或断开连接等\rprint 'finally' else: # 无任何异常 无法和finally同用\rprint 'No exception was raised.' 不可捕获的异常\rNameError: # 尝试访问一个未申明的变量\rZeroDivisionError: # 除数为零\rSyntaxErrot: # 解释器语法错误\rIndexError: # 请求的索引元素超出序列范围\rKeyError: # 请求一个不存在的字典关键字\rIOError: # 输入/输出错误\rAttributeError: # 尝试访问未知的对象属性\rImportError # 没有模块\rIndentationError # 语法缩进错误\rKeyboardInterrupt # ctrl+C\rSyntaxError # 代码语法错误\rValueError # 值错误\rTypeError # 传入对象类型与要求不符合\r内建异常\rBaseException # 所有异常的基类\rSystemExit # python解释器请求退出\rKeyboardInterrupt # 用户中断执行\rException # 常规错误的基类\rStopIteration # 迭代器没有更多的值\rGeneratorExit # 生成器发生异常来通知退出\rStandardError # 所有的内建标准异常的基类\rArithmeticError # 所有数值计算错误的基类\rFloatingPointError # 浮点计算错误\rOverflowError # 数值运算超出最大限制\rAssertionError # 断言语句失败\rAttributeError # 对象没有这个属性\rEOFError # 没有内建输入,到达EOF标记\rEnvironmentError # 操作系统错误的基类\rIOError # 输入/输出操作失败\rOSError # 操作系统错误\rWindowsError # windows系统调用失败\rImportError # 导入模块/对象失败\rKeyboardInterrupt # 用户中断执行(通常是ctrl+c)\rLookupError # 无效数据查询的基类\rIndexError # 序列中没有此索引(index)\rKeyError # 映射中没有这个键\rMemoryError # 内存溢出错误(对于python解释器不是致命的)\rNameError # 未声明/初始化对象(没有属性)\rUnboundLocalError # 访问未初始化的本地变量\rReferenceError # 若引用试图访问已经垃圾回收了的对象\rRuntimeError # 一般的运行时错误\rNotImplementedError # 尚未实现的方法\rSyntaxError # python语法错误\rIndentationError # 缩进错误\rTabError # tab和空格混用\rSystemError # 一般的解释器系统错误\rTypeError # 对类型无效的操作\rValueError # 传入无效的参数\rUnicodeError # Unicode相关的错误\rUnicodeDecodeError # Unicode解码时的错误\rUnicodeEncodeError # Unicode编码时的错误\rUnicodeTranslateError # Unicode转换时错误\rWarning # 警告的基类\rDeprecationWarning # 关于被弃用的特征的警告\rFutureWarning # 关于构造将来语义会有改变的警告\rOverflowWarning # 旧的关于自动提升为长整形的警告\rPendingDeprecationWarning # 关于特性将会被废弃的警告\rRuntimeWarning # 可疑的运行时行为的警告\rSyntaxWarning # 可疑的语法的警告\rUserWarning # 用户代码生成的警告\r触发异常\rraise exclass # 触发异常,从exclass生成一个实例(不含任何异常参数)\rraise exclass() # 触发异常,但现在不是类;通过函数调用操作符(function calloperator:\u0026quot;()\u0026quot;)作用于类名生成一个新的exclass实例,同样也没有异常参数\rraise exclass, args # 触发异常,但同时提供的异常参数args,可以是一个参数也可以是元组\rraise exclass(args) # 触发异常,同上\rraise exclass, args, tb # 触发异常,但提供一个跟踪记录(traceback)对象tb供使用\rraise exclass,instance # 通过实例触发异常(通常是exclass的实例)\rraise instance # 通过实例触发异常;异常类型是实例的类型:等价于raise instance.__class__, instance\rraise string # 触发字符串异常\rraise string, srgs # 触发字符串异常,但触发伴随着args\rraise string,args,tb # 触发字符串异常,但提供一个跟踪记录(traceback)对象tb供使用\rraise # 重新触发前一个异常,如果之前没有异常,触发TypeError\r跟踪异常栈\r# traceback 获取异常相关数据都是通过sys.exc_info()函数得到的\rimport traceback\rimport sys\rtry:\rs = raw_input()\rprint int(s)\rexcept ValueError:\r# sys.exc_info() 返回值是元组，第一个exc_type是异常的对象类型，exc_value是异常的值，exc_tb是一个traceback对象，对象中包含出错的行数、位置等数据\rexc_type, exc_value, exc_tb = sys.exc_info()\rprint \u0026quot;\\n%s \\n %s \\n %s\\n\u0026quot; %(exc_type, exc_value, exc_tb )\rtraceback.print_exc() # 打印栈跟踪信息\r抓取全部错误信息存如字典\rimport sys, traceback\rtry:\rs = raw_input()\rint(s)\rexcept:\rexc_type, exc_value, exc_traceback = sys.exc_info() traceback_details = {\r'filename': exc_traceback.tb_frame.f_code.co_filename,\r'lineno' : exc_traceback.tb_lineno,\r'name' : exc_traceback.tb_frame.f_code.co_name,\r'type' : exc_type.__name__,\r'message' : exc_value.message, }\rdel(exc_type, exc_value, exc_traceback) print traceback_details\rf = file('test1.txt', 'a')\rf.write(\u0026quot;%s %s %s %s %s\\n\u0026quot; %(traceback_details['filename'],traceback_details['lineno'],traceback_details['name'],traceback_details['type'],traceback_details['message'], ))\rf.flush()\rf.close()\r调试log\r# cgitb覆盖了默认sys.excepthook全局异常拦截器\rdef func(a, b):\rreturn a / b\rif __name__ == '__main__':\rimport cgitb\rcgitb.enable(format='text')\rfunc(1, 0)\r函数式编程的内建函数\rapply(func[,nkw][,kw]) # 用可选的参数来调用func,nkw为非关键字参数,kw为关键字参数;返回值是函数调用的返回值\rfilter(func,seq) # 调用一个布尔函数func来迭代遍历每个seq中的元素;返回一个使func返回值为true的元素的序列\rmap(func,seq1[,seq2]) # 将函数func作用于给定序列(s)的每个元素,并用一个列表来提供返回值;如果func为None,func表现为一个身份函数,返回一个含有每个序列中元素集合的n个元组的列表\rreduce(func,seq[,init]) # 将二元函数作用于seq序列的元素,每次携带一堆(先前的结果以及下一个序列元素),连续地将现有的结果和下一个值作用在获得的随后的结果上,最后减少我们的序列为一个单一的返回值;如果初始值init给定,第一个比较会是init和第一个序列元素而不是序列的头两个元素\r# filter 即通过函数方法只保留结果为真的值组成列表\rdef f(x): return x % 2 != 0 and x % 3 != 0\rf(3) # 函数结果是False 3被filter抛弃\rf(5) # 函数结果是True 5被加入filter最后的列表结果\rfilter(f, range(2, 25))\r[5, 7, 11, 13, 17, 19, 23]\r# map 通过函数对列表进行处理得到新的列表\rdef cube(x): return x*x*x\rmap(cube, range(1, 11))\r[1, 8, 27, 64, 125, 216, 343, 512, 729, 1000]\r# reduce 通过函数会先接收初始值和序列的第一个元素，然后是返回值和下一个元素，依此类推\rdef add(x,y): return x+y\rreduce(add, range(1, 11)) # 结果55 是1到10的和 x的值是上一次函数返回的结果，y是列表中循环的值\rre正则\rcompile(pattern,flags=0) # 对正则表达式模式pattern进行编译,flags是可选标识符,并返回一个regex对象\rmatch(pattern,string,flags=0) # 尝试用正则表达式模式pattern匹配字符串string,flags是可选标识符,如果匹配成功,则返回一个匹配对象;否则返回None\rsearch(pattern,string,flags=0) # 在字符串string中搜索正则表达式模式pattern的第一次出现,flags是可选标识符,如果匹配成功,则返回一个匹配对象;否则返回None\rfindall(pattern,string[,flags]) # 在字符串string中搜索正则表达式模式pattern的所有(非重复)出现:返回一个匹配对象的列表 # pattern=u'\\u4e2d\\u6587' 代表UNICODE\rfinditer(pattern,string[,flags]) # 和findall()相同,但返回的不是列表而是迭代器;对于每个匹配,该迭代器返回一个匹配对象\rsplit(pattern,string,max=0) # 根据正则表达式pattern中的分隔符把字符string分割为一个列表,返回成功匹配的列表,最多分割max次(默认所有)\rsub(pattern,repl,string,max=0) # 把字符串string中所有匹配正则表达式pattern的地方替换成字符串repl,如果max的值没有给出,则对所有匹配的地方进行替换(subn()会返回一个表示替换次数的数值)\rgroup(num=0) # 返回全部匹配对象(或指定编号是num的子组)\rgroups() # 返回一个包含全部匹配的子组的元组(如果没匹配成功,返回一个空元组)\r例子\rre.findall(r'a[be]c','123abc456eaec789') # 返回匹配对象列表 ['abc', 'aec']\rre.findall(\u0026quot;(.)12[34](..)\u0026quot;,a) # 取出匹配括号中内容 a='qedqwe123dsf'\rre.search(\u0026quot;(.)123\u0026quot;,a ).group(1) # 搜索匹配的取第1个标签\rre.match(\u0026quot;^(1|2) *(.*) *abc$\u0026quot;, str).group(2) # 取第二个标签\rre.match(\u0026quot;^(1|2) *(.*) *abc$\u0026quot;, str).groups() # 取所有标签\rre.sub('[abc]','A','alex') # 替换\rfor i in re.finditer(r'\\d+',s): # 迭代\rprint i.group(),i.span() #\r搜索网页中UNICODE格式的中文\rQueryAdd='http://www.anti-spam.org.cn/Rbl/Query/Result'\rIp='222.129.184.52'\rs = requests.post(url=QueryAdd, data={'IP':Ip})\rre.findall(u'\\u4e2d\\u56fd', s.text, re.S)\r编码转换\ra='中文' # 编码未定义按输入终端utf8或gbk\ru=u'中文' # 定义为unicode编码 u值为 u'\\u4e2d\\u6587'\ru.encode('utf8') # 转为utf8格式 u值为 '\\xe4\\xb8\\xad\\xe6\\x96\\x87'\rprint u # 结果显示 中文\rprint u.encode('utf8') # 转为utf8格式,当显示终端编码为utf8 结果显示 中文 编码不一致则乱码\rprint u.encode('gbk') # 当前终端为utf8 故乱码\rord('4') # 字符转ASCII码\rchr(52) # ASCII码转字符\r遍历递归\r[os.path.join(x[0],y) for x in os.walk('/root/python/5') for y in x[2]]\rfor i in os.walk('/root/python/5/work/server'):\rprint i\r 2 常用模块\nsys\rsys.argv # 取参数列表\rsys.exit(2) # 退出脚本返回状态 会被try截取\rsys.exc_info() # 获取当前正在处理的异常类\rsys.version # 获取Python解释程序的版本信息\rsys.maxint # 最大的Int值 9223372036854775807\rsys.maxunicode # 最大的Unicode值\rsys.modules # 返回系统导入的模块字段，key是模块名，value是模块\rsys.path # 返回模块的搜索路径，初始化时使用PYTHONPATH环境变量的值\rsys.platform # 返回操作系统平台名称\rsys.stdout # 标准输出\rsys.stdin # 标准输入\rsys.stderr # 错误输出\rsys.exec_prefix # 返回平台独立的python文件安装的位置\rsys.stdin.readline() # 从标准输入读一行\rsys.stdout.write(\u0026quot;a\u0026quot;) # 屏幕输出a os\r# 相对sys模块 os模块更为底层 os._exit() try无法抓取\ros.popen('id').read() # 执行系统命令得到返回结果\ros.system() # 得到返回状态 返回无法截取\ros.name # 返回系统平台 Linux/Unix用户是'posix'\ros.getenv() # 读取环境变量\ros.putenv() # 设置环境变量\ros.getcwd() # 当前工作路径\ros.chdir() # 改变当前工作目录\ros.walk('/root/') # 递归路径\r文件处理\rmkfifo()/mknod() # 创建命名管道/创建文件系统节点\rremove()/unlink() # 删除文件\rrename()/renames() # 重命名文件\r*stat() # 返回文件信息\rsymlink() # 创建符号链接\rutime() # 更新时间戳\rtmpfile() # 创建并打开('w+b')一个新的临时文件\rwalk() # 遍历目录树下的所有文件名\r目录/文件夹\rchdir()/fchdir() # 改变当前工作目录/通过一个文件描述符改变当前工作目录\rchroot() # 改变当前进程的根目录\rlistdir() # 列出指定目录的文件\rgetcwd()/getcwdu() # 返回当前工作目录/功能相同,但返回一个unicode对象\rmkdir()/makedirs() # 创建目录/创建多层目录\rrmdir()/removedirs() # 删除目录/删除多层目录\r访问/权限\rsaccess() # 检验权限模式\rchmod() # 改变权限模式\rchown()/lchown() # 改变owner和groupID功能相同,但不会跟踪链接\rumask() # 设置默认权限模式\r文件描述符操作\ropen() # 底层的操作系统open(对于稳健,使用标准的内建open()函数)\rread()/write() # 根据文件描述符读取/写入数据 按大小读取文件部分内容\rdup()/dup2() # 复制文件描述符号/功能相同,但是复制到另一个文件描述符\r设备号\rmakedev() # 从major和minor设备号创建一个原始设备号\rmajor()/minor() # 从原始设备号获得major/minor设备号\ros.path模块\ros.path.expanduser('~/.ssh/key') # 家目录下文件的全路径\r分隔\ros.path.basename() # 去掉目录路径,返回文件名\ros.path.dirname() # 去掉文件名,返回目录路径\ros.path.join() # 将分离的各部分组合成一个路径名\ros.path.spllt() # 返回(dirname(),basename())元组\ros.path.splitdrive() # 返回(drivename,pathname)元组\ros.path.splitext() # 返回(filename,extension)元组\r信息\ros.path.getatime() # 返回最近访问时间\ros.path.getctime() # 返回文件创建时间\ros.path.getmtime() # 返回最近文件修改时间\ros.path.getsize() # 返回文件大小(字节)\r查询\ros.path.exists() # 指定路径(文件或目录)是否存在\ros.path.isabs() # 指定路径是否为绝对路径\ros.path.isdir() # 指定路径是否存在且为一个目录\ros.path.isfile() # 指定路径是否存在且为一个文件\ros.path.islink() # 指定路径是否存在且为一个符号链接\ros.path.ismount() # 指定路径是否存在且为一个挂载点\ros.path.samefile() # 两个路径名是否指向同一个文件\r相关模块\rbase64 # 提供二进制字符串和文本字符串间的编码/解码操作\rbinascii # 提供二进制和ASCII编码的二进制字符串间的编码/解码操作\rbz2 # 访问BZ2格式的压缩文件\rcsv # 访问csv文件(逗号分隔文件)\rcsv.reader(open(file))\rfilecmp # 用于比较目录和文件\rfileinput # 提供多个文本文件的行迭代器\rgetopt/optparse # 提供了命令行参数的解析/处理\rglob/fnmatch # 提供unix样式的通配符匹配的功能\rgzip/zlib # 读写GNU zip(gzip)文件(压缩需要zlib模块)\rshutil # 提供高级文件访问功能\rc/StringIO # 对字符串对象提供类文件接口\rtarfile # 读写TAR归档文件,支持压缩文件\rtempfile # 创建一个临时文件\ruu # uu格式的编码和解码\rzipfile # 用于读取zip归档文件的工具\renviron['HOME'] # 查看系统环境变量\r子进程\ros.fork() # 创建子进程,并复制父进程所有操作 通过判断pid = os.fork() 的pid值,分别执行父进程与子进程操作，0为子进程\ros.wait() # 等待子进程结束\r跨平台os模块属性\rlinesep # 用于在文件中分隔行的字符串\rsep # 用来分隔文件路径名字的字符串\rpathsep # 用于分割文件路径的字符串\rcurdir # 当前工作目录的字符串名称\rpardir # 父目录字符串名称\rcommands\rcommands.getstatusoutput('id') # 返回元组(状态,标准输出)\rcommands.getoutput('id') # 只返回执行的结果, 忽略返回值\rcommands.getstatus('file') # 返回ls -ld file执行的结果\r文件和目录管理\rimport shutil\rshutil.copyfile('data.db', 'archive.db') # 拷贝文件\rshutil.move('/build/executables', 'installdir') # 移动文件或目录\r文件通配符\rimport glob\rglob.glob('*.py') # 查找当前目录下py结尾的文件\r随机模块\rimport random\rrandom.choice(['apple', 'pear', 'banana']) # 随机取列表一个参数\rrandom.sample(xrange(100), 10) # 不重复抽取10个\rrandom.random() # 随机浮点数\rrandom.randrange(6) # 随机整数范围\r发送邮件\r发送邮件内容\r#!/usr/bin/python\r#encoding:utf8\r# 导入 smtplib 和 MIMEText import smtplib\rfrom email.mime.text import MIMEText\r# 定义发送列表 mailto_list=[\u0026quot;272121935@qq.com\u0026quot;,\u0026quot;272121935@163.com\u0026quot;]\r# 设置服务器名称、用户名、密码以及邮件后缀 mail_host = \u0026quot;smtp.163.com\u0026quot;\rmail_user = \u0026quot;mailuser\u0026quot;\rmail_pass = \u0026quot;password\u0026quot;\rmail_postfix=\u0026quot;163.com\u0026quot;\r# 发送邮件函数\rdef send_mail(to_list, sub):\rme = mail_user + \u0026quot;\u0026lt;\u0026quot;+mail_user+\u0026quot;@\u0026quot;+mail_postfix+\u0026quot;\u0026gt;\u0026quot;\rfp = open('context.txt')\rmsg = MIMEText(fp.read(),_charset=\u0026quot;utf-8\u0026quot;)\rfp.close()\rmsg['Subject'] = sub\rmsg['From'] = me\rmsg['To'] = \u0026quot;;\u0026quot;.join(to_list)\rtry:\rsend_smtp = smtplib.SMTP()\rsend_smtp.connect(mail_host)\rsend_smtp.login(mail_user, mail_pass)\rsend_smtp.sendmail(me, to_list, msg.as_string())\rsend_smtp.close()\rreturn True\rexcept Exception, e:\rprint str(e)\rreturn False\rif send_mail(mailto_list,\u0026quot;标题\u0026quot;):\rprint \u0026quot;测试成功\u0026quot;\relse:\rprint \u0026quot;测试失败\u0026quot;\r发送附件\r#!/usr/bin/python\r#encoding:utf8\rimport smtplib\rfrom email.mime.multipart import MIMEMultipart\rfrom email.mime.base import MIMEBase\rfrom email import encoders\rdef send_mail(to_list, sub, filename):\rme = mail_user + \u0026quot;\u0026lt;\u0026quot;+mail_user+\u0026quot;@\u0026quot;+mail_postfix+\u0026quot;\u0026gt;\u0026quot;\rmsg = MIMEMultipart()\rmsg['Subject'] = sub\rmsg['From'] = me\rmsg['To'] = \u0026quot;;\u0026quot;.join(to_list)\rsubmsg = MIMEBase('application', 'x-xz')\rsubmsg.set_payload(open(filename,'rb').read())\rencoders.encode_base64(submsg)\rsubmsg.add_header('Content-Disposition', 'attachment', filename=filename)\rmsg.attach(submsg)\rtry:\rsend_smtp = smtplib.SMTP()\rsend_smtp.connect(mail_host)\rsend_smtp.login(mail_user, mail_pass)\rsend_smtp.sendmail(me, to_list, msg.as_string())\rsend_smtp.close()\rreturn True\rexcept Exception, e:\rprint str(e)[1]\rreturn False\r# 设置服务器名称、用户名、密码以及邮件后缀 mail_host = \u0026quot;smtp.163.com\u0026quot;\rmail_user = \u0026quot;xuesong\u0026quot;\rmail_pass = \u0026quot;mailpasswd\u0026quot;\rmail_postfix = \u0026quot;163.com\u0026quot;\rmailto_list = [\u0026quot;272121935@qq.com\u0026quot;,\u0026quot;quanzhou722@163.com\u0026quot;]\rtitle = 'check'\rfilename = 'file_check.html'\rif send_mail(mailto_list,title,filename):\rprint \u0026quot;发送成功\u0026quot;\relse:\rprint \u0026quot;发送失败\u0026quot;\r解压缩\rgzip压缩\rimport gzip\rf_in = open('file.log', 'rb')\rf_out = gzip.open('file.log.gz', 'wb')\rf_out.writelines(f_in)\rf_out.close()\rf_in.close()\rgzip压缩1\rFile = 'xuesong_18.log'\rg = gzip.GzipFile(filename=\u0026quot;\u0026quot;, mode='wb', compresslevel=9, fileobj=open((r'%s.gz' %File),'wb'))\rg.write(open(r'%s' %File).read())\rg.close()\rgzip解压\rg = gzip.GzipFile(mode='rb', fileobj=open((r'xuesong_18.log.gz'),'rb'))\ropen((r'xuesong_18.log'),'wb').write(g.read())\r压缩tar.gz\rimport os\rimport tarfile\rtar = tarfile.open(\u0026quot;/tmp/tartest.tar.gz\u0026quot;,\u0026quot;w:gz\u0026quot;) # 创建压缩包名\rfor path,dir,files in os.walk(\u0026quot;/tmp/tartest\u0026quot;): # 递归文件目录\rfor file in files:\rfullpath = os.path.join(path,file)\rtar.add(fullpath) # 创建压缩包\rtar.close()\r解压tar.gz\rimport tarfile\rtar = tarfile.open(\u0026quot;/tmp/tartest.tar.gz\u0026quot;)\r#tar.extract(\u0026quot;/tmp\u0026quot;) # 全部解压到指定路径\rnames = tar.getnames() # 包内文件名\rfor name in names:\rtar.extract(name,path=\u0026quot;./\u0026quot;) # 解压指定文件\rtar.close()\rzip压缩\rimport zipfile,os\rf = zipfile.ZipFile('filename.zip', 'w' ,zipfile.ZIP_DEFLATED) # ZIP_STORE 为默认表不压缩. ZIP_DEFLATED 表压缩\r#f.write('file1.txt') # 将文件写入压缩包\rfor path,dir,files in os.walk(\u0026quot;tartest\u0026quot;): # 递归压缩目录\rfor file in files:\rf.write(os.path.join(path,file)) # 将文件逐个写入压缩包 f.close()\rzip解压\rif zipfile.is_zipfile('filename.zip'): # 判断一个文件是不是zip文件\rf = zipfile.ZipFile('filename.zip')\rfor file in f.namelist(): # 返回文件列表\rf.extract(file, r'/tmp/') # 解压指定文件\r#f.extractall() # 解压全部\rf.close()\r时间\rimport time\rtime.time() # 时间戳[浮点]\rtime.localtime()[1] - 1 # 上个月\rint(time.time()) # 时间戳[整s]\rtomorrow.strftime('%Y%m%d_%H%M') # 格式化时间\rtime.strftime('%Y-%m-%d_%X',time.localtime( time.time() ) ) # 时间戳转日期\rtime.mktime(time.strptime('2012-03-28 06:53:40', '%Y-%m-%d %H:%M:%S')) # 日期转时间戳\r判断输入时间格式是否正确\r#encoding:utf8\rimport time\rwhile 1:\ratime=raw_input('输入格式如[14.05.13 13:00]:')\rtry:\rbtime=time.mktime(time.strptime('%s:00' %atime, '%y.%m.%d %H:%M:%S'))\rbreak\rexcept:\rprint '时间输入错误,请重新输入，格式如[14.05.13 13:00]'\r上一个月最后一天\rimport datetime\rlastMonth=datetime.date(datetime.date.today().year,datetime.date.today().month,1)-datetime.timedelta(1)\rlastMonth.strftime(\u0026quot;%Y/%m\u0026quot;)\r前一天\r(datetime.datetime.now() + datetime.timedelta(days=-1) ).strftime('%Y%m%d')\r两日期相差天数\rimport datetime\rd1 = datetime.datetime(2005, 2, 16)\rd2 = datetime.datetime(2004, 12, 31)\r(d1 - d2).days\r向后加10个小时\rimport datetime\rd1 = datetime.datetime.now()\rd3 = d1 + datetime.timedelta(hours=10)\rd3.ctime()\r参数[optparse]\rimport os, sys\rimport time\rimport optparse\r# python aaa.py -t file -p /etc/opt -o aaaaa\rdef do_fiotest( type, path, output,):\rprint type, path, output,\rdef main():\rparser = optparse.OptionParser()\rparser.add_option('-t', '--type', dest = 'type', default = None, help = 'test type[file, device]')\rparser.add_option('-p', '--path', dest = 'path', default = None, help = 'test file path or device path')\rparser.add_option('-o', '--output', dest = 'output', default = None, help = 'result dir path')\r(o, a) = parser.parse_args()\rif None == o.type or None == o.path or None == o.output:\rprint \u0026quot;No device or file or output dir\u0026quot;\rreturn -1\rif 'file' != o.type and 'device' != o.type:\rprint \u0026quot;You need specify test type ['file' or 'device']\u0026quot;\rreturn -1\rdo_fiotest(o.type, o.path, o.output)\rprint \u0026quot;Test done!\u0026quot;\rif __name__ == '__main__':\rmain()\rhash\rimport md5\rm = md5.new('123456').hexdigest()\rimport hashlib\rm = hashlib.md5()\rm.update(\u0026quot;Nobody inspects\u0026quot;) # 使用update方法对字符串md5加密\rm.digest() # 加密后二进制结果\rm.hexdigest() # 加密后十进制结果\rhashlib.new(\u0026quot;md5\u0026quot;, \u0026quot;string\u0026quot;).hexdigest() # 对字符串加密\rhashlib.new(\u0026quot;md5\u0026quot;, open(\u0026quot;file\u0026quot;).read()).hexdigest() # 查看文件MD5值\r隐藏输入密码\rimport getpass\rpasswd=getpass.getpass()\rstring打印a-z\rimport string\rstring.lowercase # a-z小写\rstring.uppercase # A-Z大小\rparamiko [ssh客户端]\r安装\rsudo apt-get install python-setuptools easy_install\rsudo apt-get install python-all-dev\rsudo apt-get install build-essential\rparamiko实例(账号密码登录执行命令)\r#!/usr/bin/python\r#ssh\rimport paramiko\rimport sys,os\rhost = '10.152.15.200'\ruser = 'peterli'\rpassword = '123456'\rs = paramiko.SSHClient() # 绑定实例\rs.load_system_host_keys() # 加载本地HOST主机文件\rs.set_missing_host_key_policy(paramiko.AutoAddPolicy()) # 允许连接不在know_hosts文件中的主机\rs.connect(host,22,user,password,timeout=5) # 连接远程主机\rwhile True:\rcmd=raw_input('cmd:')\rstdin,stdout,stderr = s.exec_command(cmd) # 执行命令\rcmd_result = stdout.read(),stderr.read() # 读取命令结果\rfor line in cmd_result:\rprint line,\rs.close()\rparamiko实例(传送文件)\r#!/usr/bin/evn python\rimport os\rimport paramiko\rhost='127.0.0.1'\rport=22\rusername = 'peterli'\rpassword = '123456'\rssh=paramiko.Transport((host,port))\rprivatekeyfile = os.path.expanduser('~/.ssh/id_rsa') mykey = paramiko.RSAKey.from_private_key_file( os.path.expanduser('~/.ssh/id_rsa')) # 加载key 不使用key可不加\rssh.connect(username=username,password=password) # 连接远程主机\r# 使用key把 password=password 换成 pkey=mykey\rsftp=paramiko.SFTPClient.from_transport(ssh) # SFTP使用Transport通道\rsftp.get('/etc/passwd','pwd1') # 下载 两端都要指定文件名\rsftp.put('pwd','/tmp/pwd') # 上传\rsftp.close()\rssh.close()\rparamiko实例(密钥执行命令)\r#!/usr/bin/python\r#ssh\rimport paramiko\rimport sys,os\rhost = '10.152.15.123'\ruser = 'peterli'\rs = paramiko.SSHClient()\rs.load_system_host_keys()\rs.set_missing_host_key_policy(paramiko.AutoAddPolicy())\rprivatekeyfile = os.path.expanduser('~/.ssh/id_rsa') # 定义key路径\rmykey = paramiko.RSAKey.from_private_key_file(privatekeyfile)\r# mykey=paramiko.DSSKey.from_private_key_file(privatekeyfile,password='061128') # DSSKey方式 password是key的密码\rs.connect(host,22,user,pkey=mykey,timeout=5)\rcmd=raw_input('cmd:')\rstdin,stdout,stderr = s.exec_command(cmd)\rcmd_result = stdout.read(),stderr.read()\rfor line in cmd_result:\rprint line,\rs.close()\rssh并发(Pool控制最大并发)\r#!/usr/bin/env python\r#encoding:utf8\r#ssh_concurrent.py\rimport multiprocessing\rimport sys,os,time\rimport paramiko\rdef ssh_cmd(host,port,user,passwd,cmd):\rmsg = \u0026quot;-----------Result:%s----------\u0026quot; % host\rs = paramiko.SSHClient()\rs.load_system_host_keys()\rs.set_missing_host_key_policy(paramiko.AutoAddPolicy())\rtry:\rs.connect(host,22,user,passwd,timeout=5) stdin,stdout,stderr = s.exec_command(cmd)\rcmd_result = stdout.read(),stderr.read()\rprint msg\rfor line in cmd_result:\rprint line,\rs.close()\rexcept paramiko.AuthenticationException:\rprint msg\rprint 'AuthenticationException Failed'\rexcept paramiko.BadHostKeyException:\rprint msg\rprint \u0026quot;Bad host key\u0026quot;\tresult = []\rp = multiprocessing.Pool(processes=20)\rcmd=raw_input('CMD:')\rf=open('serverlist.conf')\rlist = f.readlines()\rf.close()\rfor IP in list:\rprint IP\rhost=IP.split()[0]\rport=int(IP.split()[1])\ruser=IP.split()[2]\rpasswd=IP.split()[3]\rresult.append(p.apply_async(ssh_cmd,(host,port,user,passwd,cmd)))\rp.close()\rfor res in result:\rres.get(timeout=35)\rssh并发(取文件状态并发送邮件)\r#!/usr/bin/python\r#encoding:utf8\r#config file: ip.list\rimport paramiko\rimport multiprocessing\rimport smtplib\rimport sys,os,time,datetime,socket,re\rfrom email.mime.text import MIMEText\r# 配置文件(IP列表)\rConf = 'ip.list'\ruser_name = 'peterli'\ruser_pwd = 'passwd'\rport = 22\rPATH = '/home/peterli/'\r# 设置服务器名称、用户名、密码以及邮件后缀 mail_host = \u0026quot;smtp.163.com\u0026quot;\rmail_user = \u0026quot;xuesong\u0026quot;\rmail_pass = \u0026quot;mailpasswd\u0026quot;\rmail_postfix = \u0026quot;163.com\u0026quot;\rmailto_list = [\u0026quot;272121935@qq.com\u0026quot;,\u0026quot;quanzhou722@163.com\u0026quot;]\rtitle = 'file check'\rDATE1=(datetime.datetime.now() + datetime.timedelta(days=-1) ).strftime('%Y%m%d')\rfile_path = '%s%s' %(PATH,DATE1)\rdef Ssh_Cmd(file_path,host_ip,user_name,user_pwd,port=22):\rs = paramiko.SSHClient()\rs.load_system_host_keys()\rs.set_missing_host_key_policy(paramiko.AutoAddPolicy())\rtry:\rs.connect(hostname=host_ip,port=port,username=user_name,password=user_pwd)\rstdin,stdout,stderr = s.exec_command('stat %s' %file_path)\rstat_result = '%s%s' %(stdout.read(),stderr.read())\rif stat_result.find('No such file or directory') == -1:\rfile_status = 'OK\\t'\rstdin,stdout,stderr = s.exec_command('du -sh %s' %file_path)\rcmd1_result = '%s_%s' %(stat_result.split()[32],stat_result.split()[33].split('.')[0])\rcmd2_result = ('%s%s' %(stdout.read(),stderr.read())).split()[0] else:\rfile_status = '未生成\\t'\rcmd1_result = 'null'\rcmd2_result = 'null'\rq.put(['Login successful'])\rs.close()\rexcept socket.error:\rfile_status = '主机或端口错误'\rcmd1_result = '-'\rcmd2_result = '-'\rexcept paramiko.AuthenticationException:\rfile_status = '用户或密码错误'\rcmd1_result = '-'\rcmd2_result = '-'\rexcept paramiko.BadHostKeyException:\rfile_status = 'Bad host key'\rcmd1_result = '-'\rcmd2_result = '-'\rexcept:\rfile_status = 'ssh异常'\rcmd1_result = '-'\rcmd2_result = '-'\rr.put('%s\\t-\\t%s\\t%s\\t%s\\t%s\\n' %(time.strftime('%Y-%m-%d_%H:%M'),host_ip,file_status,cmd2_result,cmd1_result))\rdef Concurrent(Conf,file_path,user_name,user_pwd,port):\r# 执行总计\rtotal = 0\r# 读取配置文件\rf=open(Conf)\rlist = f.readlines()\rf.close()\r# 并发执行\rprocess_list = []\rlog_file = file('file_check.log', 'w')\rlog_file.write('检查时间\\t\\t业务\\tIP\\t\\t文件状态\\t大小\\t生成时间\\n') for host_info in list:\r# 判断配置文件中注释行跳过\rif host_info.startswith('#'):\rcontinue\r# 取变量,其中任意变量未取到就跳过执行\rtry:\rhost_ip=host_info.split()[0].strip()\r#user_name=host_info.split()[1]\r#user_pwd=host_info.split()[2]\rexcept:\rlog_file.write('Profile error: %s\\n' %(host_info))\rcontinue\r#try:\r#\tport=int(host_info.split()[3])\r#except:\r#\tport=22\rtotal +=1\rp = multiprocessing.Process(target=Ssh_Cmd,args=(file_path,host_ip,user_name,user_pwd,port))\rp.start()\rprocess_list.append(p)\rfor j in process_list:\rj.join()\rfor j in process_list:\rlog_file.write(r.get())\rsuccessful = q.qsize()\rlog_file.write('执行完毕。 总执行:%s 登录成功:%s 登录失败:%s\\n' %(total,successful,total - successful))\rlog_file.flush()\rlog_file.close()\rdef send_mail(to_list, sub):\rme = mail_user + \u0026quot;\u0026lt;\u0026quot;+mail_user+\u0026quot;@\u0026quot;+mail_postfix+\u0026quot;\u0026gt;\u0026quot;\rfp = open('file_check.log')\rmsg = MIMEText(fp.read(),_charset=\u0026quot;utf-8\u0026quot;)\rfp.close()\rmsg['Subject'] = sub\rmsg['From'] = me\rmsg['To'] = \u0026quot;;\u0026quot;.join(to_list)\rtry:\rsend_smtp = smtplib.SMTP()\rsend_smtp.connect(mail_host)\rsend_smtp.login(mail_user, mail_pass)\rsend_smtp.sendmail(me, to_list, msg.as_string())\rsend_smtp.close()\rreturn True\rexcept Exception, e:\rprint str(e)[1]\rreturn False\rif __name__ == '__main__':\rq = multiprocessing.Queue()\rr = multiprocessing.Queue()\rConcurrent(Conf,file_path,user_name,user_pwd,port)\rif send_mail(mailto_list,title):\rprint \u0026quot;发送成功\u0026quot;\relse:\rprint \u0026quot;发送失败\u0026quot;\rLazyManage并发批量操作(判断非root交互到root操作)\r#!/usr/bin/python\r#encoding:utf8\r# LzayManage.py\r# config file: serverlist.conf\rimport paramiko\rimport multiprocessing\rimport sys,os,time,socket,re\rdef Ssh_Cmd(host_ip,Cmd,user_name,user_pwd,port=22):\rs = paramiko.SSHClient()\rs.load_system_host_keys()\rs.set_missing_host_key_policy(paramiko.AutoAddPolicy())\rs.connect(hostname=host_ip,port=port,username=user_name,password=user_pwd)\rstdin,stdout,stderr = s.exec_command(Cmd)\rResult = '%s%s' %(stdout.read(),stderr.read())\rq.put('successful')\rs.close()\rreturn Result.strip()\rdef Ssh_Su_Cmd(host_ip,Cmd,user_name,user_pwd,root_name,root_pwd,port=22):\rs = paramiko.SSHClient()\rs.load_system_host_keys()\rs.set_missing_host_key_policy(paramiko.AutoAddPolicy())\rs.connect(hostname=host_ip,port=port,username=user_name,password=user_pwd)\rssh = s.invoke_shell()\rtime.sleep(0.1)\rssh.send('su - %s\\n' %(root_name))\rbuff = ''\rwhile not buff.endswith('Password: '):\rresp = ssh.recv(9999)\rbuff +=resp\rssh.send('%s\\n' %(root_pwd))\rbuff = ''\rwhile True:\rresp = ssh.recv(9999)\rbuff +=resp\rif ': incorrect password' in buff:\rsu_correct='passwd_error'\rbreak\relif buff.endswith('# '):\rsu_correct='passwd_correct'\rbreak\rif su_correct == 'passwd_correct':\rssh.send('%s\\n' %(Cmd))\rbuff = ''\rwhile True:\rresp = ssh.recv(9999)\rif resp.endswith('# '):\rbuff +=re.sub('\\[.*@.*\\]# $','',resp)\rbreak\rbuff +=resp\rResult = buff.lstrip('%s' %(Cmd))\rq.put('successful')\relif su_correct == 'passwd_error':\rResult = \u0026quot;\\033[31mroot密码错误\\033[m\u0026quot;\rs.close()\rreturn Result.strip()\rdef Send_File(host_ip,PathList,user_name,user_pwd,Remote='/tmp',port=22):\rs=paramiko.Transport((host_ip,port))\rs.connect(username=user_name,password=user_pwd)\rsftp=paramiko.SFTPClient.from_transport(s) for InputPath in PathList:\rLocalPath = re.sub('^\\./','',InputPath.rstrip('/'))\rRemotePath = '%s/%s' %( Remote , os.path.basename( LocalPath ))\rtry:\rsftp.rmdir(RemotePath)\rexcept:\rpass\rtry:\rsftp.remove(RemotePath)\rexcept:\rpass\rif os.path.isdir(LocalPath):\rsftp.mkdir(RemotePath)\rfor path,dirs,files in os.walk(LocalPath):\rfor dir in dirs:\rdir_path = os.path.join(path,dir)\rsftp.mkdir('%s/%s' %(RemotePath,re.sub('^%s/' %LocalPath,'',dir_path)))\rfor file in files:\rfile_path = os.path.join(path,file)\rsftp.put( file_path,'%s/%s' %(RemotePath,re.sub('^%s/' %LocalPath,'',file_path)))\relse:\rsftp.put(LocalPath,RemotePath)\rq.put('successful')\rsftp.close()\rs.close()\rResult = '%s \\033[32m传送完成\\033[m' % PathList\rreturn Result\rdef Ssh(host_ip,Operation,user_name,user_pwd,root_name,root_pwd,Cmd=None,PathList=None,port=22):\rmsg = \u0026quot;\\033[32m-----------Result:%s----------\\033[m\u0026quot; % host_ip\rtry:\rif Operation == 'Ssh_Cmd':\rResult = Ssh_Cmd(host_ip=host_ip,Cmd=Cmd,user_name=user_name,user_pwd=user_pwd,port=port)\relif Operation == 'Ssh_Su_Cmd':\rResult = Ssh_Su_Cmd(host_ip=host_ip,Cmd=Cmd,user_name=user_name,user_pwd=user_pwd,root_name=root_name,root_pwd=root_pwd,port=port)\relif Operation == 'Ssh_Script':\rSend_File(host_ip=host_ip,PathList=PathList,user_name=user_name,user_pwd=user_pwd,port=port)\rScript_Head = open(PathList[0]).readline().strip()\rLocalPath = re.sub('^\\./','',PathList[0].rstrip('/'))\rCmd = '%s /tmp/%s' %( re.sub('^#!','',Script_Head), os.path.basename( LocalPath ))\rResult = Ssh_Cmd(host_ip=host_ip,Cmd=Cmd,user_name=user_name,user_pwd=user_pwd,port=port)\relif Operation == 'Ssh_Su_Script':\rSend_File(host_ip=host_ip,PathList=PathList,user_name=user_name,user_pwd=user_pwd,port=port)\rScript_Head = open(PathList[0]).readline().strip()\rLocalPath = re.sub('^\\./','',PathList[0].rstrip('/'))\rCmd = '%s /tmp/%s' %( re.sub('^#!','',Script_Head), os.path.basename( LocalPath ))\rResult = Ssh_Su_Cmd(host_ip=host_ip,Cmd=Cmd,user_name=user_name,user_pwd=user_pwd,root_name=root_name,root_pwd=root_pwd,port=port)\relif Operation == 'Send_File':\rResult = Send_File(host_ip=host_ip,PathList=PathList,user_name=user_name,user_pwd=user_pwd,port=port)\relse:\rResult = '操作不存在'\rexcept socket.error:\rResult = '\\033[31m主机或端口错误\\033[m'\rexcept paramiko.AuthenticationException:\rResult = '\\033[31m用户名或密码错误\\033[m'\rexcept paramiko.BadHostKeyException:\rResult = '\\033[31mBad host key\\033[m['\rexcept IOError:\rResult = '\\033[31m远程主机已存在非空目录或没有写权限\\033[m'\rexcept:\rResult = '\\033[31m未知错误\\033[m'\rr.put('%s\\n%s\\n' %(msg,Result))\rdef Concurrent(Conf,Operation,user_name,user_pwd,root_name,root_pwd,Cmd=None,PathList=None,port=22):\r# 读取配置文件\rf=open(Conf)\rlist = f.readlines()\rf.close()\r# 执行总计\rtotal = 0\r# 并发执行\rfor host_info in list:\r# 判断配置文件中注释行跳过\rif host_info.startswith('#'):\rcontinue\r# 取变量,其中任意变量未取到就跳过执行\rtry:\rhost_ip=host_info.split()[0]\r#user_name=host_info.split()[1]\r#user_pwd=host_info.split()[2]\rexcept:\rprint('Profile error: %s' %(host_info) )\rcontinue\rtry:\rport=int(host_info.split()[3])\rexcept:\rport=22\rtotal +=1\rp = multiprocessing.Process(target=Ssh,args=(host_ip,Operation,user_name,user_pwd,root_name,root_pwd,Cmd,PathList,port))\rp.start()\r# 打印执行结果\rfor j in range(total):\rprint(r.get() )\rif Operation == 'Ssh_Script' or Operation == 'Ssh_Su_Script':\rsuccessful = q.qsize() / 2\relse:\rsuccessful = q.qsize()\rprint('\\033[32m执行完毕[总执行:%s 成功:%s 失败:%s]\\033[m' %(total,successful,total - successful) )\rq.close()\rr.close()\rdef Help():\rprint('''\t1.执行命令\r2.执行脚本 \\033[32m[位置1脚本(必须带脚本头),后可带执行脚本所需要的包\\文件\\文件夹路径,空格分隔]\\033[m\r3.发送文件 \\033[32m[传送的包\\文件\\文件夹路径,空格分隔]\\033[m\r退出: 0\\exit\\quit\r帮助: help\\h\\?\r注意: 发送文件默认为/tmp下,如已存在同名文件会被强制覆盖,非空目录则中断操作.执行脚本先将本地脚本及包发送远程主机上,发送规则同发送文件\r''')\rif __name__=='__main__':\r# 定义root账号信息\rroot_name = 'root'\rroot_pwd = 'peterli'\ruser_name='peterli'\ruser_pwd='\u0026lt;++(3Ie'\r# 配置文件\rConf='serverlist.conf'\rif not os.path.isfile(Conf):\rprint('\\033[33m配置文件 %s 不存在\\033[m' %(Conf) )\rsys.exit()\rHelp()\rwhile True:\ri = raw_i "});index.add({'id':22,'href':'/posts/Shell%E5%AE%9E%E4%BE%8B%E6%89%8B%E5%86%8C/','title':"Shell实例手册",'section':"Posts",'content':"Shell实例手册\n0说明{\n手册制作: 雪松\r更新日期: 2013-12-06\r欢迎系统运维加入Q群: 198173206\r请使用\u0026quot;notepad++\u0026quot;打开此文档,\u0026quot;alt+0\u0026quot;将函数折叠后方便查阅\r请勿删除信息，转载请说明出处，抵制不道德行为。\r错误在所难免，还望指正！\r# shell实例手册最新下载地址:\rhttp://hi.baidu.com/quanzhou722/item/f4a4f3c9eb37f02d46d5c0d9\r# LazyManage系统批量管理软件下载(shell):\rhttp://hi.baidu.com/quanzhou722/item/4ccf7e88a877eaccef083d1a\r# python实例手册下载地址:\rhttp://hi.baidu.com/quanzhou722/item/cf4471f8e23d3149932af2a7\r }\n1文件{\ntouch file # 创建空白文件\rrm -rf 目录名 # 不提示删除非空目录(-r:递归删除 -f强制)\rdos2unix # windows文本转linux文本 unix2dos # linux文本转windows文本\renca filename # 查看编码 安装 yum install -y enca md5sum # 查看md5值\rln 源文件 目标文件 # 硬链接\rln -s 源文件 目标文件 # 符号连接\rreadlink -f /data # 查看连接真实目录\rcat file | nl |less # 查看上下翻页且显示行号 q退出\rhead # 查看文件开头内容\rhead -c 10m # 截取文件中10M内容\rsplit -C 10M # 将文件切割大小为10M\rtail -f file # 查看结尾 监视日志文件\rfile # 检查文件类型\rumask # 更改默认权限\runiq # 删除重复的行\runiq -c # 重复的行出现次数\runiq -u # 只显示不重复行\rpaste a b # 将两个文件合并用tab键分隔开\rpaste -d'+' a b # 将两个文件合并指定'+'符号隔开\rpaste -s a # 将多行数据合并到一行用tab键隔开\rchattr +i /etc/passwd # 设置不可改变位\rmore # 向下分面器\rlocate 字符串 # 搜索\rwc -l file # 查看行数\rcp filename{,.bak} # 快速备份一个文件\r\\cp a b # 拷贝不提示 既不使用别名 cp -i\rrev # 将行中的字符逆序排列\rcomm -12 2 3 # 行和行比较匹配\riconv -f gbk -t utf8 原.txt \u0026gt; 新.txt # 转换编码\rrename 原模式 目标模式 文件 # 重命名 可正则\rwatch -d -n 1 'df; ls -FlAt /path' # 实时某个目录下查看最新改动过的文件\rcp -v /dev/dvd /rhel4.6.iso9660 # 制作镜像\rdiff suzu.c suzu2.c \u0026gt; sz.patch # 制作补丁\rpatch suzu.c \u0026lt; sz.patch # 安装补丁\rsort排序{\r-t # 指定排序时所用的栏位分隔字符\r-n # 依照数值的大小排序\r-r # 以相反的顺序来排序\r-f # 排序时，将小写字母视为大写字母\r-d # 排序时，处理英文字母、数字及空格字符外，忽略其他的字符\r-c # 检查文件是否已经按照顺序排序\r-b # 忽略每行前面开始处的空格字符\r-M # 前面3个字母依照月份的缩写进行排序\r-k # 指定域\r-m # 将几个排序好的文件进行合并\r+\u0026lt;起始栏位\u0026gt;-\u0026lt;结束栏位\u0026gt; # 以指定的栏位来排序，范围由起始栏位到结束栏位的前一栏位。\r-o # 将排序后的结果存入指定的文\rn # 表示进行排序\rr # 表示逆序\rsort -n # 按数字排序\rsort -nr # 按数字倒叙\rsort -u # 过滤重复行\rsort -m a.txt c.txt # 将两个文件内容整合到一起\rsort -n -t' ' -k 2 -k 3 a.txt # 第二域相同，将从第三域进行升降处理\rsort -n -t':' -k 3r a.txt # 以:为分割域的第三域进行倒叙排列\rsort -k 1.3 a.txt # 从第三个字母起进行排序\rsort -t\u0026quot; \u0026quot; -k 2n -u a.txt # 以第二域进行排序，如果遇到重复的，就删除\r}\rfind查找{\r# linux文件无创建时间\r# Access 使用时间 # Modify 内容修改时间 # Change 状态改变时间(权限、属主)\r# 时间默认以24小时为单位,当前时间到向前24小时为0天,向前48-72小时为2天\r# -and 且 匹配两个条件 参数可以确定时间范围 -mtime +2 -and -mtime -4\r# -or 或 匹配任意一个条件\rfind /etc -name http # 按文件名查找\rfind . -type f # 查找某一类型文件\rfind / -perm # 按照文件权限查找\rfind / -user # 按照文件属主查找\rfind / -group # 按照文件所属的组来查找文件\rfind / -atime -n # 文件使用时间在N天以内\rfind / -atime +n # 文件使用时间在N天以前\rfind / -mtime -n # 文件内容改变时间在N天以内\rfind / -mtime +n # 文件内容改变时间在N天以前\rfind / -ctime +n # 文件状态改变时间在N天前\rfind / -ctime -n # 文件状态改变时间在N天内\rfind / -size +1000000c -print # 查找文件长度大于1M字节的文件\rfind /etc -name \u0026quot;passwd*\u0026quot; -exec grep \u0026quot;xuesong\u0026quot; {} \\; # 按名字查找文件传递给-exec后命令\rfind . -name 't*' -exec basename {} \\; # 查找文件名,不取路径\rfind . -type f -name \u0026quot;err*\u0026quot; -exec rename err ERR {} \\; # 批量改名(查找err 替换为 ERR {}文件\rfind 路径 -name *name1* -or -name *name2* # 查找任意一个关键字\r}\rvim编辑器{\rgconf-editor # 配置编辑器\r/etc/vimrc # 配置文件路径\rvim +24 file # 打开文件定位到指定行\rvim file1 file2 # 打开多个文件 vim -O2 file1 file2 # 垂直分屏\rvim -on file1 file2 # 水平分屏\rsp filename # 上下分割打开新文件\rvsp filename # 左右分割打开新文件\rCtrl+W [操作] # 多个文件间操作 大写W # 操作: 关闭当前窗口c 屏幕高度一样= 增加高度+ 移动光标所在屏 右l 左h 上k 下j 中h 下一个w :n # 编辑下一个文件\r:2n # 编辑下二个文件\r:N # 编辑前一个文件\r:rew # 回到首文件\r:set nu # 打开行号\r:set nonu # 取消行号\r200G # 跳转到200\r:nohl # 取消高亮\r:set autoindent # 设置自动缩进\r:set ff # 查看文本格式\r:set binary # 改为unix格式\rctrl+ U # 向前翻页\rctrl+ D # 向后翻页\r%s/字符1/字符2/g # 全部替换 X # 文档加密\r}\r归档解压缩{\rtar zxvpf gz.tar.gz -C 放到指定目录 包中的目录 # 解包tar.gz 不指定目录则全解压\rtar zcvpf /$path/gz.tar.gz * # 打包gz 注意*最好用相对路径\rtar zcf /$path/gz.tar.gz * # 打包正确不提示\rtar ztvpf gz.tar.gz # 查看gz\rtar xvf 1.tar -C 目录 # 解包tar\rtar -cvf 1.tar * # 打包tar\rtar tvf 1.tar # 查看tar\rtar -rvf 1.tar 文件名 # 给tar追加文件\rtar --exclude=/home/dmtsai -zcvf myfile.tar.gz /home/* /etc # 打包/home, /etc ，但排除 /home/dmtsai\rtar -N \u0026quot;2005/06/01\u0026quot; -zcvf home.tar.gz /home # 在 /home 当中，比 2005/06/01 新的文件才备份\rtar -zcvfh home.tar.gz /home # 打包目录中包括连接目录\rzgrep 字符 1.gz # 查看压缩包中文件字符行\rbzip2 -dv 1.tar.bz2 # 解压bzip2\rbzip2 -v 1.tar # bzip2压缩\rbzcat # 查看bzip2\rgzip A # 直接压缩文件 # 压缩后源文件消失\rgunzip A.gz # 直接解压文件 # 解压后源文件消失\rgzip -dv 1.tar.gz # 解压gzip到tar\rgzip -v 1.tar # 压缩tar到gz\runzip zip.zip # 解压zip\rzip zip.zip * # 压缩zip\r# rar3.6下载: http://www.rarsoft.com/rar/rarlinux-3.6.0.tar.gz\rrar a rar.rar *.jpg # 压缩文件为rar包\runrar x rar.rar # 解压rar包\r7z a 7z.7z * # 7z压缩\r7z e 7z.7z # 7z解压\r}\r文件ACL权限控制{\rgetfacl 1.test # 查看文件ACL权限\rsetfacl -R -m u:xuesong:rw- 1.test # 对文件增加用户的读写权限 -R 递归\r}\rsvn更新代码{\r--force # 强制覆盖\r/usr/bin/svn --username user --password passwd co $Code ${SvnPath}src/ # 检出整个项目\r/usr/bin/svn --username user --password passwd export $Code$File ${SvnPath}src/$File # 导出个别文件\r}\r恢复rm删除的文件{\r# debugfs针对 ext2 # ext3grep针对 ext3 # extundelete针对 ext4\rdf -T # 首先查看磁盘分区格式\rumount /data/ # 卸载挂载,数据丢失请首先卸载挂载,或重新挂载只读\rext3grep /dev/sdb1 --ls --inode 2 # 记录信息继续查找目录下文件inode信息\rext3grep /dev/sdb1 --ls --inode 131081 # 此处是inode\rext3grep /dev/sdb1 --restore-inode 49153 # 记录下inode信息开始恢复目录\r}\r }\n2软件{\nrpm{\rrpm -ivh lynx # rpm安装\rrpm -e lynx # 卸载包\rrpm -e lynx --nodeps # 强制卸载\rrpm -qa # 查看所有安装的rpm包\rrpm -qa | grep lynx # 查找包是否安装\rrpm -ql # 软件包路径\rrpm -Uvh # 升级包\rrpm --test lynx # 测试\rrpm -qc # 软件包配置文档\rrpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-6 # 导入rpm的签名信息\r}\ryum{\ryum list # 查找所有列表\ryum install 包名 # 安装包和依赖包\ryum -y update # 升级所有包版本,依赖关系，系统版本内核都升级\ryum -y update 软件包名 # 升级指定的软件包\ryum -y upgrade # 不改变软件设置更新软件，系统版本升级，内核不改变\ryum search mail # yum搜索相关包\ryum grouplist # 软件包组\ryum -y groupinstall \u0026quot;Virtualization\u0026quot; # 安装软件包组\r}\ryum扩展源{\r# 包下载地址:http://download.fedoraproject.org/pub/epel # 选择版本\rwget http://download.fedoraproject.org/pub/epel/5/i386/epel-release-5-4.noarch.rpm\rrpm -Uvh epel-release-5-4.noarch.rpm\r}\r自定义yum源{\rfind /etc/yum.repos.d -name \u0026quot;*.repo\u0026quot; -exec mv {} {}.bak \\;\rvim /etc/yum.repos.d/yum.repo\r[yum]\r#http\rbaseurl=http://10.0.0.1/centos5.5\r#挂载iso\r#mount -o loop CentOS-5.8-x86_64-bin-DVD-1of2.iso /data/iso/\r#本地\r#baseurl=file:///data/iso/\renable=1\r#导入key\rrpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-5\r}\r编译{\r源码安装{\r./configure --help # 查看所有编译参数\r./configure --prefix=/usr/local/ # 配置参数\rmake # 编译\rmake install # 安装包\rmake clean # 清除编译结果\r}\rperl程序编译{\rperl Makefile.PL\rmake\rmake test\rmake install\r}\rpython程序编译{\rpython file.py\r}\r编译c程序{\rgcc -g hello.c -o hello\r}\r}\r }\n3系统{\nwall # 给其它用户发消息\rwhereis ls # 查找命令的目录\rwhich # 查看当前要执行的命令所在的路径\rclear # 清空整个屏幕\rreset # 重新初始化屏幕\rcal # 显示月历\recho -n 123456 | md5sum # md5加密\rmkpasswd # 随机生成密码 -l位数 -C大小 -c小写 -d数字 -s特殊字符\rnetstat -anlp | grep port # 是否打开了某个端口\rntpdate stdtime.gov.hk # 同步时间\rtzselect # 选择时区 #+8=(5 9 1 1) # (TZ='Asia/Shanghai'; export TZ)括号内写入 /etc/profile\r/sbin/hwclock -w # 保存到硬件\r/etc/shadow # 账户影子文件\rLANG=en # 修改语言\rvim /etc/sysconfig/i18n # 修改编码 LANG=\u0026quot;en_US.UTF-8\u0026quot;\rexport LC_ALL=C # 强制字符集\rvi /etc/hosts # 查询静态主机名\ralias # 别名\rwatch uptime # 监测命令动态刷新\ripcs -a # 查看Linux系统当前单个共享内存段的最大值\rlsof |grep /lib # 查看加载库文件\rldconfig # 动态链接库管理命令\rdist-upgrade # 会改变配置文件,改变旧的依赖关系，改变系统版本 /boot/grub/grub.conf # grub启动项配置\rsysctl -p # 修改内核参数/etc/sysctl.conf，让/etc/rc.d/rc.sysinit读取生效\rmkpasswd -l 8 -C 2 -c 2 -d 4 -s 0 # 随机生成指定类型密码\recho 1 \u0026gt; /proc/sys/net/ipv4/tcp_syncookies # 使TCP SYN Cookie 保护生效 # \u0026quot;SYN Attack\u0026quot;是一种拒绝服务的攻击方式\r开机启动脚本顺序{\r/etc/profile\r/etc/profile.d/*.sh\r~/bash_profile\r~/.bashrc\r/etc/bashrc\r}\r进程管理{\rps -eaf # 查看所有进程\rkill -9 PID # 强制终止某个PID进程\rkill -15 PID # 安全退出 需程序内部处理信号\rcmd \u0026amp; # 命令后台运行\rnohup cmd \u0026amp; # 后台运行不受shell退出影响\rctrl+z # 将前台放入后台(暂停)\rjobs # 查看后台运行程序\rbg 2 # 启动后台暂停进程\rfg 2 # 调回后台进程\rpstree # 进程树\rvmstat 1 9 # 每隔一秒报告系统性能信息9次\rsar # 查看cpu等状态\rlsof file # 显示打开指定文件的所有进程\rlsof -i:32768 # 查看端口的进程\rrenice +1 180 # 把180号进程的优先级加1\rps aux |grep -v USER | sort -nk +4 | tail # 显示消耗内存最多的10个运行中的进程，以内存使用量排序.cpu +3 top{\r前五行是系统整体的统计信息。\r第一行: 任务队列信息，同 uptime 命令的执行结果。内容如下：\r01:06:48 当前时间\rup 1:22 系统运行时间，格式为时:分\r1 user 当前登录用户数\rload average: 0.06, 0.60, 0.48 系统负载，即任务队列的平均长度。\r三个数值分别为 1分钟、5分钟、15分钟前到现在的平均值。\r第二、三行:为进程和CPU的信息。当有多个CPU时，这些内容可能会超过两行。内容如下：\rTasks: 29 total 进程总数\r1 running 正在运行的进程数\r28 sleeping 睡眠的进程数\r0 stopped 停止的进程数\r0 zombie 僵尸进程数\rCpu(s): 0.3% us 用户空间占用CPU百分比\r1.0% sy 内核空间占用CPU百分比\r0.0% ni 用户进程空间内改变过优先级的进程占用CPU百分比\r98.7% id 空闲CPU百分比\r0.0% wa 等待输入输出的CPU时间百分比\r0.0% hi\r0.0% si\r第四、五行:为内存信息。内容如下：\rMem: 191272k total 物理内存总量\r173656k used 使用的物理内存总量\r17616k free 空闲内存总量\r22052k buffers 用作内核缓存的内存量\rSwap: 192772k total 交换区总量\r0k used 使用的交换区总量\r192772k free 空闲交换区总量\r123988k cached 缓冲的交换区总量。\r内存中的内容被换出到交换区，而后又被换入到内存，但使用过的交换区尚未被覆盖，\r该数值即为这些内容已存在于内存中的交换区的大小。\r相应的内存再次被换出时可不必再对交换区写入。\r进程信息区,各列的含义如下: # 显示各个进程的详细信息\r序号 列名 含义\ra PID 进程id\rb PPID 父进程id\rc RUSER Real user name\rd UID 进程所有者的用户id\re USER 进程所有者的用户名\rf GROUP 进程所有者的组名\rg TTY 启动进程的终端名。不是从终端启动的进程则显示为 ?\rh PR 优先级\ri NI nice值。负值表示高优先级，正值表示低优先级\rj P 最后使用的CPU，仅在多CPU环境下有意义\rk %CPU 上次更新到现在的CPU时间占用百分比\rl TIME 进程使用的CPU时间总计，单位秒\rm TIME+ 进程使用的CPU时间总计，单位1/100秒\rn %MEM 进程使用的物理内存百分比\ro VIRT 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES\rp SWAP 进程使用的虚拟内存中，被换出的大小，单位kb。\rq RES 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA\rr CODE 可执行代码占用的物理内存大小，单位kb\rs DATA 可执行代码以外的部分(数据段+栈)占用的物理内存大小，单位kb\rt SHR 共享内存大小，单位kb\ru nFLT 页面错误次数\rv nDRT 最后一次写入到现在，被修改过的页面数。\rw S 进程状态。\rD=不可中断的睡眠状态\rR=运行\rS=睡眠\rT=跟踪/停止\rZ=僵尸进程\rx COMMAND 命令名/命令行\ry WCHAN 若该进程在睡眠，则显示睡眠中的系统函数名\rz Flags 任务标志，参考 sched.h\r}\rlinux操作系统提供的信号{\rkill -l # 查看linux提供的信号\rtrap \u0026quot;echo aaa\u0026quot; 2 3 15 # shell使用 trap 捕捉退出信号\r# 发送信号一般有两种原因:\r# 1(被动式) 内核检测到一个系统事件.例如子进程退出会像父进程发送SIGCHLD信号.键盘按下control+c会发送SIGINT信号\r# 2(主动式) 通过系统调用kill来向指定进程发送信号 # 进程结束信号 SIGTERM 和 SIGKILL 的区别: SIGTERM 比较友好，进程能捕捉这个信号，根据您的需要来关闭程序。在关闭程序之前，您可以结束打开的记录文件和完成正在做的任务。在某些情况下，假如进程正在进行作业而且不能中断，那么进程可以忽略这个SIGTERM信号。\r# 如果一个进程收到一个SIGUSR1信号，然后执行信号绑定函数，第二个SIGUSR2信号又来了，第一个信号没有被处理完毕的话，第二个信号就会丢弃。\rSIGHUP 1 A # 终端挂起或者控制进程终止\rSIGINT 2 A # 键盘终端进程(如control+c)\rSIGQUIT 3 C # 键盘的退出键被按下\rSIGILL 4 C # 非法指令\rSIGABRT 6 C # 由abort(3)发出的退出指令\rSIGFPE 8 C # 浮点异常\rSIGKILL 9 AEF # Kill信号 立刻停止\rSIGSEGV 11 C # 无效的内存引用\rSIGPIPE 13 A # 管道破裂: 写一个没有读端口的管道\rSIGALRM 14 A # 闹钟信号 由alarm(2)发出的信号 SIGTERM 15 A # 终止信号,可让程序安全退出 kill -15\rSIGUSR1 30,10,16 A # 用户自定义信号1\rSIGUSR2 31,12,17 A # 用户自定义信号2\rSIGCHLD 20,17,18 B # 子进程结束自动向父进程发送SIGCHLD信号\rSIGCONT 19,18,25 # 进程继续（曾被停止的进程）\rSIGSTOP 17,19,23 DEF # 终止进程\rSIGTSTP 18,20,24 D # 控制终端（tty）上按下停止键\rSIGTTIN 21,21,26 D # 后台进程企图从控制终端读\rSIGTTOU 22,22,27 D # 后台进程企图从控制终端写\r缺省处理动作一项中的字母含义如下:\rA 缺省的动作是终止进程\rB 缺省的动作是忽略此信号，将该信号丢弃，不做处理\rC 缺省的动作是终止进程并进行内核映像转储(dump core),内核映像转储是指将进程数据在内存的映像和进程在内核结构中的部分内容以一定格式转储到文件系统，并且进程退出执行，这样做的好处是为程序员提供了方便，使得他们可以得到进程当时执行时的数据值，允许他们确定转储的原因，并且可以调试他们的程序。\rD 缺省的动作是停止进程，进入停止状况以后还能重新进行下去，一般是在调试的过程中（例如ptrace系统调用）\rE 信号不能被捕获\rF 信号不能被忽略\r}\r}\r日志管理{\rhistory # 历时命令默认1000条\rHISTTIMEFORMAT=\u0026quot;%Y-%m-%d %H:%M:%S \u0026quot; # 让history命令显示具体时间\rhistory -c # 清除记录命令\rcat $HOME/.bash_history # 历史命令记录文件\rlast # 查看登陆过的用户信息\rwho /var/log/wtmp # 查看登陆过的用户信息\rlastlog # 用户最后登录的时间\rlastb -a # 列出登录系统失败的用户相关信息\r/var/log/btmp # 登录失败二进制日志记录文件\rtail -f /var/log/messages # 系统日志\rtail -f /var/log/secure # ssh日志\r}\rselinux{\rsestatus -v # 查看selinux状态\rgetenforce # 查看selinux模式\rsetenforce 0 # 设置selinux为宽容模式(可避免阻止一些操作)\rsemanage port -l # 查看selinux端口限制规则\rsemanage port -a -t http_port_t -p tcp 8000 # 在selinux中注册端口类型\rvi /etc/selinux/config # selinux配置文件\rSELINUX=enfoceing # 关闭selinux 把其修改为 SELINUX=disabled\r}\r查看剩余内存{\rfree -m\r#-/+ buffers/cache: 6458 1649\r#6458M为真实使用内存 1649M为真实剩余内存(剩余内存+缓存+缓冲器)\r#linux会利用所有的剩余内存作为缓存，所以要保证linux运行速度，就需要保证内存的缓存大小\r}\r系统信息{\runame -a # 查看Linux内核版本信息\rcat /proc/version # 查看内核版本\rcat /etc/issue # 查看系统版本\rlsb_release -a # 查看系统版本 需安装 centos-release\rlocale -a # 列出所有语系\rhwclock # 查看时间\rwho # 当前在线用户\rw # 当前在线用户\rwhoami # 查看当前用户名\rlogname # 查看初始登陆用户名\ruptime # 查看服务器启动时间\rsar -n DEV 1 10 # 查看网卡网速流量\rdmesg # 显示开机信息\rlsmod # 查看内核模块\r}\r硬件信息{\rmore /proc/cpuinfo # 查看cpu信息\rcat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c # 查看cpu型号和逻辑核心数\rgetconf LONG_BIT # cpu运行的位数\rcat /proc/cpuinfo | grep physical | uniq -c # 物理cpu个数\rcat /proc/cpuinfo | grep flags | grep ' lm ' | wc -l # 结果大于0支持64位\rcat /proc/cpuinfo|grep flags # 查看cpu是否支持虚拟化 pae支持半虚拟化 IntelVT 支持全虚拟化\rmore /proc/meminfo # 查看内存信息\rdmidecode # 查看全面硬件信息\rdmidecode | grep \u0026quot;Product Name\u0026quot; # 查看服务器型号\rdmidecode | grep -P -A5 \u0026quot;Memory\\s+Device\u0026quot; | grep Size | grep -v Range # 查看内存插槽\rcat /proc/mdstat # 查看软raid信息\rcat /proc/scsi/scsi # 查看Dell硬raid信息(IBM、HP需要官方检测工具)\rlspci # 查看硬件信息\rlspci|grep RAID # 查看是否支持raid\rlspci -vvv |grep Ethernet # 查看网卡型号\rlspci -vvv |grep Kernel|grep driver # 查看驱动模块\rmodinfo tg2 # 查看驱动版本(驱动模块)\rethtool -i em1 # 查看网卡驱动版本\r}\r终端快捷键{\rCtrl+A # 行前\rCtrl+E # 行尾\rCtrl+S # 终端锁屏\rCtrl+Q # 解锁屏\rCtrl+D # 退出\r}\r开机启动模式{\rvi /etc/inittab\rid:3:initdefault: # 3为多用户命令\r#ca::ctrlaltdel:/sbin/shutdown -t3 -r now # 注释此行 禁止 ctrl+alt+del 关闭计算机\r}\r终端提示显示{\recho $PS1 # 环境变量控制提示显示\rPS1='[\\u@ \\H \\w \\A \\@#]\\$'\rPS1='[\\u@\\h \\W]\\$'\r}\r定时任务{\rat 5pm + 3 days /bin/ls # 单次定时任务 指定三天后下午5:00执行/bin/ls\rcrontab -e # 编辑周期任务\r#分钟 小时 天 月 星期 命令或脚本\r1,30 1-3/2 * * * 命令或脚本 \u0026gt;\u0026gt; file.log 2\u0026gt;\u0026amp;1\recho \u0026quot;40 7 * * 2 /root/sh\u0026quot;\u0026gt;\u0026gt;/var/spool/cron/root # 直接将命令写入周期任务\rcrontab -l # 查看自动周期性任务\rcrontab -r # 删除自动周期性任务\rcron.deny和cron.allow # 禁止或允许用户使用周期任务\rservice crond start|stop|restart # 启动自动周期性服务\r}\rdate{\rdate -s 20091112 # 设日期\rdate -s 18:30:50 # 设时间\rdate -d \u0026quot;7 days ago\u0026quot; +%Y%m%d # 7天前日期\rdate -d \u0026quot;5 minute ago\u0026quot; +%H:%M # 5分钟前时间\rdate -d \u0026quot;1 month ago\u0026quot; +%Y%m%d # 一个月前\rdate +%Y-%m-%d -d '20110902' # 日期格式转换\rdate +%Y-%m-%d_%X # 日期和时间\rdate +%N # 纳秒\rdate -d \u0026quot;2012-08-13 14:00:23\u0026quot; +%s # 换算成秒计算(1970年至今的秒数)\rdate -d \u0026quot;@1363867952\u0026quot; +%Y-%m-%d-%T # 将时间戳换算成日期\rdate -d \u0026quot;1970-01-01 UTC 1363867952 seconds\u0026quot; +%Y-%m-%d-%T # 将时间戳换算成日期\rdate -d \u0026quot;`awk -F. '{print $1}' /proc/uptime` second ago\u0026quot; +\u0026quot;%Y-%m-%d %H:%M:%S\u0026quot; # 格式化系统启动时间(多少秒前)\r}\r最大连接数{\rulimit -SHn 65535 # 修改最大打开文件数(等同最大连接数)\rulimit -a # 查看\r/etc/security/limits.conf # 进程最大打开文件数\r# nofile 可以被理解为是文件句柄数 文件描述符 还有socket数\r* soft nofile 65535\r* hard nofile 65535\r# 最大进程数\r* soft nproc 65535\r* hard nproc 65535\r# 如果/etc/security/limits.d/有配置文件，将会覆盖/etc/security/limits.conf里的配置\r# 即/etc/security/limits.d/的配置文件里就不要有同样的参量设置\r/etc/security/limits.d/90-nproc.conf # centos6.3的最大进程数文件\r* soft nproc 65535 * hard nproc 65535\r}\rsudo{\rvisudo # sudo命令权限添加\r用户 别名(可用all)=NOPASSWD:命令1，命令2\rwangming linuxfan=NOPASSWD:/sbin/apache start,/sbin/apache restart\rUserName ALL=(ALL) ALL\rpeterli ALL=(ALL) NOPASSWD:/sbin/service\rDefaults requiretty # sudo不允许后台运行,注释此行既允许\rDefaults !visiblepw # sudo不允许远程,去掉!既允许\r}\rgrub开机启动项添加{\rvim /etc/grub.conf\rtitle ms-dos\rrootnoverify (hd0,0)\rchainloader +1\r}\rstty{\r#stty时一个用来改变并打印终端行设置的常用命令\rstty iuclc # 在命令行下禁止输出大写\rstty -iuclc # 恢复输出大写\rstty olcuc # 在命令行下禁止输出小写\rstty -olcuc # 恢复输出小写\rstty size # 打印出终端的行数和列数\rstty eof \u0026quot;string\u0026quot; # 改变系统默认ctrl+D来表示文件的结束 stty -echo # 禁止回显\rstty echo # 打开回显\rstty -echo;read;stty echo;read # 测试禁止回显\rstty igncr # 忽略回车符\rstty -igncr # 恢复回车符\rstty erase '#' # 将#设置为退格字符\rstty erase '^?' # 恢复退格字符\r定时输入{\rtimeout_read(){\rtimeout=$1\rold_stty_settings=`stty -g`　# save current settings\rstty -icanon min 0 time 100　# set 10seconds,not 100seconds\reval read varname　# =read $varname\rstty \u0026quot;$old_stty_settings\u0026quot;　# recover settings\r}\rread -t 10 varname # 更简单的方法就是利用read命令的-t选项\r}\r检测用户按键{\r#!/bin/bash\rold_tty_settings=$(stty -g) # 保存老的设置(为什么?). stty -icanon\rKeypress=$(head -c1) # 或者使用$(dd bs=1 count=1 2\u0026gt; /dev/null)\recho \u0026quot;Key pressed was \\\u0026quot;\u0026quot;$Keypress\u0026quot;\\\u0026quot;.\u0026quot;\rstty \u0026quot;$old_tty_settings\u0026quot; # 恢复老的设置. exit 0\r}\r}\riptables{\r内建三个表：nat mangle 和 filter\rfilter预设规则表，有INPUT、FORWARD 和 OUTPUT 三个规则链\rvi /etc/sysconfig/iptables # 配置文件\rINPUT # 进入\rFORWARD # 转发\rOUTPUT # 出去\rACCEPT # 将封包放行\rREJECT # 拦阻该封包\rDROP # 丢弃封包不予处理\r-A # 在所选择的链(INPUT等)末添加一条或更多规则\r-D # 删除一条\r-E # 修改\r-p # tcp、udp、icmp 0相当于所有all !取反\r-P # 设置缺省策略(与所有链都不匹配强制使用此策略)\r-s # IP/掩码 (IP/24) 主机名、网络名和清楚的IP地址 !取反\r-j # 目标跳转，立即决定包的命运的专用内建目标\r-i # 进入的（网络）接口 [名称] eth0\r-o # 输出接口[名称] -m # 模块\r--sport # 源端口\r--dport # 目标端口\riptables -F # 将防火墙中的规则条目清除掉 # 注意: iptables -P INPUT ACCEPT\riptables-restore \u0026lt; 规则文件 # 导入防火墙规则\r/etc/init.d/iptables save # 保存防火墙设置\r/etc/init.d/iptables restart # 重启防火墙服务\riptables -L -n # 查看规则\riptables -t nat -nL # 查看转发\riptables实例{\riptables -L INPUT # 列出某规则链中的所有规则\riptables -X allowed # 删除某个规则链 ,不加规则链，清除所有非内建的\riptables -Z INPUT # 将封包计数器归零\riptables -N allowed # 定义新的规则链\riptables -P INPUT DROP # 定义过滤政策\riptables -A INPUT -s 192.168.1.1 # 比对封包的来源IP # ! 192.168.0.0/24 ! 反向对比\riptables -A INPUT -d 192.168.1.1 # 比对封包的目的地IP\riptables -A INPUT -i eth0 # 比对封包是从哪片网卡进入\riptables -A FORWARD -o eth0 # 比对封包要从哪片网卡送出 eth+表示所有的网卡\riptables -A INPUT -p tcp # -p ! tcp 排除tcp以外的udp、icmp。-p all所有类型\riptables -D INPUT 8 # 从某个规则链中删除一条规则\riptables -D INPUT --dport 80 -j DROP # 从某个规则链中删除一条规则\riptables -R INPUT 8 -s 192.168.0.1 -j DROP # 取代现行规则\riptables -I INPUT 8 --dport 80 -j ACCEPT # 插入一条规则\riptables -A INPUT -i eth0 -j DROP # 其它情况不允许\riptables -A INPUT -p tcp -s IP -j DROP # 禁止指定IP访问\riptables -A INPUT -p tcp -s IP --dport port -j DROP # 禁止指定IP访问端口\riptables -A INPUT -s IP -p tcp --dport port -j ACCEPT # 允许在IP访问指定端口\riptables -A INPUT -p tcp --dport 22 -j DROP # 禁止使用某端口\riptables -A INPUT -i eth0 -p icmp -m icmp --icmp-type 8 -j DROP # 禁止icmp端口\riptables -A INPUT -i eth0 -p icmp -j DROP # 禁止icmp端口\riptables -t filter -A INPUT -i eth0 -p tcp --syn -j DROP # 阻止所有没有经过你系统授权的TCP连接\riptables -A INPUT -f -m limit --limit 100/s --limit-burst 100 -j ACCEPT # IP包流量限制\riptables -A INPUT -i eth0 -s 192.168.62.1/32 -p icmp -m icmp --icmp-type 8 -j ACCEPT # 除192.168.62.1外，禁止其它人ping我的主机\riptables -A INPUT -p tcp -m tcp --dport 80 -m state --state NEW -m recent --update --seconds 5 --hitcount 20 --rttl --name WEB --rsource -j DROP # 可防御cc攻击(未测试)\r}\riptables配置实例文件{\r# Generated by iptables-save v1.2.11 on Fri Feb 9 12:10:37 2007\r*filter\r:INPUT ACCEPT [637:58967]\r:FORWARD DROP [0:0]\r:OUTPUT ACCEPT [5091:1301533]\r# 允许的IP或IP段访问 建议多个\r-A INPUT -s 127.0.0.1 -p tcp -j ACCEPT\r-A INPUT -s 192.168.0.0/255.255.0.0 -p tcp -j ACCEPT\r# 开放对外开放端口\r-A INPUT -p tcp --dport 80 -j ACCEPT\r# 指定某端口针对IP开放\r-A INPUT -s 192.168.10.37 -p tcp --dport 22 -j ACCEPT\r# 拒绝所有协议(INPUT允许)\r-A INPUT -p tcp -m tcp --tcp-flags FIN,SYN,RST,PSH,URG RST -j DROP\r# 允许已建立的或相关连的通行\riptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT\r# 拒绝ping\r-A INPUT -p tcp -m tcp -j REJECT --reject-with icmp-port-unreachable\rCOMMIT\r# Completed on Fri Feb 9 12:10:37 2007\r}\riptables配置实例{\r# 允许某段IP访问任何端口\riptables -A INPUT -s 192.168.0.3/24 -p tcp -j ACCEPT\r# 设定预设规则 (拒绝所有的数据包，再允许需要的,如只做WEB服务器.还是推荐三个链都是DROP)\riptables -P INPUT DROP\riptables -P FORWARD DROP\riptables -P OUTPUT ACCEPT\r# 注意: 直接设置这三条会掉线\r# 开启22端口\riptables -A INPUT -p tcp --dport 22 -j ACCEPT\r# 如果OUTPUT 设置成DROP的，要写上下面一条\riptables -A OUTPUT -p tcp --sport 22 -j ACCEPT # 注:不写导致无法SSH.其他的端口一样,OUTPUT设置成DROP的话,也要添加一条链\r# 如果开启了web服务器,OUTPUT设置成DROP的话,同样也要添加一条链\riptables -A OUTPUT -p tcp --sport 80 -j ACCEPT\r# 做WEB服务器,开启80端口 ,其他同理\riptables -A INPUT -p tcp --dport 80 -j ACCEPT\r# 做邮件服务器,开启25,110端口\riptables -A INPUT -p tcp --dport 110 -j ACCEPT\riptables -A INPUT -p tcp --dport 25 -j ACCEPT\r# 允许icmp包通过,允许ping\riptables -A OUTPUT -p icmp -j ACCEPT (OUTPUT设置成DROP的话) iptables -A INPUT -p icmp -j ACCEPT (INPUT设置成DROP的话)\r# 允许loopback!(不然会导致DNS无法正常关闭等问题) IPTABLES -A INPUT -i lo -p all -j ACCEPT (如果是INPUT DROP)\rIPTABLES -A OUTPUT -o lo -p all -j ACCEPT(如果是OUTPUT DROP)\r}\r添加网段转发{\r# 例如通过vpn上网\recho 1 \u0026gt; /proc/sys/net/ipv4/ip_forward # 在内核里打开ip转发功能\riptables -t nat -A POSTROUTING -s 10.8.0.0/24 -j MASQUERADE # 添加网段转发\riptables -t nat -A POSTROUTING -s 10.0.0.0/255.0.0.0 -o eth0 -j SNAT --to 192.168.10.158 # 原IP网段经过哪个网卡IP出去\riptables -t nat -nL # 查看转发\r}\r端口映射{\r# 内网通过有外网IP的机器映射端口\recho 1 \u0026gt; /proc/sys/net/ipv4/ip_forward # 在内核里打开ip转发功能\rroute add -net 10.10.20.0 netmask 255.255.255.0 gw 10.10.20.111 # 内网需要添加默认网关，并且网关开启转发\riptables -t nat -A PREROUTING -d 192.168.10.158 -p tcp --dport 9999 -j DNAT --to 10.10.20.55:22\riptables -t nat -nL # 查看转发\r}\r}\r }\n4服务{\n/etc/init.d/sendmail start # 启动服务 /etc/init.d/sendmail stop # 关闭服务\r/etc/init.d/sendmail status # 查看服务当前状态\r/date/mysql/bin/mysqld_safe --user=mysql \u0026amp; # 启动mysql后台运行\rvi /etc/rc.d/rc.local # 开机启动执行 可用于开机启动脚本\r/etc/rc.d/rc3.d/S55sshd # 开机启动和关机关闭服务连接 # S开机start K关机stop 55级别 后跟服务名\rln -s -f /date/httpd/bin/apachectl /etc/rc.d/rc3.d/S15httpd # 将启动程序脚本连接到开机启动目录\ripvsadm -ln # lvs查看后端负载机并发\ripvsadm -C # lvs清除规则\rxm list # 查看xen虚拟主机列表\rvirsh # 虚拟化(xen\\kvm)管理工具 yum groupinstall Virtual*\r./bin/httpd -M # 查看httpd加载模块\rhttpd -t -D DUMP_MODULES # rpm包httpd查看加载模块\recho 内容| /bin/mail -s \u0026quot;标题\u0026quot; 收件箱 -- -f 发件人 # 发送邮件\r\u0026quot;`echo \u0026quot;内容\u0026quot;|iconv -f utf8 -t gbk`\u0026quot; | /bin/mail -s \u0026quot;`echo \u0026quot;标题\u0026quot;|iconv -f utf8 -t gbk`\u0026quot; 收件箱 # 解决邮件乱码\r/usr/local/nagios/bin/nagios -v /usr/local/nagios/etc/nagios.cfg # 检测nagios配置文件\rchkconfig{\rchkconfig 服务名 on|off|set # 设置非独立服务启状态\rchkconfig --level 35 httpd off # 让服务不自动启动\rchkconfig --level 35 httpd on # 让服务自动启动 35指的是运行级别\rchkconfig --list # 查看所有服务的启动状态\rchkconfig --list |grep httpd # 查看某个服务的启动状态\rchkconfig –-list [服务名称] # 查看服务的状态\r}\rhttpd{\r编译参数{\r# so模块用来提供DSO支持的apache核心模块\r# 如果编译中包含任何DSO模块，则mod_so会被自动包含进核心。\r# 如果希望核心能够装载DSO，但不实际编译任何DSO模块，则需明确指定\u0026quot;--enable-so=static\u0026quot;\r./configure --prefix=/usr/local/apache --enable-so --enable-mods-shared=most --enable-rewrite --enable-forward # 实例编译\r--with-mpm=worker # 已worker方式运行\r--with-apxs=/usr/local/apache/bin/apxs # 制作apache的动态模块DSO rpm包 httpd-devel #编译模块 apxs -i -a -c mod_foo.c\r--enable-so # 让Apache可以支持DSO模式\r--enable-mods-shared=most # 告诉编译器将所有标准模块都动态编译为DSO模块\r--enable-rewrite # 支持地址重写功能\r--enable-module=most # 用most可以将一些不常用的，不在缺省常用模块中的模块编译进来\r--enable-mods-shared=all # 意思是动态加载所有模块，如果去掉-shared话，是静态加载所有模块\r--enable-expires # 可以添加文件过期的限制，有效减轻服务器压力，缓存在用户端，有效期内不会再次访问服务器，除非按f5刷新，但也导致文件更新不及时\r--enable-deflate # 压缩功能，网页可以达到40%的压缩，节省带宽成本，但会对cpu压力有一点提高\r--enable-headers # 文件头信息改写，压缩功能需要\r--disable-MODULE # 禁用MODULE模块(仅用于基本模块)\r--enable-MODULE=shared # 将MODULE编译为DSO(可用于所有模块) --enable-mods-shared=MODULE-LIST # 将MODULE-LIST中的所有模块都编译成DSO(可用于所有模块) --enable-modules=MODULE-LIST # 将MODULE-LIST静态连接进核心(可用于所有模块)\r# 上述 MODULE-LIST 可以是:\r1、用引号界定并且用空格分隔的模块名列表 --enable-mods-shared='headers rewrite dav'\r2、\u0026quot;most\u0026quot;(大多数模块) --enable-mods-shared=most 3、\u0026quot;all\u0026quot;(所有模块)\r}\r转发{\r#针对非80端口的请求处理\rRewriteCond %{SERVER_PORT} !^80$\rRewriteRule ^/(.*) http://fully.qualified.domain.name:%{SERVER_PORT}/$1 [L,R]\rRewriteCond %{HTTP_HOST} ^ss.aa.com [NC]\rRewriteRule ^(.*) http://www.aa.com/so/$1/0/p0? [L,R=301]\r#RewriteRule 只对?前处理，所以会把?后的都保留下来\r#在转发后地址后加?即可取消RewriteRule保留的字符\r#R的含义是redirect，即重定向，该请求不会再被apache交给后端处理，而是直接返回给浏览器进行重定向跳转。301是返回的http状态码，具体可以参考http rfc文档，跳转都是3XX。\r#L是last，即最后一个rewrite规则，如果请求被此规则命中，将不会继续再向下匹配其他规则。 }\r}\rmysql源码安装{\rgroupadd mysql\ruseradd mysql -g mysql -M -s /bin/false\rtar zxvf mysql-5.0.22.tar.gz\rcd mysql-5.0.22\r./configure --prefix=/usr/local/mysql \\\r--with-client-ldflags=-all-static \\\r--with-mysqld-ldflags=-all-static \\\r--with-mysqld-user=mysql \\\r--with-extra-charsets=all \\\r--with-unix-socket-path=/var/tmp/mysql.sock\rmake \u0026amp;\u0026amp; make install\r# 生成mysql用户数据库和表文件，在安装包中输入\rscripts/mysql_install_db --user=mysql\rvi ~/.bashrc\rexport PATH=\u0026quot;$PATH: /usr/local/mysql/bin\u0026quot;\r# 配置文件,有large,medium,small三个，根据机器性能选择\rcp support-files/my-medium.cnf /etc/my.cnf\rcp support-files/mysql.server /etc/init.d/mysqld\rchmod 700 /etc/init.d/mysqld\rcd /usr/local\rchmod 750 mysql -R\rchgrp mysql mysql -R\rchown mysql mysql/var -R\rcp /usr/local/mysql/libexec/mysqld mysqld.old\rln -s /usr/local/mysql/bin/mysql /sbin/mysql\rln -s /usr/local/mysql/bin/mysqladmin /sbin/mysqladmin\rln -s -f /usr/local/mysql/bin/mysqld_safe /etc/rc.d/rc3.d/S15mysql5\rln -s -f /usr/local/mysql/bin/mysqld_safe /etc/rc.d/rc0.d/K15mysql5\r}\rmysql常用命令{\r./mysql/bin/mysqld_safe --user=mysql \u0026amp; # 启动mysql服务\r./mysql/bin/mysqladmin -uroot -p -S ./mysql/data/mysql.sock shutdown # 停止mysql服务\rmysqlcheck -uroot -p -S mysql.sock --optimize --databases account # 检查、修复、优化MyISAM表\rmysqlbinlog slave-relay-bin.000001 # 查看二进制日志(报错加绝对路径)\rmysqladmin -h myhost -u root -p create dbname # 创建数据库\rflush privileges; # 刷新\rshow databases; # 显示所有数据库\ruse dbname; # 打开数据库\rshow tables; # 显示选中数据库中所有的表\rdesc tables; # 查看表结构\rdrop database name; # 删除数据库\rdrop table name; # 删除表\rcreate database name; # 创建数据库\rselect 列名称 from 表名称; # 查询\rshow grants for repl; # 查看用户权限\rshow processlist; # 查看mysql进程\rselect user(); # 查看所有用户\rshow slave status\\G; # 查看主从状态\rshow variables; # 查看所有参数变量\rshow table status # 查看表的引擎状态\rdrop table if exists user # 表存在就删除\rcreate table if not exists user # 表不存在就创建\rselect host,user,password from user; # 查询用户权限 先use mysql\rcreate table ka(ka_id varchar(6),qianshu int); # 创建表\rSHOW VARIABLES LIKE 'character_set_%'; # 查看系统的字符集和排序方式的设定\rshow variables like '%timeout%'; # 查看超时(wait_timeout)\rdelete from user where user=''; # 删除空用户\rdelete from user where user='sss' and host='localhost' ; # 删除用户\rALTER TABLE mytable ENGINE = MyISAM ; # 改变现有的表使用的存储引擎\rSHOW TABLE STATUS from 库名 where Name='表名'; # 查询表引擎\rCREATE TABLE innodb (id int, title char(20)) ENGINE = INNODB # 创建表指定存储引擎的类型(MyISAM或INNODB)\rgrant replication slave on *.* to '用户'@'%' identified by '密码'; # 创建主从复制用户\rALTER TABLE player ADD INDEX weekcredit_faction_index (weekcredit, faction); # 添加索引\ralter table name add column accountid(列名) int(11) NOT NULL(字段不为空); # 插入字段\rupdate host set monitor_state='Y',hostname='xuesong' where ip='192.168.1.1'; # 更新数据\r自增表{\rcreate table oldBoy (id INTEGER PRIMARY KEY AUTO_INCREMENT, name CHAR(30) NOT NULL, age integer , sex CHAR(15) ); # 创建自增表\rinsert into oldBoy(name,age,sex) values(%s,%s,%s) # 自增插入数据\r}\r登录mysql的命令{\r# 格式： mysql -h 主机地址 -u 用户名 -p 用户密码\rmysql -h110.110.110.110 -P3306 -uroot -p\rmysql -uroot -p -S /data1/mysql5/data/mysql.sock -A --default-character-set=GBK\r}\rshell执行mysql命令{\rmysql -u$username -p$passwd -h$dbhost -P$dbport -A -e \u0026quot; use $dbname;\rdelete from data where date=('$date1');\r\u0026quot; # 执行多条mysql命令\rmysql -uroot -p -S mysql.sock -e \u0026quot;use db;alter table gift add column accountid int(11) NOT NULL;flush privileges;\u0026quot; # 不登陆mysql插入字段\r}\r备份数据库{\rmysqldump -h host -u root -p --default-character-set=utf8 dbname \u0026gt;dbname_backup.sql # 不包括库名，还原需先创建库，在use mysqldump -h host -u root -p --database --default-character-set=utf8 dbname \u0026gt;dbname_backup.sql # 包括库名，还原不需要创建库\r/bin/mysqlhotcopy -u root -p # mysqlhotcopy只能备份MyISAM引擎\rmysqldump -u root -p -S mysql.sock --default-character-set=utf8 dbname table1 table2 \u0026gt; /data/db.sql # 备份表\rmysqldump -uroot -p123 -d database \u0026gt; database.sql # 备份数据库结构\rinnobackupex --user=root --password=\u0026quot;\u0026quot; --defaults-file=/data/mysql5/data/my_3306.cnf --socket=/data/mysql5/data/mysql.sock --slave-info --stream=tar --tmpdir=/data/dbbackup/temp /data/dbbackup/ 2\u0026gt;/data/dbbackup/dbbackup.log | gzip 1\u0026gt;/data/dbbackup/db50.tar.gz # xtrabackup备份需单独安装软件 优点: 速度快,压力小,可直接恢复主从复制\r}\r还原数据库{\rmysql -h host -u root -p dbname \u0026lt; dbname_backup.sql source 路径.sql # 登陆mysql后还原sql文件\r}\r赋权限{\r# 指定IP: $IP 本机: localhost 所有IP地址: % # 通常指定多条\rgrant all on zabbix.* to user@\u0026quot;$IP\u0026quot;; # 对现有账号赋予权限\rgrant select on database.* to user@\u0026quot;%\u0026quot; Identified by \u0026quot;passwd\u0026quot;; # 赋予查询权限(没有用户，直接创建)\rgrant all privileges on database.* to user@\u0026quot;$IP\u0026quot; identified by 'passwd'; # 赋予指定IP指定用户所有权限(不允许对当前库给其他用户赋权限)\rgrant all privileges on database.* to user@\u0026quot;localhost\u0026quot; identified by 'passwd' with grant option; # 赋予本机指定用户所有权限(允许对当前库给其他用户赋权限)\rgrant select, insert, update, delete on database.* to user@'ip'identified by \u0026quot;passwd\u0026quot;; # 开放管理操作指令\rrevoke all on *.* from user@localhost; # 回收权限\r}\r更改密码{\rupdate user set password=password('passwd') where user='root'\rmysqladmin -u root password 'xuesong'\r}\rmysql忘记密码后重置{\rcd /data/mysql5\r/data/mysql5/bin/mysqld_safe --user=mysql --skip-grant-tables --skip-networking \u0026amp;\rupdate user set password=password('123123') where user='root';\r}\rmysql主从复制失败恢复{\rslave stop;\rreset slave;\rchange master to master_host='10.10.10.110',master_port=3306,master_user='repl',master_password='repl',master_log_file='master-bin.000010',master_log_pos=107,master_connect_retry=60;\rslave start;\r}\r检测mysql主从复制延迟{\r1、在从库定时执行更新主库中的一个timeout数值\r2、同时取出从库中的timeout值对比判断从库与主库的延迟\r}\r}\rmongodb{\r一、启动{\r# 不启动认证\r./mongod --port 27017 --fork --logpath=/opt/mongodb/mongodb.log --logappend --dbpath=/opt/mongodb/data/\r# 启动认证\r./mongod --port 27017 --fork --logpath=/opt/mongodb/mongodb.log --logappend --dbpath=/opt/mongodb/data/ --auth\r# 配置文件方式启动\rcat /opt/mongodb/mongodb.conf\rport=27017 # 端口号\rfork=true # 以守护进程的方式运行，创建服务器进程\rauth=true # 开启用户认证\rlogappend=true # 日志采用追加方式\rlogpath=/opt/mongodb/mongodb.log # 日志输出文件路径\rdbpath=/opt/mongodb/data/ # 数据库路径\rshardsvr=true # 设置是否分片\rmaxConns=600 # 数据库的最大连接数\r./mongod -f /opt/mongodb/mongodb.conf\r# 其他参数\rbind_ip # 绑定IP 使用mongo登录需要指定对应IP\rjournal # 开启日志功能,降低单机故障的恢复时间,取代dur参数\rsyncdelay # 系统同步刷新磁盘的时间,默认60秒\rdirectoryperdb # 每个db单独存放目录,建议设置.与mysql独立表空间类似\rrepairpath # 执行repair时的临时目录.如果没开启journal,出现异常重启,必须执行repair操作\r# mongodb没有参数设置内存大小.使用os mmap机制缓存数据文件,在数据量不超过内存的情况下,效率非常高.数据量超过系统可用内存会影响写入性能\r}\r二、关闭{\r# 方法一:登录mongodb\r./mongo\ruse admin\rdb.shutdownServer()\r# 方法:kill传递信号 两种皆可\rkill -2 pid\rkill -15 pid\r}\r三、开启认证与用户管理{\r./mongo # 先登录\ruse admin # 切换到admin库\rdb.addUser(\u0026quot;root\u0026quot;,\u0026quot;123456\u0026quot;) # 创建用户\rdb.addUser('zhansan','pass',true) # 如果用户的readOnly为true那么这个用户只能读取数据，添加一个readOnly用户zhansan\r./mongo 127.0.0.1:27017/mydb -uroot -p123456 # 再次登录,只能针对用户所在库登录\r#虽然是超级管理员，但是admin不能直接登录其他数据库，否则报错\r#Fri Nov 22 15:03:21.886 Error: 18 { code: 18, ok: 0.0, errmsg: \u0026quot;auth fails\u0026quot; } at src/mongo/shell/db.js:228\rshow collections # 查看链接状态 再次登录使用如下命令,显示错误未经授权\rdb.system.users.find(); # 查看创建用户信息\rdb.system.users.remove({user:\u0026quot;zhansan\u0026quot;}) # 删除用户\r#恢复密码只需要重启mongodb 不加--auth参数\r}\r四、登录{\r192.168.1.5:28017 # http登录后可查看状态\r./mongo # 默认登录后打开 test 库\r./mongo 192.168.1.5:27017/databaseName # 直接连接某个库 不存在则创建 启动认证需要指定对应库才可登录\r}\r五、查看状态{\r#登录后执行命令查看状态\rdb.runCommand({\u0026quot;serverStatus\u0026quot;:1})\rglobalLock # 表示全局写入锁占用了服务器多少时间(微秒)\rmem # 包含服务器内存映射了多少数据,服务器进程的虚拟内存和常驻内存的占用情况(MB)\rindexCounters # 表示B树在磁盘检索(misses)和内存检索(hits)的次数.如果这两个比值开始上升,就要考虑添加内存了\rbackgroudFlushing # 表示后台做了多少次fsync以及用了多少时间\ropcounters # 包含每种主要擦撞的次数\rasserts # 统计了断言的次数\r#状态信息从服务器启动开始计算,如果过大就会复位,发送复位，所有计数都会复位,asserts中的roolovers值增加\r#mongodb自带的命令\r./mongostat\rinsert #每秒插入量\rquery #每秒查询量\rupdate #每秒更新量\rdelete #每秒删除量\rlocked #锁定量\rqr|qw #客户端查询排队长度(读|写)\rar|aw #活跃客户端量(读|写)\rconn #连接数\rtime #当前时间\r}\r六、常用命令{\rdb.listCommands() # 当前MongoDB支持的所有命令（同样可通过运行命令db.runCommand({\u0026quot;listCommands\u0026quot; : `1})来查询所有命令）\rdb.runCommand({\u0026quot;buildInfo\u0026quot; : 1}) # 返回MongoDB服务器的版本号和服务器OS的相关信息。\rdb.runCommand({\u0026quot;collStats\u0026quot; : 集合名}) # 返回该集合的统计信息，包括数据大小，已分配存储空间大小，索引的大小等。\rdb.runCommand({\u0026quot;distinct\u0026quot; : 集合名, \u0026quot;key\u0026quot; : 键, \u0026quot;query\u0026quot; : 查询文档}) # 返回特定文档所有符合查询文档指定条件的文档的指定键的所有不同的值。\rdb.runCommand({\u0026quot;dropDatabase\u0026quot; : 1}) # 清空当前数据库的信息，包括删除所有的集合和索引。\rdb.runCommand({\u0026quot;isMaster\u0026quot; : 1}) # 检查本服务器是主服务器还是从服务器。\rdb.runCommand({\u0026quot;ping\u0026quot; : 1}) # 检查服务器链接是否正常。即便服务器上锁，该命令也会立即返回。\rdb.runCommand({\u0026quot;repaireDatabase\u0026quot; : 1}) # 对当前数据库进行修复并压缩，如果数据库特别大，这个命令会非常耗时。\rdb.runCommand({\u0026quot;serverStatus\u0026quot; : 1}) # 查看这台服务器的管理统计信息。\r# 某些命令必须在admin数据库下运行，如下两个命令：\rdb.runCommand({\u0026quot;renameCollection\u0026quot; : 集合名, \u0026quot;to\u0026quot;：集合名}) # 对集合重命名，注意两个集合名都要是完整的集合命名空间，如foo.bar, 表示数据库foo下的集合bar。\rdb.runCommand({\u0026quot;listDatabases\u0026quot; : 1}) # 列出服务器上所有的数据库\r}\r七、进程控制{\rdb.currentOp() # 查看活动进程\rdb.$cmd.sys.inprog.findOne() # 查看活动进程 与上面一样\ropid # 操作进程号\rop # 操作类型(查询\\更新)\rns # 命名空间,指操作的是哪个对象\rquery # 如果操作类型是查询,这里将显示具体的查询内容\rlockType # 锁的类型,指明是读锁还是写锁\rdb.killOp(opid值) # 结束进程\rdb.$cmd.sys.killop.findOne({op:opid值}) # 结束进程\r}\r八、备份还原{\r./mongoexport -d test -c t1 -o t1.dat # 导出JSON格式\r-c # 指明导出集合\r-d # 使用库\r./mongoexport -d test -c t1 -csv -f num -o t1.dat # 导出csv格式\r-csv # 指明导出csv格式\r-f # 指明需要导出那些例\rdb.t1.drop() # 登录后删除数据\r./mongoimport -d test -c t1 -file t1.dat # mongoimport还原JSON格式\r./mongoimport -d test -c t1 -type csv --headerline -file t1.dat # mongoimport还原csv格式数据\r--headerline # 指明不导入第一行 因为第一行是列名\r./mongodump -d test -o /bak/mongodump # mongodump数据备份\r./mongorestore -d test --drop /bak/mongodump/* # mongorestore恢复\r--drop #恢复前先删除\rdb.t1.find() #查看\r# mongodump 虽然能不停机备份,但市区了获取实时数据视图的能力,使用fsync命令能在运行时复制数据目录并且不会损坏数据\r# fsync会强制服务器将所有缓冲区的数据写入磁盘.配合lock还阻止对数据库的进一步写入,知道释放锁为止\r# 备份在从库上备份，不耽误读写还能保证实时快照备份\rdb.runCommand({\u0026quot;fsync\u0026quot;:1,\u0026quot;lock\u0026quot;:1}) # 执行强制更新与写入锁\rdb.$cmd.sys.unlock.findOne() # 解锁\rdb.currentOp() # 查看解锁是否正常\r}\r九、修复{\r# 当停电或其他故障引起不正常关闭时,会造成部分数据损坏丢失\r./mongod --repair # 修复操作:启动时候加上 --repair\r# 修复过程:将所有文档导出,然后马上导入,忽略无效文档.完成后重建索引。时间较长,会丢弃损坏文档\r# 修复数据还能起到压缩数据库的作用\rdb.repairDatabase() # 运行中的mongodb可使用 repairDatabase 修复当前使用的数据库\r{\u0026quot;repairDatabase\u0026quot;:1} # 通过驱动程序\r}\r十、python使用mongodb{\r原文: http://blog.nosqlfan.com/html/2989.html\reasy_install pymongo # 安装(python2.7+)\rimport pymongo\rconnection=pymongo.Connection('localhost',27017) # 创建连接\rdb = connection.test_database # 切换数据库\rcollection = db.test_collection # 获取collection\r# db和collection都是延时创建的，在添加Document时才真正创建\r文档添加, _id自动创建\rimport datetime\rpost = {\u0026quot;author\u0026quot;: \u0026quot;Mike\u0026quot;,\r\u0026quot;text\u0026quot;: \u0026quot;My first blog post!\u0026quot;,\r\u0026quot;tags\u0026quot;: [\u0026quot;mongodb\u0026quot;, \u0026quot;python\u0026quot;, \u0026quot;pymongo\u0026quot;],\r\u0026quot;date\u0026quot;: datetime.datetime.utcnow()}\rposts = db.posts\rposts.insert(post)\rObjectId('...')\r批量插入\rnew_posts = [{\u0026quot;author\u0026quot;: \u0026quot;Mike\u0026quot;,\r "});index.add({'id':23,'href':'/posts/%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E7%9A%84Mysql%E5%AE%89%E8%A3%85/','title':"开发环境的Mysql安装",'section':"Posts",'content':" 初始化 mysql \u0026ndash;initialize 配置文件 [client] default-character-set=utf8 [mysqld] port=3306 default-storage-engine=INNODB character-set-server=utf8 collation-server=utf8_general_ci 启动 mysql \u0026ndash;console \u0026ndash;explict_default_for_timestamp=true 连接 mysql -uroot -p 管理 mysqladmin -uroot -p password mysqladmin -uroot shutdown  "});index.add({'id':24,'href':'/posts/Emacs-%E4%BD%BF%E7%94%A8%E7%B2%BE%E8%A6%81/','title':"Emacs 使用精要",'section':"Posts",'content':"使用emacs的daemon模式快速使用emacsclient -nw 启动emacs\n# alias emacs alias emacsd=\u0026#39;emacs --daemon\u0026#39; alias e=\u0026#39;emacsclient -t\u0026#39; alias ec=\u0026#39;emacsclient -c\u0026#39; # run emacs daemon [[ -z $(ps -C \u0026#39;emacs --daemon\u0026#39; -o pid=) ]] \u0026amp;\u0026amp; emacsd # add kill emacs function function kill-emacs(){ emacsclient -e \u0026#34;(kill-emacs)\u0026#34; emacs_pid=$( ps -C \u0026#39;emacs --daemon\u0026#39; -o pid= ) if [[ -n \u0026#34;${emacs_pid}\u0026#34; ]];then kill -9 \u0026#34;${emacs_pid}\u0026#34; fi } "});index.add({'id':25,'href':'/posts/%E5%AE%B9%E6%98%93%E9%81%97%E5%BF%98%E7%9A%84%E7%9F%A5%E8%AF%86%E7%82%B9/','title':"容易遗忘的知识点",'section':"Posts",'content':" 最近在微信看到一篇文章提到了面试常问的知识点。尝试着去回答这些问题，发现好多都回答不上来，或者讲不清楚。以后抽些时间把不清楚的问题的答案都补全。\n 面试常问的知识点？ #  1）集合相关问题（必问）： #  HashMap、LinkedHashMap、ConcurrentHashMap、ArrayList、LinkedList的底层实现。 #  HashMap的底层实现 #  Java8以前，HashMap由数组存储节点，节点与节点之间构成链表。从Java8开始，HashMap的key超过8个，会被转换为红黑树结构。\n链表结构的HashMap #  Entry被存储在table数组中。HashMap默认构造方法会构造空间为16，负载系数为0.75的table数组。key通过散列计算直接获得table上存储Entry的下标地址hashcode。table中存储的Entry数量超过数组空间乘以负载系数时，数组就会进行resize，数组长度翻倍。由于resize需要重新计算key的hashcode，比较耗费性能，如果能预估key的数量，可以在构造时指定初始空间大小。如果存着key的hashcode相同时，第一个加入key的next引用指向第二个加入的key，以此类推形成链表。在JDK8或以上里，如果一个hashcode对应的链表节点超过8个时，链表会被重新整理为红黑树。如果一个hashcode对应的链表是红黑树，而节点又少于6个时，红黑树又会被重新整理为链表。\n/** * The table, resized as necessary. Length MUST Always be a power of two. */ transient Entry[] table; static class Entry\u0026lt;K,V\u0026gt; implements Map.Entry\u0026lt;K,V\u0026gt; { final K key; V value; Entry\u0026lt;K,V\u0026gt; next; final int hash; …… } 红黑树结构的HashMap #  HashMap和Hashtable的区别。 #  ArrayList、LinkedList、Vector的区别。 #  HashMap和ConcurrentHashMap的区别。 #  HashMap和LinkedHashMap的区别。 #  HashMap是线程安全的吗。 #  ConcurrentHashMap是怎么实现线程安全的。 #  2）线程相关问题（必问）： #  创建线程的3种方式。 什么是线程安全。 Runnable接口和Callable接口的区别。 wait方法和sleep方法的区别。 synchronized、Lock、ReentrantLock、ReadWriteLock。 介绍下CAS(无锁技术)。 什么是ThreadLocal。 创建线程池的4种方式。 ThreadPoolExecutor的内部工作原理。 分布式环境下，怎么保证线程安全。 想要朝这方面发展或者真心有兴趣的。可以找我要一些基础的学习视频，Q号码：3300863615，这个是免费的，希望同学找我要的时候不要有理所应当的态度，毕竟都是我的心血，希望你是真的有一颗想要学好java的心，我也会尽所能的去帮助你成为一名优秀的程序员。\n3）JVM相关问题： #  介绍下垃圾收集机制（在什么时候，对什么，做了什么）。 垃圾收集有哪些算法，各自的特点。 类加载的过程。 双亲委派模型。 有哪些类加载器。 能不能自己写一个类叫java.lang.String。\n4）设计模式相关问题（必问）： #  先问你熟悉哪些设计模式，然后再具体问你某个设计模式具体实现和相关扩展问题。\n5）数据库相关问题，针对Mysql（必问）： #  给题目让你手写SQL。 有没有SQL优化经验。 Mysql索引的数据结构。 SQL怎么进行优化。 SQL关键字的执行顺序。 有哪几种索引。 什么时候该（不该）建索引。 Explain包含哪些列。 Explain的Type列有哪几种值。\n6）框架相关问题： #  Hibernate和Mybatis的区别。 Spring MVC和Struts2的区别。 Spring用了哪些设计模式。 Spring中AOP主要用来做什么。 Spring注入bean的方式。 什么是IOC，什么是依赖注入。 Spring是单例还是多例，怎么修改。 Spring事务隔离级别和传播性。 介绍下Mybatis/Hibernate的缓存机制。 Mybatis的mapper文件中#和$的区别。 Mybatis的mapper文件中resultType和resultMap的区别。 Mybatis中DAO层接口没有写实现类，Mapper中的方法和DAO接口方法是怎么绑定到一起的，其内部是怎么实现的。\n7）其他遇到问题： #  介绍下栈和队列。 IO和NIO的区别。 接口和抽象类的区别。 int和Integer的自动拆箱/装箱相关问题。 常量池相关问题。 ==和equals的区别。 重载和重写的区别。 String和StringBuilder、StringBuffer的区别。 静态变量、实例变量、局部变量线程安全吗，为什么。 try、catch、finally都有return语句时执行哪个。 介绍下B树、二叉树。 ajax的4个字母分别是什么意思。 xml全称是什么。 分布式锁的实现。 分布式session存储解决方案。 常用的linux命令。\n"});index.add({'id':26,'href':'/posts/%E5%AE%9E%E4%BE%8B%E5%8C%96%E9%9C%80%E6%B1%82%E5%AD%A6%E4%B9%A0%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86/','title':"实例化需求学习第一部分",'section':"Posts",'content':"  最近公司在推进实例化需求。在info上找到了《实例化需求》这本书的电子版，瞬间剁手赶紧买下来学习一下。\n 先介绍一下作者Gojko Adzic。战略软件交付顾问，专注敏捷和精益开发。尤其擅长敏捷测试、实例化需求和行为驱动开发。感觉头衔不是很多啊，是不是介绍得太谦虚了。 内容提要：本书是在世界各地调查了多个短腿交付过程后的经验总结。书中介绍了这些团队如何在很短的周期内说明需求、开发软件，并交付正确的、无缺陷的产品；为团队在实施实例化需求说明是使用的模式、想法和工件创建了一致的语言；展示了案例中的团队用来实现实例需求说明原则的关键性实践；并在案例分析部分展示了一些团队实施实例化需求说明的历程。本书适合与项目管理、开发、测试、交付有关的人员阅读。\n看看现状 #  在实施敏捷的实践有很多，这些方法大多都带有实现敏捷或者精益的目的，比如极限编程、Scrum、看板。 大多公司在做敏捷时都会结合多种敏捷实践，组合中使用自己团队的敏捷方法。在将需求变成产品的过程中，人们有许多用于描述需求并使之作为业务、SA、开发、测试、UX都能看得多的中间语言的实践。以下实践名字不同但是作法确实一致的。\n 敏捷验收测试 验收测试驱动开发 实例驱动开发 故事测试 行为驱动开发 实例化需求说明 实例化需求是一份活着的验证文档。测试人员执行实例化需求文档中的步骤即可验证需求中的功能，这也是为什么实例化需求被称为可执行的活文档。如果传统的需求文档由描述式语言写成，那么实例化文档就是由过程式语言写成。  主要优点 #  实例化需求的主要优点 #  现在人们开发一套软件的时间不在向以前一样需要持续好几年。软件开发的时间缩短到半年甚至是几周。人们不再花费大量的时间来做软件开发前期的分析和设计工作，以及漫长的手动测试回归工作。 技术上的成功和产品上的成功都很重要，软件开发实践必须满足以下几点；\n 保证所有项目干系人和交付团队的成员都对需要交付那些东西由一致的理解。 由准确的需求说明，这样交付团队才能避免由磨棱两可和功能确实造成的无谓返工。 有用来衡量某项工作是否已经完成的客观标准。 具有用来引导软件功能或团队结构变更的文档。 传统意义上，构建正确的产品需要庞大的功能需求说明、文档以及漫长的测试阶段。如今软件都按照周或者月进行交付。为了适应新的交付模式我们应该朝着这些目标前进： 避免过度说明需求从而产生浪费、避免花时间在开发前会花时间的细节上。 有一种可靠的文档，可以解释系统的行为，据此我们能容易修改系统行为。 以最少的维护成本维持文档的相关性与可靠性。 适合短迭代和基于流的过程，这样能为即将开展的工作提供即时足够的信息。 所以敏捷团队构建正确产品所需要的文档特点是 即使编写 易于维护 精确、客观可测试  有效地实施变更 #  在对已有的软件实施大型变更时，实例化需求文档就好比是文字化的单元测试，你让对重构的过程充满信心。只要按照原来的实例需求文档进行开发和测试，产品不会有太多预料之外的改变。\n更高的产品质量 #  实例化需求是一种开发测试都能看得懂的系统逻辑语言。它将清楚了什么情况下该做什么。想想看一本词典，前面介绍词性最后给出给出些例子，让你有了更直观的理解。实例化需求让那些晦涩难懂的需求变得直观，减少了沟通障碍。软件开发中减少了沟通障碍使得缺陷在开发过程中就被发现。很多团队在开发周期的起始阶段使用实例化需求会让需求更加精确，尽早识别太含糊或有太多功能缺失的用户故事。如果没有实例化需求说明，团队经常要到开发中期或者上线前才发现需求不清楚的问题，中断的流程常常需要耗费大量的时间，导致迭代中的产品功能无法按时交付。\n更好的协作 #  单元测试案例面向程序方法，它可以告诉开发人员程序是不是正常功能，却不能告诉我们程序是否满足整体的业务需求。实例化需求说明使得团队可以用一种清晰、客观和可衡量的方式定义预期的功能。他还能加速反馈、改善开发流程，并防止中断计划好的工作。\n为什么实例化需求文档是活的 #  让我们来看看实例化需求文档的主要过程模式 [业务目标]\u0026ndash;（从目标中获取范围）\u0026ndash;\u0026gt;[用户故事]\u0026ndash;（需求举例沟通）\u0026ndash;\u0026gt;[关键实例]\u0026ndash;（提炼需求说明）\u0026ndash;\u0026gt;[实例化需求说明]\u0026ndash;（自动化验证）\u0026ndash;\u0026gt;[可执行的需求]\u0026ndash;（验证/更新）\u0026mdash;\u0026gt;[活文档]。\n关键过程模式 #  从目标中获取范围 #  商业用户不是软件设计师。我们以客户的业务目标为起始，通过协作界定可以实现的目标范围。\n协作制定需求说明 #  在设计需求阶段，如果开发和测试人员都没有参与，那么我们就必须单独将这些需求传达给他们。在需求传递的过程中必然会丢失一些信息，甚至可能是关键信息。协作制定需求说明使我们能够充分利用整个团队的知识和经验，它还创造了需求的集团所有制，让每个人都能更多地参与到交付过程中。\n举例说明 #  自然语言是模棱两可的，而且和上下文相关。开发人员和测试人员对一些棘手需求可能有着截然不同的解释。举例说明让团队和用户一起确切地描述那些预期功能的关键实例。在此过程中，开发人员和测试人员往往会提出一些额外的实例，用于说明边界的情况，或重点标识出系统中某些特别有问题的地方。这可以清除功能分歧和不一致的地方，并确保所有参与者都对需求交付的东西有一个共识，避免由误解及解释不到位导致的返工。\n提炼需求说明 #  讨论过程会产生一些与需求不相关的细节。通过提炼需求获得具体的、精确的上下文。它是一种工作规范和验收测试案例，也是很好的功能回归测试案例。\n自动化验证时不修改需求说明 #  为了从关键实例中获的最大的收益，成功的团队在做自动化验证时不会去改变需求信息。在自动化过程中，他们几乎完全不改变需求。这样就不会有错误理解的风险。当他们进行自动化验证而不改变需求说明时，电子化的关键实例和把他们写到白板上看起来一样：团队的所有成员都可以直接看到。这是一份可执行的需求说明，我们把它当作开发目标，轻松地检查系统是否按照预期运作，并向用户进行澄清。如果需要变更需求，只需要在一个地方进行变更。\n频繁验证 #  代码往往是我们唯一能真正信任的东西，大多数编写好的文档在软件交付前就已经过时了。通过频繁地检查所有可执行的需求说明，团队能快速地发现系统和需求说明之间的任何差别。因为可执行的需求说明很容易理解，团队可以和用户讨论这些改动。并决定如何处理。\n演化出一个文档系统 #  活文档是关于系统功能可靠的、权威的信息源，任何人都可以获得。他和代码一样可靠，但是更容易阅读和理解。运营可以用它来查明系统在做什么以及这样做的原因。开发人员可以用它作为开发的目标。测试可以用它来作为测试案例或回归案例。分析功能变更前请求影响时，系统分析师可以从它开始着手。\n实际的例子 #  商业目标 #  良好的商业目标例子 12个月内对现有客户提高50%的重复销售。\n范围 #  例子：客户注册一个VIP计划，VIP客户有资格获得特定物品的免费送货权利。 会员忠诚度管理系统基本功能的用户故事\n 为了能够对现有客户做产品直销，作为营销经理，我想让客户通过加入VIP计划注册个人信息。 为了吸引现有客户注册VIP计划，作为营销经理，我要系统为VIP客户提供特定物品的免费送货。 为了节省开支，作为现有客户，我希望能收到特价优惠的信息。  关键实例 #  关键实例：免费送货\n VIP客户购物车中有5本书籍可以获得免费送货。 VIP客户购物车中有4本书籍就不提供免费送货。 普通客户购物车中有5本书籍没有免费送货。 VIP客户购物车中有5台洗衣机时不提供免费送货。 VIP客户购物车中有5本书籍和1台洗衣机时不提供免费送货。  带实例的需求说明 #  我们从关键实例中提炼出需求说明，创建出一目了然的文档并将其格式化便于今后做自动化验证。 免费送货\n 当VIP客户购买一定数量的书籍时，提供免费送货。免费送货不提供给普通客户或购买非书籍的VIP客户。 假定至少买5本书才能获得免费送货服务，那么我们会得到以下预期：     客户类型 购物车中的物品 送货     VIP 5本书 免费，标准   VIP 4本书 标准   普通 10本书 标准   VIP 5台洗衣机 标准   VIP 5本书,1台洗衣机 标准   这个需求说明————一目了然的文档————可以用作实现的目标和自动化测试的驱动，这样我们就可以客观地衡量什么时候算完成了。把它作为活文档的一部分，保存在需求说明仓库中。      可执行的需求说明 #  开发人员会实现相关功能并把它与自动化框架关联在一起。他们使用自动化框架如RobotFramework，从需求说明中获得输入并验证预期的输出，而不需要实际修改需求说明文档。当验证实现自动化以后，需求说明就变成可执行的了。\n活文档 #  所有已实现功能的需求说明需要频繁地进行验证，一般通过自动化构建过程来实现。这样可以确保需求说明保持更新，同时有助于避免功能退化的问题。当实现了整个用户故事的时候，需要有人去做首次验证以确保其已经完成，然后重组需求说明确保它和已实现功能的需求说明是一致的。当我需要回顾或添加处理逻辑时，我们可以使用活文档来理解现有的功能并注明需要修改的地方。使用已有的实例来协作制定需求说明，这部分最终会和需求说明的其他部分合并到一起。\n铭记 #   实例化需求说明的主要过程模式是从目标中获取范围、协作制定需求说明、举例说明、提炼需求说明、自动化炎症是不修改需求说明、频繁演郑伊健演进出活文档系统。 对于实例化需求说明而言，功能需求、需求说明和验证测试都是一回事。 不同背景的团队使用不同的实践来实施过程模式。  活文档 #  为什么我们需要权威的文档 #  测试可以是好问的 #  根据可执行的需求说明创建文档 #  以文档为中心的模型所具有的好处 #  开始改变 #  如何开始改变过程 #  如何开始改变团队文化 #  团队如何在流程和迭代中集成协作 #  处理签收和可追朔性。 #  警告信号 #  通过协作制定需求说明 #  为什么写作制定需要说明 #  最热门的协作模型 #  准备协作 #  选择协作模型 #  "});index.add({'id':27,'href':'/posts/%E5%AE%9E%E4%BE%8B%E5%8C%96%E9%9C%80%E6%B1%82%E5%B0%81%E9%9D%A2.jpg/','title':"实例化需求封面.jpg",'section':"Posts",'content':";s:25:\u0026ldquo;实例化需求封面.jpg\u0026rdquo;;s:4:\u0026ldquo;path\u0026rdquo;;s:35:\u0026quot;/usr/uploads/2017/11/3462487182.jpg\u0026quot;;s:4:\u0026ldquo;size\u0026rdquo;;i:15026;s:4:\u0026ldquo;type\u0026rdquo;;s:3:\u0026ldquo;jpg\u0026rdquo;;s:4:\u0026ldquo;mime\u0026rdquo;;s:10:\u0026ldquo;image/jpeg\u0026rdquo;;}\n"});index.add({'id':28,'href':'/posts/%E6%95%8F%E6%8D%B7%E6%AD%A6%E5%A3%AB%E7%AC%94%E8%AE%B0/','title':"敏捷武士笔记",'section':"Posts",'content':"Part1 敏捷简介 #  每周交付一些有价值的东西 #   要将大问题拆分为许多小问题\u0026ndash;逐步完成目标 要将注意力集中与最重要的事务\u0026ndash;可工作的软件 确保正在交付的软件可以工作\u0026ndash;充分测试 寻求反馈\u0026ndash;UAT 必要时可以改变过程\u0026ndash;延期 要勇于负责\u0026ndash;设定质量、进度、期望值  敏捷计划如何生效 #  排列用户故事由高级特性组成。根据优先级排列高级特性与用户故事。如果进度无法保证时，应改变计划减少用户故事来保证质量。制定不切实际的计划，只能祈求奇迹的发生。如果一个项目一直通过祈求奇迹的方式运行，那是多么地糟糕和失控。与业务开诚布公地说明风险、人力和需求的关系，让业务做出明确的决定。与其幻想着在有限的时间和资源内交付完美的软件，还不如期待最后会发生奇迹。\n“完成”的意思就是“完成” #  详细的计划和设计以及测试设计不代表完成了所需的代码。实际编写代码时会遇到比设计过程中更多的问题。关联系统的错误可能导致编码无法继续，历史遗留的bug会让你花费更多的时间。多次更改让bug错综复杂，测试计划覆盖无法全面。设计文档不能说明任务完成了一半，它只是一份备忘录，让你有更多精力发现编码或测试前没有考虑到的问题。\n三条简单准则 #    在项目的初期不可能收集到所有的需求。 不管你收集到什么需求，最终他们肯定会发生变化。 总会由任务超时、超支。   接受第一条：即使没有完全准备好，也要大胆开始收集需求的敏捷旅程。 接受第二条：不必害怕需求变更，变化无可避免，不如想想如何调整计划。 接受第三条：任务超时或者超支时，不要感到有压力。对于变化频繁的项目来说，这只是正常状态。唯一能做的是设置号任务的优先级，把有限的资源用在紧急的任务中。 一旦接受以上三条简单的项目准则，那些在软件交付过程中经常困扰你的紧张和焦虑感就会消失。\nXXXXX\rCrystal X XX Scrum\rXXXXX XXXXXX\rX XX XX X\rXX XXXX XX\rXXXX XXXXXXX\rXX X X XXX\rLean X X XP\rX X\rX XX\rX XX\rX X\rX X\rKanban X X Your Method\rX X\rXX\r敏捷是一种开发思维方式，但却不是终极解决方案。结合Scrum、XP、精益、看板甚至是你自己的独特方式解决实践问题。\n结识敏捷团队 #  敏捷团队中没有预先设计好的角色，任何人应该预备做任何事的能力。它就是一头野兽，面对业务需求凶猛残暴，它身体上的每一部分都充满攻击性。\n敏捷项目有何不同 #  大公司的敏捷团队与创业公司没有什么不同，每个人的角色很模糊。虽然人们各有专长，但实际上敏捷团队中不应该有开发、测试这种侠义的角色存在。开发可以担任白盒测试，负责其他开发人员的软件单元测试编写工作。测试可以深入代码，配合开发完成复杂逻辑的开发任务。敏捷团队的业务分析、设计、编码和测试是一连串不断重复的活动。成员与成员直接关系紧密，每个人都参与其中，承担着出生产问题的风险。\n如何激发团队 #  集中办公 #  集中办公的效率就是要高一些，没有了距离，面对面的沟通中人们通过肢体语言、面部表情和语气可以更加精确地传递信息，减少了沟通阻碍。通过工作之外的一些交流，人与人之间建立了认知关系。\n专职客户 #  提供需求的业务人员也是敏捷开发的成员之一，这里称为专职客户。专职客户了解系统的开发过程，与开发人员长期沟通产生了默契，合作的时间越久，沟通的效率越高。专职客户最好与开发人员一起工作，甚至是在同一现场办公。在开发过程中不断把中间结果提供给专职客户，收集客户的反馈，然后把那些bug都解决掉！\n自组织 #  让角色适应人而不是让人适应角色。\n勇于承担和授权 #  跨职能 #  我们通常所见之角色 #  敏捷客户 #  开发团队 #  敏捷分析师 #  敏捷程序员 #  敏捷测试者 #  敏捷项目经理 #  敏捷用户体验设计师 #  其他人 #  组建敏捷团队的技巧 #  寻求多面手 #  能够欣然接受模糊角色之人 #  那些能够放下自己的架子之团队员工 #  "});index.add({'id':29,'href':'/posts/Redis-%E5%AE%9E%E9%AA%8C%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98/','title':"Redis 实验中遇到的一些问题",'section':"Posts",'content':"如何在外网访问redis？ 在实例配置文件中修改以下配置：\n 注释bind命令。  # bind 127.0.0.1 将保护模式改为no  protected-mode 打通防火墙  sudo ufw all 6379 "});index.add({'id':30,'href':'/posts/linux%E7%BD%91%E5%8D%A1/','title':"linux网卡",'section':"Posts",'content':"# 找到可用的网卡 $ ifconfig -a # 添加网卡 $ sudo vim /etc/network/interfaces # 写入内容 iface enp0s9 inet dhcp # 启动网卡 $ ifup enp0s9 "});index.add({'id':31,'href':'/posts/Java%E8%BF%9B%E8%A1%8C%E8%AE%BF%E9%97%AEHttps/','title':"Java进行访问Https",'section':"Posts",'content':" 导入证书 keytool -import -file test.crt -keystore ca_certs  信任所有证书 HttpsURLConnection.setDefaultHostnameVerifier(new HostnameVerifier() { @Override public boolean verify(String s, SSLSession sslSession) { return true; } }); try { SSLContext sslc = SSLContext.getInstance(\u0026#34;TLS\u0026#34;); sslc.init(null, new TrustManager[]{new X509TrustManager() { @Override public void checkClientTrusted(X509Certificate[] x509Certificates, String s) throws CertificateException { } @Override public void checkServerTrusted(X509Certificate[] x509Certificates, String s) throws CertificateException { } @Override public X509Certificate[] getAcceptedIssuers() { return null; } }}, null); } catch (Exception e) { e.printStackTrace(); } `\n 使用httpUrlConnection正常连接Http  "});index.add({'id':32,'href':'/posts/Web%E6%8E%A5%E5%8F%A3%E8%AE%BE%E8%AE%A1%E4%B9%8B%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8/','title':"Web接口设计之数据安全",'section':"Posts",'content':"最近有一个暴露在外网的接口服务需要加密。有了一些自己的想法，现记录下来。\n层次一 #  层次二 #  层次三 #  传输层加密 #  Http明文传输接口报文非常不安全，必须使用HTTPS来做传输层加密，防止报文数被简单截取。\n调用权限验证 #  做法来自于微信公众号开发中使用appid、nonce一次性随机数、盐、timestamp时间戳、用户名和密码来验证接口权限和建立双方互信。 客户端先向服务器发送获取token的请求，服务器验签后提供token给客户端。客户端调用接口时直接提供token，服务检查token是否存在、过期在根据情况提供api服务。\n访问控制列表 #  服务器判断用户的api请求是否在访问控制列表中，如果用户没有所需功能的权限，返回错误信息。java平台爱能够保护web安全的常见框架如Spring Security、Apache Shiro。\n"});index.add({'id':33,'href':'/posts/%E6%94%B9%E9%80%A0%E8%BF%87%E5%90%8E%E7%9A%84typecho%E7%BC%96%E8%BE%91%E5%B7%A5%E5%85%B7%E6%A0%8F.PNG/','title':"改造过后的typecho编辑工具栏.PNG",'section':"Posts",'content':";s:41:\u0026ldquo;改造过后的typecho编辑工具栏.PNG\u0026rdquo;;s:4:\u0026ldquo;path\u0026rdquo;;s:35:\u0026quot;/usr/uploads/2017/10/1551369649.png\u0026quot;;s:4:\u0026ldquo;size\u0026rdquo;;i:3910;s:4:\u0026ldquo;type\u0026rdquo;;s:3:\u0026ldquo;png\u0026rdquo;;s:4:\u0026ldquo;mime\u0026rdquo;;s:9:\u0026ldquo;image/png\u0026rdquo;;}\n"});index.add({'id':34,'href':'/posts/ACIDCAP%E5%92%8CBASE/','title':"ACID、CAP和BASE",'section':"Posts",'content':"#  ACID #  Atomicity #  Consistency #  Isolation #  Durability #  CAP #  Consistency #  Availability #  Partition tolerance #  BASE #  Basically Available Soft state Eventual #  "});index.add({'id':35,'href':'/posts/%E5%A4%A7%E5%A4%B4%E4%B8%8E%E5%B0%8F%E5%A4%B4/','title':"大头与小头",'section':"Posts",'content':"Little-Endian\u0026amp;Big-Endian\n例子 #  整数：6699 如果左边是起始地址0，右边无限大。 大头：数据从左到右存放-\u0026gt;1A2B 小头：数据从右到左存放-\u0026gt;2B1A\n代码 #  int main(void) { int i = 0x12345678; if(*((char*)\u0026amp;i) == 0x12) printf(\u0026#34;大端\u0026#34;); else printf(\u0026#34;小端\u0026#34;); return 0; } "});index.add({'id':36,'href':'/posts/%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E5%85%A8binary-safe/','title':"二进制安全（binary safe）",'section':"Posts",'content':"C语言的字符串依赖“\\0”来识别字符串的末尾。如果一个需要存储的字符串中含有“\\0”，那么C语言的字符串就不适合。二进制安全是不依赖于数据本身的某种格式来处理数据。 Redis中的SDS字符串使用了len变量来记录字符串的长度，原始数据使用字节数组来存储。任何形式的数据包括但不限于图片，声音，程序，文本。\n"});index.add({'id':37,'href':'/posts/typecho-%E5%BE%AE%E8%B0%83/','title':"typecho 微调",'section':"Posts",'content':"主题与插件 #  主题：Moricolor 插件：\n Access\t获取访客信息 Adminer\tAdminer for Typecho Blog Platform AjaxComments\tAjax 内置嵌套评论 AppStore\tTypecho 应用商店 APlayer for Typecho | Meting\tAPlayer for Typecho TpCache\tTypecho缓存插件  typecho本身 #  typecho编辑器的工具栏在浏览器窗口过窄时，比如用手机打开，就会出现按钮“丢失”。工具栏的id和class都为wmd-button-row，问题出在css文件\u0026rsquo;admin/css/style.css\u0026rsquo;中高度的设置为26px，改成auto就可以了。\n.wmd-button-row{list-style:none;margin:0;padding:0;height:26px;line-height:1;} 原来的CSS样式 修改过后的工具栏在手机上也可以使用了。\n"});index.add({'id':38,'href':'/posts/Redis-%E4%BB%8B%E7%BB%8D/','title':"Redis 介绍",'section':"Posts",'content':"Redis应用介绍# #  引文 #  简介 #  Redis诞生于2009年，是一个用ANSI C写成，基于键值对的可持久化开源内存数据库，最新版本为4.0.2。它提供对多种抽象数据结构的支持。授权类型为对商业友好的BSD授权。Redis是“REmote DIctionary Server”中大写字母的缩写。在DB-Engines排行上，经常被评为最受欢迎的键值对数据库。\n对编程语言的支持 #  Redis支持众多编程语言，包括常见的C/C++，C#，GO，Java, JavaScript（Nodejs）, PHP, Python, Ruby等。\n数据结构 #  使Redis变得流行的原因包括它内建多种实用的数据结构。Redis支持对数据的原子操作，对Set类型的集合操作等高级命令。目前Redis可支持的数据结构有string, lists, map, set, sorted set, bitmap, HyperLogLog, geo。\n原子性 #  Redis的单个操作有是原 子性，多个操作支持使用事务来保证数据安全。\n持久化 #  通常Redis将所有数据都放在内存中以加快操作速度。为了保障数据的安全，Redis提供了持久化的方案。用户可以选择使用RDB（Redis database ）快照，每隔一段时间将Redis在内存中的数据完整地写入到磁盘中，或者使用AOF（append-only file）来定时将数据变更日志写入到磁盘中,来增加系统的鲁棒性。\n主从（master-slave）复制 #  主从复制有利于系统读取速度，和数据冗余。Redis的master可以支持任意个slave。slave本身又可以作为其他slave的master。master-slave组成的集群就成了一个树形结构。Redis实现了完整的发布订阅功能。slave订阅一个channel以后，可以收到发送给master的消息，由此更新整个master-slave结构。\n性能 #  因为不必把变更写入磁盘，与需要遵守ACID的传统数据库相比，Redis有更高的效率，很容易支持10万/s以上的读写频率。除了AOF操作会多出一个线程外，通常一个Redis实例只有一个线程用于数据操作。因此，单个Redis不能并行执行任务，比如执行存储过程。\n集群 #  Redis在3.0版本推出了集群功能。Redis集群致力于在不使用代理额异步复制的情况下实现1000个节点以内的高性能线性伸缩。对集群写入时，能尽量保证写入的一致性。当有mater或者slave宕机时，集群能够自我调节，自动平衡分配master和slave。\n安装 #   redis在windows平台还没有官方支持。但是用户可以使用cygwin在windows下面编译使用。\n $ wget http://download.redis.io/releases/redis-4.0.2.tar.gz $ tar xzf redis-4.0.2.tar.gz $ cd redis-4.0.2 $ make # 暂时不安装到系统 $ cd src $ ./redis-server # 开启另一个终端 $ cd \u0026lt;刚才的src目录\u0026gt; $ ./redis-cli # 现在进入到了Redis的命令行环境，测试一下 127.0.0.1:6379\u0026gt; set hello world OK 127.0.0.1:6379\u0026gt; get hello \u0026#34;world\u0026#34; 127.0.0.1:6379\u0026gt; shutdown not connected\u0026gt; 使用 #  常见使用场景简介 #   根据二八原则，数据库中的大部分数据都是不经常使用的数据。虽然Redis用于页面缓存效果很好，但是越往前端走，数据的变化几率越大。Redis在DAO层使用的使用则很简单，加速效果也很明显。 Redis可以通过Session插件，替代服务器本身实现的Session。使用Redis作为session存储，就没有了分布式环境下的session复制问题。由于Redis在内存中的数据可以持久化，在突然宕机的情况下，应用重新启动能够最大限度地恢复已有会话。 得力于Redis内置的数据结构支持，其他程序可以使用redis的list作为公共的操作队列，每个list可以存放约40亿个数据，可以选择固定list长度来只保留最新的数据。 Redis的Set集合可以实现传统数据库不方便实现的集合操作，如多个集合的交集、并集。使用SRANDMEMBER可以随机获取元素，方便实现抽奖功能。 Redis的String实现了二进制安全，可以存放任意类型的数据。配合incr、incrby、decr、decrby进行原子性的递增递减操作，可以用于实现计数器。 Sorted-Sets提供可以高效操作的有序集合，适合快速统计区间，排行情况。 redis3.2版本新增了地理位置支持。包括获取某范围内的地理位置，获取两个地理位置的距离等。非常适合LBS类应用。 使用Redis实现分布式锁。使用Redis存放一个lock值，如果lock存在则存放失败，并给lock设置超时时间以免死锁。  Redis高可用方案 #  主从 Replication #  主从分离是简单的异步复制方案。写入由master负责，Slave只负责读取，减少Master的处理负担。需要注意的是，Slave的数据通过异步复制来提高效率。所以Master和Slave的数据有不一致的可能。\n +-----------+\r| Master |\r+----+------+\r|\r+--------------------------------------+\r| | |\r| | |\r+------v-----+ +-----------+ +------v-----+\r| Slave | | Slave | | Slave |\r+------------+ +-----------+ +------------+\r配置文件 #    复制Redis目录下的redis.conf到master、slave01、slave02、slave03文件夹。以下配置无特殊说明都在各自的redis.conf中配置。\n  修改端口号：通过修改redis.conf来修改master的端口号为6900，依次修改slave为6901、6902、6903。\nport 6900   修改pid：pid文件就是redis的启动锁，所以需要给master和slave单独指定pid文件，这里Master的配置使用端口号来区分redis。Slave的配置相似。\npidfile /var/run/redis_6900.pid   Slave连接Master，需要在配置中指定ip地址和端口号。如果Master有密码，还要配置masterauth\nslaveof 127.0.0.1 6900 # If the master is password protected (using the \u0026#34;requirepass\u0026#34; configuration # directive below) it is possible to tell the slave to authenticate before # starting the replication synchronization process, otherwise the master will # refuse the slave request. # # masterauth \u0026lt;master-password\u0026gt; 读写分离，需要在Master中配置slave-read-only，Redis默认配置为yes\nslave-read-only yes   启动Master，检查进程和端口占用情况。Master占用了6900并且已经开始服务。\n# 启动Master redis-server master00/redis.conf # 检查运行情况 ps -ef | grep redis-server \u0026gt; root 31707 31141 0 10:07 pts/0 00:00:00 ./redis-server 127.0.0.1:6900 # 使用客户端连接Master redis-cli -p 6900 # 使用info检查Master运行情况 127.0.0.1:6900\u0026gt; info # Server redis_version:4.0.1 redis_git_sha1:00000000 redis_git_dirty:0 redis_build_id:c6561a899728564f redis_mode:standalone os:Linux 4.4.0-62-generic x86_64 arch_bits:64 multiplexing_api:epoll atomicvar_api:atomic-builtin gcc_version:5.4.0 process_id:31707 run_id:9ad3b08ab0df9a99fc65b92c3d835c6737efa09c tcp_port:6900 uptime_in_seconds:79 uptime_in_days:0 hz:10 lru_clock:15897904 executable:/www/server/redis/src/./redis-server config_file:/www/server/redis/master-slave/master00/redis.conf # 启动slave redis-server slave01/redis.conf 899:S 27 Oct 10:29:51.169 * Ready to accept connections 899:S 27 Oct 10:29:51.169 * Connecting to MASTER 127.0.0.1:6900 899:S 27 Oct 10:29:51.169 * MASTER \u0026lt;-\u0026gt; SLAVE sync started   哨兵 Sentinel #  哨兵Sentinel，是Redis官方的高可用性解决方案，下面统称哨兵。如同它的名字一样，哨兵实例作为Redis集群的监管人，时刻监视者多个主服务器和从服务器。当主服务器意外宕机或者出现写入不稳定的时候，哨兵就会进行主从切换（failover）挑选一个从服务器作为主服务器来继续维持主从结构。因为哨兵的工作原理，至少需要三个哨兵实例共同协作，因此也需要三个配置文件。下面修改哨兵的配置文件sentinel00.conf\n配置 #    配置哨兵的端口\nport 26901   配置需要监控的主服务器\n# 最后面的2表示至少需要2个哨兵实例的同意才可以执行failover sentinel monitor mymaster 127.0.0.1 6900 2   启动哨兵\nredis-sentinel sentinel00.conf   协作 #  上面的配置中，并没有指定哨兵之间的关系。那么哨兵之间是如何协作的呢？启动哨兵的时候，它会使用Redis的发布和订阅功能，发布自己存在的情况。哨兵之间建立联系后，是用特殊协议gossip来互相传递信息。如果哨兵发现某个master挂了，为了防止因为网络延迟的原因误判，那么它会征求其他哨兵的意见。如果任务此master挂掉的哨兵数量超过上面哨兵配置中设定的值，那么哨兵才会执行主从切换。所以哨兵的数量至少为三个。因为slave只读，如果一个哨兵发现某个slave挂了，不用询问其他哨兵，会之间在可用列表中去除这个slave。\n集群 Redis Cluster #  Redis的集群实际上是多个实例共同存储数据。有些类似与oracle分区表中的hash分区。由于集群分区存储数据，多个key有可能并不在同一个实例上，涉及到多个key的操作会影响性能，在突然高并发的情况下，有可能导致严重错误。Redis集群存在的意义在于把篮子拆成好几个，当一部分篮子不可用的时候，其它篮子不受影响。集群等待那个坏了的篮子进行主从切换，在短时间的切换后，集群又能恢复正常。数据拆分到了多个篮子，因此整个集群的横向扩展能力增强了。\n根据官方的解释，Redis Cluster使用将每个key通过CRC16校验后对16384取模来决定放置在哪个槽。好比把数据分成了16384个区，每个master-slave分配一定数量的区。当master挂了以后，启动主从切换来让这个区域的槽能够继续使用。由于使用了主从复制，所以Redis Cluster也不保证数据的强一致性。极端情况下，当某个master-slave中的master和slave全部挂掉后，对应的槽也会出现不可用。Redis Cluster被设计为去中心化，每个Cluster节点之间没有严格的主从关系。每个Cluster节点都保存了其他节点的连接信息。客户端连接任何一个节点都能获取其他节点的信息。需要注意的是，创建和运行集群时，必须保证有三个及以上的Cluster节点存在，如果运行时节点数量少于节点总数的一半的时候，整个集群便无法提供服务。\n60-Redis Cluster集群由于推出的时间不久，客户端并不多。但是在java平台上的Jedis和Redission都提供了对Redis Cluster集群的支持。\n创建集群 #    修改Redis实例配置\n# 开启集群 cluster-enabled yes # 指定生成的集群配置文件名 cluster-config-file nodes_6900.conf # 集群连接超时ms cluster-node-timeout 10000   使用官方提供的ruby脚本创建集群\nredis-trib.rb create --replicas 1 127.0.0.1:6900 127.0.0.1:6910 127.0.0.1:6920\t使用时只需连接其中一个master即连接到整个集群。\n  Redis分布式锁 #  RedLock #  Redis本身不针对特定平台，所以基于Redis设计的分布式锁理论上可以用于所有实现了Redis客户端编程语言。官方权威的Redis分布式锁算法被称为RedLock。\n分布式锁首先需要满足锁的安全性，其次必须保证锁的获取效率，并防止死锁。最后在分布式环境下能够保证一定的容灾能力。下面我们假设只有一个永不挂掉的Redis节点，只需要通过SET lockKey lockValue NX PX 10000就可以创建一个可靠的锁。NX表示只有lockKey这个key不存在的时候才设置key的值。PX 100000则表示10000毫秒后lockKey过期，保证了超时情况下不会死锁。注意，这里的lockKey必须是一个唯一值。为免与其他锁产生干扰可以使用伪随机数加应用编号的字符串尽来可能地保证这一点。锁使用完毕后，应该用DEL主动删除锁。但如果超时了，锁已经被删除，或者被替换则会出现误删除锁的问题。为了避免这个问题，可以在删除锁前检查锁的value是否与当初设置的一致，只有一致的情况下才可以删除这个锁。\nif redis.call(\u0026#34;get\u0026#34;,KEYS[1]) == ARGV[1] then return redis.call(\u0026#34;del\u0026#34;,KEYS[1]) else return 0 end 127.0.0.1:6379\u0026gt; SET lock 111 NX PX 10000 OK 127.0.0.1:6379\u0026gt; EVAL \u0026#34;if redis.call(\\\u0026#34;get\\\u0026#34;,KEYS[1]) == ARGV[1] then return redis.call(\\\u0026#34;del\\\u0026#34;,KEYS[1]) else return 0 end\u0026#34; 1 lock 222 (integer) 0 127.0.0.1:6379\u0026gt; EVAL \u0026#34;if redis.call(\\\u0026#34;get\\\u0026#34;,KEYS[1]) == ARGV[1] then return redis.call(\\\u0026#34;del\\\u0026#34;,KEYS[1]) else return 0 end\u0026#34; 1 lock 111 (integer) 1 单机环境下，用Redis实现分布式锁很方便也很好理解。如果是在分布时环境下呢？假设有Master和Slave各一台。\n 客户端A在Master获取了锁，客户端A开始使用唯一业务资源。 Master挂掉，Master到Slave的异步复制未完成。 Slave变成Master，客户端B获得与客户端A相同的锁。 客户端A和客户端B共同持有业务资源，锁失效。  Redlock算法为了应对分布式环境下，部分Redis实例失效的问题。要求客户端在释放时间截至前获取超过一半实例的锁。如果超时，或者获取一半以上实例的锁失败，则删除曾经尝试获得的锁。为了减少延时，应该使用socket的非阻塞模式同时向多个实例发起锁请求，而不是一个一个获取。获取锁的过程也应该设置超时，防止某个节点挂掉后长时间阻塞上锁过程。假如客户端获取锁失败，设置一定次数的重试。需要注意的是，如果多个程序间隔相同时间进行重试，容易产生严重的锁获取冲突。如果将重试的间隔时间设为随机，则重视的机会更小。释放锁过程相对与获得锁很直接，直接删除所有节点，包括尝试过但未能获得锁的节点上的锁。上述是一个较为完美的锁使用过程，然而在生产环境，难免会出现服务器非正常关机的情况。虽然Redis可以启用AOF持久化功能，每秒钟都把操作增量写到磁盘，但实际上只是操作系统把数据写到了缓冲。如果把缓冲区数据同步到磁盘的函数fsync每秒钟执行一次，那么还是有机会出现实例重启后丢失锁的可能。我们也可以把fsync设为立即模式，但是这样设置的结果就是降低了实例的生产效率，所以官方的默认设置为appendfsync everysec。前面规定Redlock锁都有释放时间，即在TTL（time to live）时间以外，锁会自动失败。通过设定Redis重启之后的服务延迟为锁的最长存活时间来让可能存在的锁因超时而失效，这样的延时重启策略在不依赖Redis的某种持久化特性的情况下保证了分布式锁的安全性。与此同时带来的问题是实例重启后不能立刻投入使用。极端状态下，所有实例一起宕机，重启后会有一段时间的服务真空期。\n   参数 注释 利弊     appendfsync no 让操作系统决定将缓冲真正写入到磁盘的时间 数据安全性得不到保障   appendfsync everysec 每秒钟请求操作系统将缓冲写入一次磁盘 数据安全性与效率的平衡   appendfsync always 总是请求操作系统将缓冲写入磁盘 安全性高，效率差    Redission上的RedLock #  使用Redis作为分布式锁的实现的效率较高。在单实例环境下可以非常简单地实现锁。在Java平台上也有较为成熟的分布式锁开源实现Redission。Redission本身支持单例模式、主从模式，哨兵模式、集群模式模式的Redis实例。如集群模式：\n// 创建Redis客户端 Config config = new Config(); config.useClusterServers() .setScanInterval(2000) // cluster state scan interval in milliseconds  .addNodeAddress(\u0026#34;127.0.0.1:6379\u0026#34;, \u0026#34;127.0.0.1:6380\u0026#34;) .addNodeAddress(\u0026#34;127.0.0.1:6381\u0026#34;); RedissonClient redisson = Redisson.create(config); // 获得锁 RLock lock = client.getLock(\u0026#34;testLock\u0026#34;); lock.tryLock(5,10, TimeUnit.SECONDS); // 组合锁 RLock lock1 = client1.getLock(\u0026#34;lock1\u0026#34;); RLock lock2 = client2.getLock(\u0026#34;lock2\u0026#34;); RLock lock3 = client3.getLock(\u0026#34;lock3\u0026#34;); RedissonMultiLock lockMulti = new RedissonMultiLock(lock1, lock2, lock3); // 正常获取锁 lock.unlock(); // 强制解锁 lock.forceUnlock(); // lock.forceUnlock()的具体实现 @Override public RFuture\u0026lt;Boolean\u0026gt; forceUnlockAsync() { cancelExpirationRenewal(); return commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN, // 暴力删除，并通知其他客户端  \u0026#34;if (redis.call(\u0026#39;del\u0026#39;, KEYS[1]) == 1) then \u0026#34; + \u0026#34;redis.call(\u0026#39;publish\u0026#39;, KEYS[2], ARGV[1]); \u0026#34; + \u0026#34;return 1 \u0026#34; + \u0026#34;else \u0026#34; + \u0026#34;return 0 \u0026#34; + \u0026#34;end\u0026#34;, Arrays.\u0026lt;Object\u0026gt;asList(getName(), getChannelName()), LockPubSub.unlockMessage); } // lock.unlock()的具体实现 // KEY[1]为锁名称，KEY[2]为关注的队列名称，ARGV[1]为解锁消息，ARGV[2]为超时时间，ARGV[3]为线程  protected RFuture\u0026lt;Boolean\u0026gt; unlockInnerAsync(long threadId) { return commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN, \u0026#34;if (redis.call(\u0026#39;exists\u0026#39;, KEYS[1]) == 0) then \u0026#34; + \u0026#34;redis.call(\u0026#39;publish\u0026#39;, KEYS[2], ARGV[1]); \u0026#34; + \u0026#34;return 1; \u0026#34; + \u0026#34;end;\u0026#34; + // 检查key是否还存在，如果不存在通知其他客户端  \u0026#34;if (redis.call(\u0026#39;hexists\u0026#39;, KEYS[1], ARGV[3]) == 0) then \u0026#34; + \u0026#34;return nil;\u0026#34; + \u0026#34;end; \u0026#34; + // 检查锁对应的线程是不是自己  // 自己不想再占有锁，锁的持有计数减1  \u0026#34;local counter = redis.call(\u0026#39;hincrby\u0026#39;, KEYS[1], ARGV[3], -1); \u0026#34; + \u0026#34;if (counter \u0026gt; 0) then \u0026#34; + // 如果自己不是最后一个持有者，让锁在指定时间内过期  \u0026#34;redis.call(\u0026#39;pexpire\u0026#39;, KEYS[1], ARGV[2]); \u0026#34; + \u0026#34;return 0; \u0026#34; + \u0026#34;else \u0026#34; + // 自己是最后一个持有者，删除锁，并通知其他客户端  \u0026#34;redis.call(\u0026#39;del\u0026#39;, KEYS[1]); \u0026#34; + \u0026#34;redis.call(\u0026#39;publish\u0026#39;, KEYS[2], ARGV[1]); \u0026#34; + \u0026#34;return 1; \u0026#34;+ \u0026#34;end; \u0026#34; + \u0026#34;return nil;\u0026#34;, Arrays.\u0026lt;Object\u0026gt;asList(getName(), getChannelName()), LockPubSub.unlockMessage, internalLockLeaseTime, getLockName(threadId)); } 其实除了实现Redlock，MultiLock，Redission还实现了Java并发包中常见的锁\n  可重入锁（Reentrant Lock）\n  公平锁 （Fair Lock）\n  读写锁（ReadWriteLock）\n  信号量（Semaphore）\n  闭锁（CountDownLatch）\n  从源代码上可见，Redission对分布式锁的实现较为完善。只是因为使用了lua脚本来操作Redis，所以需要Redis版本在2.6.0以上。\nJedis与Redission的比较 #  Jedis也是Redis在Java平台上一个客户端。Jedis使用穿传统的阻塞IO，依赖commons-pool2，除此之外几乎没有任何依赖。因为线程不安全，需要配合线程池使用。有一套完整的api对应Redis的各种原生功能。Redission基于Netty异步IO和事件编程，依赖较多，如：jackson、netty、projectreactor、javax.cache。Redission除了实现spring和java的缓存规范外，还屏蔽了Redis的底层操作，使用者直接操作分布式对象和集合。根据Redis中国用户组主席张冬洪翻译Nikita Koksharov的 文章，随着处理线程的增加（\u0026gt;8），Redission相较于Jedis，虽然处理速度慢2~3倍，但是吞吐量是Jedis的4倍左右。需要注意的是测试的Redission Pro版本是Redission的收费版本，多了Redis集群部署管理和针对大容量Map和Set的自动分片。由于Jedis出现得较早，目前使用的项目更多。个人认为，Jedis与Redission之间的关系就好比MyBatis与Hibernate。Redission自从2014年以来发展强劲，功能日趋完善。Redission的宗旨是让使用者能够将精力更多地放在处理业务逻辑上。\n在Spring中作为分布式Session服务器使用 #  传统会话#### #  用户访问web应用程序时，容器会为浏览器分配一个成为会话ID的随机字符串。第一次创建会话时，创建的会话ID将会作为响应的一部分返回到用户浏览器中。接下来从该用户浏览器中发出的请求都将通过某种方式包含该会话ID。当应用程序收到含有会话ID的请求时，它可以通过该ID将现有会话与当前请求关联起来。传输会话ID可以使用cookie技术存放在请求头中，通过设置超时时间来保证会话安全。如果浏览器不支持cookie或者主动关闭了cookie，web服务器也可以使用URL重写在返回给浏览器的html中的每个链接中使用参数分割符;加上会话ID作为URL的一部分。甚至是把会话绑定在SSL请求中，不过这样也要求用户使用HTTPS连接服务器。\nhttp://www.foo.com/bar;JSESSONID=EWNVFDxewfrWER234B?foo=bar\u0026amp;pick=up\r在支持Java EE6的容器中，可以配置所需要的模式：\n\u0026lt;session-config\u0026gt; \u0026lt;tracking-mode\u0026gt;COOKIE\u0026lt;/tracking-mode\u0026gt; \u0026lt;tracking-mode\u0026gt;URL\u0026lt;/tracking-mode\u0026gt; \u0026lt;tracking-mode\u0026gt;SSL\u0026lt;/tracking-mode\u0026gt; \u0026lt;/session-config\u0026gt; 会话会话以对象的方式存在与内存中。如果web应用部署在多个实例上，因为负载均衡用户两次访问到不同的服务器，服务器无法识别请求的会话ID。解决的办法是使用会话粘滞。通过在前端负载均衡服务器上安装插件，让apache、nginx、IIS等服务器识别会话ID的后缀，会话只会被发给指定的web容器。为了保证集群的可用性，通常还会采用会话复制的方式来避免某台实例宕机带来的用户数据丢失。在tomcat中编辑server.xml使用Cluster标签配置tomcat简单集群后。在应用中的web.xml中加上\u0026lt;distributable /\u0026gt; 标签即可开启集群间的会话共享。需要注意的是设置session共享后，如果使用session时了放入没有序列化接口的对象，会抛出IllegalArgurmentException异常。\nsession粘滞和session共享通过解决了session在集群环境下使用的问题。但是会话粘滞本身削弱了负载均衡的能力，会话复制在集群数量上升时会带来可观的系统资源开销。\nRedis实现会话的方案 #  用Redis实现会话共享有很多优点，比如：读取速度快，集群支持，实时在线用户管理，会话持久化，应用节点增加无感知。用Redis实现会话，主要有两种方式。第一种是在web容器层实现，对web应用无感知，但是依赖于固定容器。第二种是在应用层实现，对web容器无依赖，但是应用层可能有兼容性问题。\n Redis Session Manager for Apache Tomcat是Tomcat的一个Session插件，在github有1275个star。我们可以用它实现来实现Redis分布式存储session。下载源码进行编译，将实现包和依赖包commons-pool2-2.3.jar、jedis-2.7.2.jar、tomcat8_redis_session-0.0.1-SNAPSHOT.jar拷贝到tomcat的lib下。在tomcat的context.xml中或者server.xml的context部分配置插件和集群参数。\n\u0026lt;Valve className=\u0026#34;com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve\u0026#34; /\u0026gt; \u0026lt;Manager className=\u0026#34;com.orangefunction.tomcat.redissessions.RedisSessionManager\u0026#34; host=\u0026#34;localhost\u0026#34; \u0026lt;!-- optional: defaults to \u0026#34;localhost\u0026#34; --\u0026gt; port=\u0026#34;6379\u0026#34; \u0026lt;!-- optional: defaults to \u0026#34;6379\u0026#34; --\u0026gt; database=\u0026#34;0\u0026#34; \u0026lt;!-- optional: defaults to \u0026#34;0\u0026#34; --\u0026gt; maxInactiveInterval=\u0026#34;60\u0026#34; \u0026lt;!-- optional: defaults to \u0026#34;60\u0026#34; (in seconds) --\u0026gt; sessionPersistPolicies=\u0026#34;PERSIST_POLICY_1,PERSIST_POLICY_2,..\u0026#34; \u0026lt;!-- optional SAVE_ON_CHANGE:session 的 session.setAttribute() 或者 session.removeAttribute()方法被调用时，ALWAYS_SAVE_AFTER_REQUEST:每次请求结束后。--\u0026gt; sentinelMaster=\u0026#34;SentinelMasterName\u0026#34; \u0026lt;!-- optional --\u0026gt; sentinels=\u0026#34;sentinel-host-1:port,sentinel-host-2:port,..\u0026#34; \u0026lt;!-- optional --\u0026gt; /\u0026gt; 重启tomcat后，会话就被存储在了Redis中。实际使用时，在tomcat8中需要修改部分源代码。\n/* 类路径：src/main/java/com/demo/redis_session/RedisSessionManager.java */ private void initializeSerializer() throws ClassNotFoundException, IllegalAccessException, InstantiationException { ... /* if (getContainer() != null) { loader = getContainer().getLoader(); } */ // 修改为支持tomcat8 \tContext context = this.getContext(); if (context != null) { loader = context.getLoader(); } ... } Redission同样提供了对 Tomcat会话管理器（Tomcat Session Manager）的支持。添加RedissonSessionManager和相关jar包到Tomcat的lib目录下即可。\n如果你已经在使用Spring，可以整合 Spring Session。Spring Session支持使用Redis、GemFire、JDBC、MongoDB、Hazelcast来存储session。\n Spring Session自己实现了HttpSession，从Redis客户端中存取session对象。 Redis客户端支持集群，Spring Session也支持集群。 支持在同一个浏览器器里管理多个session。 提供RESTful API。 使用WebSocket接受消息时可以保持Session存活。  添加依赖\n\u0026lt;dependencies\u0026gt; \u0026lt;!-- ... --\u0026gt; \u0026lt;dependency\u0026gt;\u0026lt;!-- spring需要的组件 --\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.session\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-session-data-redis\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.3.1.RELEASE\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt;\u0026lt;!-- 一个Redis客户端 --\u0026gt; \u0026lt;groupId\u0026gt;biz.paluch.redis\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lettuce\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.5.0.Final\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-web\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.3.4.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; Spring Session的实现与Spring Security相似，需要在web.xml中添加过滤器：\n\u0026lt;!-- - Location of the XML file that defines the root application context - Applied by ContextLoaderListener. --\u0026gt; \u0026lt;!-- tag::context-param[] --\u0026gt; \u0026lt;context-param\u0026gt; \u0026lt;param-name\u0026gt;contextConfigLocation\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt; /WEB-INF/spring/*.xml \u0026lt;/param-value\u0026gt; \u0026lt;/context-param\u0026gt; \u0026lt;!-- end::context-param[] --\u0026gt; \u0026lt;!-- tag::springSessionRepositoryFilter[] --\u0026gt; \u0026lt;filter\u0026gt; \u0026lt;filter-name\u0026gt;springSessionRepositoryFilter\u0026lt;/filter-name\u0026gt; \u0026lt;filter-class\u0026gt;org.springframework.web.filter.DelegatingFilterProxy\u0026lt;/filter-class\u0026gt; \u0026lt;/filter\u0026gt; \u0026lt;filter-mapping\u0026gt; \u0026lt;filter-name\u0026gt;springSessionRepositoryFilter\u0026lt;/filter-name\u0026gt; \u0026lt;url-pattern\u0026gt;/*\u0026lt;/url-pattern\u0026gt; \u0026lt;dispatcher\u0026gt;REQUEST\u0026lt;/dispatcher\u0026gt; \u0026lt;dispatcher\u0026gt;ERROR\u0026lt;/dispatcher\u0026gt; \u0026lt;/filter-mapping\u0026gt; \u0026lt;!-- end::springSessionRepositoryFilter[] --\u0026gt; \u0026lt;!-- - Loads the root application context of this web app at startup. - The application context is then available via - WebApplicationContextUtils.getWebApplicationContext(servletContext). --\u0026gt; \u0026lt;!-- tag::listeners[] --\u0026gt; \u0026lt;listener\u0026gt; \u0026lt;listener-class\u0026gt; org.springframework.web.context.ContextLoaderListener \u0026lt;/listener-class\u0026gt; \u0026lt;/listener\u0026gt; \u0026lt;!-- end::listeners[] --\u0026gt; web.xml中载入的session.xml如下，装配了与redis交互的客户端：\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns:context=\u0026#34;http://www.springframework.org/schema/context\u0026#34; xmlns:p=\u0026#34;http://www.springframework.org/schema/p\u0026#34; xsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\u0026#34;\u0026gt; \u0026lt;!-- tag::beans[] --\u0026gt; \u0026lt;!--1--\u0026gt; \u0026lt;context:annotation-config/\u0026gt; \u0026lt;bean class=\u0026#34;org.springframework.session.data.redis.config.annotation.web.http.RedisHttpSessionConfiguration\u0026#34;/\u0026gt; \u0026lt;!--2--\u0026gt; \u0026lt;bean id=\u0026#34;jedisConnectionFactory\u0026#34; class=\u0026#34;org.springframework.data.redis.connection.jedis.JedisConnectionFactory\u0026#34; p:host-name=\u0026#34;localhost\u0026#34; p:port=\u0026#34;6379\u0026#34; /\u0026gt; \u0026lt;/beans\u0026gt; 上述为简单的单机方案，如果是哨兵集群方案，需要使用RedisSentinelConfiguration来配置。\n/** * jedis */ @Bean public RedisConnectionFactory jedisConnectionFactory() { RedisSentinelConfiguration sentinelConfig = new RedisSentinelConfiguration() .master(\u0026#34;mymaster\u0026#34;) .sentinel(\u0026#34;127.0.0.1\u0026#34;, 26379) .sentinel(\u0026#34;127.0.0.1\u0026#34;, 26380); return new JedisConnectionFactory(sentinelConfig); } Redission也提供了整合Spring Session的方法。需要先 整合Spring和Redission，再使用@EnableRedissionHttpSession声明使用Redission来实现HttpSession。\n@EnableRedissonHttpSession public class Config { @Bean public RedissonClient redisson() { return Redisson.create(); } } 然后提供一个启动器AbstractHttpSessionApplicationInitializer的扩展\npublic class Initializer extends AbstractHttpSessionApplicationInitializer { public Initializer() { super(Config.class); } } Spring Session由于重写了HttpSession，可能出现一些不可预料的结果。\n 不规范请求头可能导致请求输入流丢失。 jsp下从session中取出的对象修改完成后必须使用setAttribute方法提醒Spring Session向Redis提交更改。 Spring Session会主动开启Redis的键空间事件通知。redis-cli config set notify-keyspace-events Egx  如果你不使用spring框架，可以自己编写获取session的工具类，尽管这样对原来的业务代码有侵入性。\nRedis实现秒杀方案 #  要点：\n 不使用悲观锁 使用原子地进行增减 记录成功秒杀的用户信息 异步处理订单事务 结合流量防火墙限制请求  核心Redis操作指令如下\n# Server # 初始化商品的数量 set goods 100 # Client # 观察goods数量的变化 watch goods # 开始事务 multi # 减少商品数量 incrby goods -1 # 执行事务 exec # 1 事务成功,记录秒杀成功信息 setnx \u0026#39;seckill:userid\u0026#39; \u0026#39;userSecKillSucc\u0026#39;  服务器初始商品的数量 客户端连接服务器使用watch来检测键的变化 开启事务后减少商品数量 如果goods在事务过程中被改变了，那么事务失败。 如果goods在事务过程中没有被改变，事务成功。 事务成功后记录客户秒杀信息。 秒杀活动结束后，订单系统处理客户秒杀信息，将订单存入数据库。  Redis实时去重 #  统计网站访问量UV、PV时需要除重来获得净访问量。爬虫遍历URL时常常需要对数据进行除重来判断当前数据是否已经处理过，防止重复处理浪费资源。使用数据库的时候，我们可以使用distinct来去重，但是这个操作比较耗费时间，在时效性比较高的在线处理场合，传统数据库又出现了力不从心的情况。这里让redis实现实时去重的核心是Bloom Filter（布隆过滤器）配合Redis的BitMap。\n布隆过滤器 #  布隆过滤器要解决的问题是判断一个元素是否在集合中。\n   优点 缺点     只存储hash后的比特位，占用空间小 存在误判   hash算法效率高 只支持查询和插入   误判率固定为万分之五    只会误判，不会漏判      根据《数学之美》中给出的数据，在使用8个哈希函数的情况下，512MB大小的位数组在误报率万分之五的情况下可以对约两亿的url去重。而若单纯的使用set()去重的话，以一个url64个字节记，两亿url约需要128GB的内存空间。\n 布隆过滤器是一种高效率的标记结构。它使用hash计算将key名称散列到一些bit位上，下次检测key是否存在时只需将key从新散列，并检查散列后对应的bit位。如果每个bit位都是1则key存在，否则判定为不存在。大家都知道hash散列可能出现冲撞的情况，存储hash的空间越大，冲撞的几率越小。在Redis我们可以使用最大为512MB的BitMaps类型来存储Hash后的位状态，可供存储的状态位数量为 2^32个，出现误判的几率可以保持在5%以下。当可以承受一定的误判时，布隆过滤器相对其他数据结构有着非常大的空间优势。如果数据量太大，还可以将key进行hash后再取模分片到不同的key中。\n# 将key中偏移位10的状态位设为1 \u0026gt; setbit key 10 1 (integer) 0 # 再次设置key中偏移位的状态位，设置状态位1，并返回前一个状态。 \u0026gt; setbit key 10 1 (integer) 1 # 获取key偏移位10的状态位为1 \u0026gt; getbit key 10 (integer) 1 # 获取key偏移位11的状态位，因为之前没有设置，所以获得为0 \u0026gt; getbit key 11 (integer) 0 # 在key中放置url经过特定hash函数计算后的整数同样成立，可以判断之前有没有将url存入其中。 "});index.add({'id':39,'href':'/posts/Docker%E4%BD%BF%E7%94%A8/','title':"Docker使用",'section':"Posts",'content':"# 使用docker安装neo4j sudo apt install docker.io docker pull neo4j docker run -p 7474:7474 -p 7687:7687 -v $HOME/neo4j/data:/data neo4j "});index.add({'id':40,'href':'/posts/IO%E6%A8%A1%E5%9E%8B%E4%B8%8ENIO%E6%A8%A1%E5%9E%8B/','title':"IO模型与NIO模型",'section':"Posts",'content':"IO与NIO读取数据 #  +--------+ +--------+ +------+\r| Thread +------------------------------------\u0026gt; stream +-----\u0026gt; OS |\r+--------+ +--------+ +------+\r+--------+ +---------+\r+-- \u0026gt; buffer +---\u0026gt; channel +--+\r| +--------+ +---------+ |\r| |\r+--------+ +----------+ | +--------+ +---------+ | +------+\r| Thread +----\u0026gt; selector +----- \u0026gt; buffer +---\u0026gt; channel +-----\u0026gt; OS |\r+--------+ +----------+ | +--------+ +---------+ | +------+\r| |\r| +--------+ +---------+ |\r+-- \u0026gt; buffer +---\u0026gt; channel +--+\r+--------+ +---------+\r NIO读取含中文文本文件的例子 #  import java.io.IOException; import java.io.RandomAccessFile; import java.nio.ByteBuffer; import java.nio.channels.FileChannel; public class NIOTest { public static void main(String[] args) throws IOException { byte[] b1 = new byte[1]; int bn = 0; RandomAccessFile aFile = new RandomAccessFile(\u0026#34;D:/niotest.txt\u0026#34;, \u0026#34;rw\u0026#34;); FileChannel inChannel = aFile.getChannel(); ByteBuffer buffer = ByteBuffer.allocate(2); int bytesRead = inChannel.read(buffer); while (bytesRead != -1){ buffer.flip();//翻过来，不让操作系统继续向缓冲区写入数据。  while(buffer.hasRemaining()){ b1 = ensureCapacity(b1, bn); b1[bn++] = buffer.get();//按字节获取。如果按字获取，则必须保证每次读到的字节数为两个。  } buffer.clear();//清理缓存区的数据，让操作系统可以继续向缓冲区写数据。  bytesRead = inChannel.read(buffer); } aFile.close(); String content = new String(b1,\u0026#34;UTF-8\u0026#34;); System.out.println(content.toString()); } private static byte[] ensureCapacity(byte[] b1, int bn) { if(bn == b1.length){ byte[] b2 = new byte[b1.length*2]; System.arraycopy(b1,0,b2,0,b1.length); b1 = b2; } return b1; } } "});})();